{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Notebook for model training\n",
    "\n",
    "### Training Flow\n",
    "\n",
    "Load Training Data:\n",
    "- Load set of input data and label files\n",
    "- Prefilter positive set only to rule out heavily-masked patches\n",
    "- Create train/test set\n",
    "- Define augmentation parameters\n",
    "\n",
    "Train Model:\n",
    "- Define model architecture\n",
    "- Compile model\n",
    "- Train and evaluate model\n",
    "- Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-23 08:11:51.778203: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-23 08:11:51.798262: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-23 08:11:51.798280: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-23 08:11:51.798783: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-23 08:11:51.802449: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-23 08:11:52.455428: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "from datetime import datetime\n",
    "import time\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import io\n",
    "from contextlib import redirect_stdout\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, Conv2D\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "parent_dir = os.path.split(os.getcwd())[0]\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.insert(0, parent_dir)\n",
    "\n",
    "from scripts import dl_utils\n",
    "from scripts import viz_tools\n",
    "from scripts import models\n",
    "\n",
    "import gc\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# export TF_GPU_ALLOCATOR=cuda_malloc_async\n",
    "os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f3cc0b2f95e49939a8970d8f30015b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4549 samples loaded\n",
      "1891 positive samples\n",
      "2658 negative samples\n"
     ]
    }
   ],
   "source": [
    "resolution = 48\n",
    "\n",
    "data_files = [\n",
    "    \"amazonas_2020_thresh_0.5_2_negatives_2019-01-01_2020-01-01_patch_arrays.pkl\",\n",
    "    \"amazonas_2020_thresh_0.8_sumbsample_3_positives_2019-01-01_2020-01-01_patch_arrays.pkl\",\n",
    "    \"MinesPos2018-2020Sentinel_points_2019-01-01_2020-01-01_patch_arrays.pkl\",\n",
    "    \"bolivar_2020_thresh_0.8_sumbsample_5_positives_2019-01-01_2020-01-01_patch_arrays.pkl\",\n",
    "    \"full_amazon_v9_negatives_2019-01-01_2020-01-01_patch_arrays.pkl\",\n",
    "    \"v2.4_amazon_positives_2019-01-01_2020-01-01_patch_arrays.pkl\",\n",
    "    \"v2.6_amazon_thresh_0.8_negatives_2019-01-01_2020-01-01_patch_arrays.pkl\",\n",
    "    \"v2.0_bolivar_negatives_2019-01-01_2020-01-01_patch_arrays.pkl\",\n",
    "    \"riverbank_negatives_2019-01-01_2020-01-01_patch_arrays.pkl\",\n",
    "    \"bolivar_2020_thresh_0.8_1_negatives_2019-01-01_2020-01-01_patch_arrays.pkl\",\n",
    "    \"v2.1.1_bolivar_negatives_2019-01-01_2020-01-01_patch_arrays.pkl\",\n",
    "    \"v2.1_bolivar_positives_2019-01-01_2020-01-01_patch_arrays.pkl\",\n",
    "    \"v2.4_amazonas_negatives_2019-01-01_2020-01-01_patch_arrays.pkl\",\n",
    "    \"v2.4_amazon_negatives_2019-01-01_2020-01-01_patch_arrays.pkl\",\n",
    "    \"v2.6_amazon_negatives_2019-01-01_2020-01-01_patch_arrays.pkl\",\n",
    "    \"v2.6_amazon_negatives_v2_2019-01-01_2020-01-01_patch_arrays.pkl\",\n",
    "    \"v3.1_2023_negatives_2023-01-01_2024-01-01_patch_arrays.pkl\",\n",
    "    \"amazon_all_48px_v3.1_2023_positives_0.999_2023-01-01_2024-01-01_patch_arrays.pkl\",\n",
    "    \"v3.2_2023_negatives_2023-01-01_2024-01-01_patch_arrays.pkl\",\n",
    "    \"v3.3_2023_positives_2023-01-01_2024-01-01_patch_arrays.pkl\",\n",
    "    \"v3.4_2023_negatives_2023-01-01_2024-01-01_patch_arrays.pkl\",\n",
    "    \"v3.5_2023_negatives_2023-01-01_2024-01-01_patch_arrays.pkl\",\n",
    "    \"v3.6_2023_positives_2023-01-01_2024-01-01_patch_arrays.pkl\"\n",
    "    \n",
    "    ]\n",
    "\n",
    "label_files = [\n",
    "    \"amazonas_2020_thresh_0.5_2_negatives_2019-01-01_2020-01-01_patch_array_labels.pkl\",\n",
    "    \"amazonas_2020_thresh_0.8_sumbsample_3_positives_2019-01-01_2020-01-01_patch_array_labels.pkl\",\n",
    "    \"MinesPos2018-2020Sentinel_points_2019-01-01_2020-01-01_patch_array_labels.pkl\",\n",
    "    \"bolivar_2020_thresh_0.8_sumbsample_5_positives_2019-01-01_2020-01-01_patch_array_labels.pkl\",\n",
    "    \"full_amazon_v9_negatives_2019-01-01_2020-01-01_patch_array_labels.pkl\",\n",
    "    \"v2.4_amazon_positives_2019-01-01_2020-01-01_patch_array_labels.pkl\",\n",
    "    \"v2.6_amazon_thresh_0.8_negatives_2019-01-01_2020-01-01_patch_array_labels.pkl\",\n",
    "    \"v2.0_bolivar_negatives_2019-01-01_2020-01-01_patch_array_labels.pkl\",\n",
    "    \"riverbank_negatives_2019-01-01_2020-01-01_patch_array_labels.pkl\",\n",
    "    \"bolivar_2020_thresh_0.8_1_negatives_2019-01-01_2020-01-01_patch_array_labels.pkl\",\n",
    "    \"v2.1.1_bolivar_negatives_2019-01-01_2020-01-01_patch_array_labels.pkl\",\n",
    "    \"v2.1_bolivar_positives_2019-01-01_2020-01-01_patch_array_labels.pkl\",\n",
    "    \"v2.4_amazonas_negatives_2019-01-01_2020-01-01_patch_array_labels.pkl\",\n",
    "    \"v2.4_amazon_negatives_2019-01-01_2020-01-01_patch_array_labels.pkl\",\n",
    "    \"v2.6_amazon_negatives_2019-01-01_2020-01-01_patch_array_labels.pkl\",\n",
    "    \"v2.6_amazon_negatives_v2_2019-01-01_2020-01-01_patch_array_labels.pkl\",\n",
    "    \"v3.1_2023_negatives_2023-01-01_2024-01-01_patch_array_labels.pkl\",\n",
    "    \"amazon_all_48px_v3.1_2023_positives_0.999_2023-01-01_2024-01-01_patch_array_labels.pkl\",\n",
    "    \"v3.2_2023_negatives_2023-01-01_2024-01-01_patch_array_labels.pkl\",\n",
    "    \"v3.3_2023_positives_2023-01-01_2024-01-01_patch_array_labels.pkl\",\n",
    "    \"v3.4_2023_negatives_2023-01-01_2024-01-01_patch_array_labels.pkl\",\n",
    "    \"v3.5_2023_negatives_2023-01-01_2024-01-01_patch_array_labels.pkl\",\n",
    "    \"v3.6_2023_positives_2023-01-01_2024-01-01_patch_array_labels.pkl\"\n",
    "    \n",
    "    \n",
    "]\n",
    "\n",
    "patches = []\n",
    "labels = []\n",
    "\n",
    "data_dir = os.path.join('..', 'data', 'training_data', f\"{resolution}_px\")\n",
    "\n",
    "for data, label in tqdm(zip(data_files, label_files), total=len(data_files)):\n",
    "    with open(os.path.join(data_dir, data), 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "        for elem in data:\n",
    "            #patch = dl_utils.pad_patch(elem, resolution)\n",
    "            patches.append(elem)\n",
    "    with open(os.path.join(data_dir, label), 'rb') as f:\n",
    "        label = pickle.load(f)\n",
    "        labels = np.concatenate((labels, label))\n",
    "\n",
    "patches = np.array(patches)\n",
    "negative_patches = patches[labels == 0]\n",
    "positive_patches = patches[labels == 1]\n",
    "\n",
    "print(len(patches), \"samples loaded\")\n",
    "print(sum(labels == 1), \"positive samples\")\n",
    "print(sum(labels == 0), \"negative samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 64\n",
    "indices = np.random.randint(0, len(patches), num_samples)\n",
    "# viz_tools.plot_image_grid(patches[indices], labels=[int(label) for label in labels[indices]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_black(data, mask_limit=0.1, return_rejects=False):\n",
    "    masked_fraction = np.array([np.sum(np.mean(patch, axis=-1) < 10) / np.size(np.mean(patch, axis=-1)) for patch in data])\n",
    "    filtered_data = data[masked_fraction < mask_limit]\n",
    "    print(f\"{len(filtered_data) / len(data) :.1%} of data below brightness limit\")\n",
    "    if return_rejects:\n",
    "        rejected_data = data[masked_fraction >= mask_limit]\n",
    "        return filtered_data, rejected_data\n",
    "    else:\n",
    "        return filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.9% of data below brightness limit\n"
     ]
    }
   ],
   "source": [
    "# Filter positive pixels that are masked beyond a threshold. Don't want to give positive examples of cloud-masked patches\n",
    "filtered_positives, positive_rejects = filter_black(positive_patches, mask_limit = 0.1, return_rejects=True)\n",
    "if len(positive_rejects) > 0:\n",
    "    num_samples = 16**2\n",
    "    if len(positive_rejects) < num_samples:\n",
    "        num_samples = len(positive_rejects)\n",
    "    indices = np.random.randint(0, len(positive_rejects), num_samples)\n",
    "    # viz_tools.plot_numpy_grid(positive_rejects[indices,:,:,3:0:-1] / 3000)\n",
    "    # plt.title(\"Positive Masked Rejects\")\n",
    "    # plt.show()\n",
    "\n",
    "num_samples = 25 ** 2\n",
    "indices = np.random.randint(0, len(filtered_positives), num_samples)\n",
    "# fig = viz_tools.plot_numpy_grid(filtered_positives[indices,:,:,3:0:-1] / 3000)\n",
    "# plt.title('Positive Filtered Samples')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0% of data below brightness limit\n"
     ]
    }
   ],
   "source": [
    "filtered_negatives, negative_rejects = filter_black(negative_patches, mask_limit = 0.6, return_rejects=True)\n",
    "if len(negative_rejects) > 0:\n",
    "    num_samples = 16**2\n",
    "    if len(positive_rejects) < num_samples:\n",
    "        num_samples = len(positive_rejects)\n",
    "    indices = np.random.randint(0, len(negative_rejects), num_samples)\n",
    "    # viz_tools.plot_numpy_grid(negative_rejects[indices,:,:,3:0:-1] / 3000)\n",
    "    # plt.title(\"Negative Mask Rejects\")\n",
    "    # plt.show()\n",
    "\n",
    "num_samples = 25 ** 2\n",
    "indices = np.random.randint(0, len(filtered_negatives), num_samples)\n",
    "# fig = viz_tools.plot_numpy_grid(filtered_negatives[indices,:,:,3:0:-1] / 3000)\n",
    "# plt.title('Negative Filtered Samples')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for RGBIR, x = normalize(np.copy(images[:,:,:,[1,2,3,8]]))\n",
    "x = np.concatenate((filtered_negatives, filtered_positives))\n",
    "y = np.concatenate((np.zeros(len(filtered_negatives)), np.ones(len(filtered_positives))))\n",
    "x, y = shuffle(x, y, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raulpg/anaconda3/envs/tfm_tf/lib/python3.11/site-packages/keras/src/preprocessing/image.py:766: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3, or 4 channels on axis 3. However, it was passed an array with shape (4548, 48, 48, 12) (12 channels).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1800x1800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "augmentation_parameters = {\n",
    "    'featurewise_center': False,\n",
    "    'rotation_range': 360,\n",
    "    'width_shift_range': [0.9, 1.1],\n",
    "    'height_shift_range': [0.9, 1.1],\n",
    "    'shear_range': 10,\n",
    "    'zoom_range': [0.9, 1.1],\n",
    "    'vertical_flip': True,\n",
    "    'horizontal_flip': True,\n",
    "    # Fill options: \"constant\", \"nearest\", \"reflect\" or \"wrap\"\n",
    "    'fill_mode': 'reflect'\n",
    "}\n",
    "\n",
    "datagen = ImageDataGenerator(**augmentation_parameters)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12,12), facecolor=(1,1,1), dpi=150)\n",
    "aug_img, aug_labels = datagen.flow(x, y, batch_size=64).next()\n",
    "# viz_tools.plot_image_grid(aug_img, labels=[int(l) for l in aug_labels], norm=True);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_norm = np.clip(np.array(x.astype(\"float32\") / 10000), 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partimos el 10% del dataset total para test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = len(y)\n",
    "test_partition = int(dataset_size*0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de clases positivas en el dataset de training es de 1705, número de clases negativas 2389\n"
     ]
    }
   ],
   "source": [
    "num_positive_samples_train = sum(y[test_partition:]==1)\n",
    "num_negative_samples_train = sum(y[test_partition:]==0)\n",
    "\n",
    "print(f\"Número de clases positivas en el dataset de training es de {num_positive_samples_train}, número de clases negativas {num_negative_samples_train}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminamos estos samples del dataset de validacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_partition_x = x_norm[:test_partition]\n",
    "test_partition_y = y[:test_partition]\n",
    "\n",
    "x_norm = x_norm[test_partition:]\n",
    "y = y[test_partition:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Hiperparámetros ejecuciones originales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Preparación de hiperparámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Balanceo de clases para el entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "El número de valores para la clase no mina es de 0.8568438677270824 y para la clase mina 1.2005865102639297\n",
      "\n",
      "Ponemos peso a cada clase para tenerlo en cuenta en el entrenamiento {0: 0.8568438677270824, 1: 1.2005865102639297}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "import numpy as np\n",
    "\n",
    "# Suponiendo que 'y_train' es un array de las etiquetas de entrenamiento\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y),\n",
    "    y=y\n",
    ")\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "print(f\"\\nEl número de valores para la clase no mina es de {class_weight_dict[0]} y para la clase mina {class_weight_dict[1]}\")\n",
    "print(f\"\\nPonemos peso a cada clase para tenerlo en cuenta en el entrenamiento {class_weight_dict}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Clases no balanceadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a weighted loss\n",
    "class_weight = {0: 1, 1: 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diccionario con todos los hiperparámetros editables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hiperparámetros para pruebas: early stopping = 7 y LR descendiente = 4 con test size del 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################################################\n",
    "########################################## CLASES BALANCEADAS ###########################################\n",
    "#########################################################################################################\n",
    "                                                                                                        #\n",
    "# reduce_lr en callbacks                                                                                #                            \n",
    "hiper_params_test1_20 = {\"class_weight\" : class_weight_dict, #\n",
    "                      \"batch_size\" : 32,                                                                #\n",
    "                      \"epochs\" : 160,                                                                   #\n",
    "                      \"define_callbacks\" : [\"reduce_lr\", \"early_stopping\", \"model_checkpoint\"],         #\n",
    "                      \"patience_early_stopping\" : 7,                                                   #\n",
    "                      \"patience_reduce_lr\" : 4,                                                         #\n",
    "                      \"test_size\" : 0.2                                                                 #\n",
    "                     }                                                                                  #\n",
    "                                                                                                        #\n",
    "# SIN reduce_lr en callbacks                                                                            #\n",
    "hiper_params_test2_20 = {\"class_weight\" : class_weight_dict, #\n",
    "                      \"batch_size\" : 32,                                                                #\n",
    "                      \"epochs\" : 160,                                                                   #\n",
    "                      \"define_callbacks\" : [\"early_stopping\", \"model_checkpoint\"],                      #\n",
    "                      \"patience_early_stopping\" : 7,                                                   #\n",
    "                      \"test_size\" : 0.2                                                                 #\n",
    "                     }                                                                                  #\n",
    "#########################################################################################################\n",
    "\n",
    "#########################################################################################################\n",
    "####################################### CLASES NO BALANCEADAS ###########################################\n",
    "#########################################################################################################\n",
    "                                                                                                        #\n",
    "# Reduce_lr en callbacks                                                                                #\n",
    "hiper_params_test3_20 = {\"class_weight\" : {0: 1, 1: 1},                                                 #\n",
    "                      \"batch_size\" : 32,                                                                #\n",
    "                      \"epochs\" : 160,                                                                   #\n",
    "                      \"define_callbacks\" : [\"reduce_lr\", \"early_stopping\", \"model_checkpoint\"],         #\n",
    "                      \"patience_early_stopping\" : 7,                                                   #\n",
    "                      \"patience_reduce_lr\" : 4,                                                         #\n",
    "                      \"test_size\" : 0.2                                                                 #\n",
    "                     }                                                                                  #\n",
    "#SIN Reduce_lr en callbacks                                                                             #\n",
    "hiper_params_test4_20 = {\"class_weight\" : {0: 1, 1: 1},                                                 #\n",
    "                      \"batch_size\" : 32,                                                                #\n",
    "                      \"epochs\" : 160,                                                                   #\n",
    "                      \"define_callbacks\" : [\"early_stopping\", \"model_checkpoint\"],                      #\n",
    "                      \"patience_early_stopping\" : 7,                                                   #\n",
    "                      \"test_size\" : 0.2                                                                 #\n",
    "                     }                                                                                  #\n",
    "#########################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Hiperparámetros para pruebas: early stopping = 7 y LR descendiente = 4 con test size del 30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################################################\n",
    "###################################### CLASES BALANCEADAS ###############################################\n",
    "#########################################################################################################\n",
    "                                                                                                        #\n",
    "# Reduce_lr en callbacks                                                                                #\n",
    "hiper_params_test1_30 = {\"class_weight\" : class_weight_dict, #\n",
    "                      \"batch_size\" : 16,                                                                #\n",
    "                      \"epochs\" : 160,                                                                   #\n",
    "                      \"define_callbacks\" : [\"reduce_lr\", \"early_stopping\", \"model_checkpoint\"],         #\n",
    "                      \"patience_early_stopping\" : 7,                                                   #\n",
    "                      \"patience_reduce_lr\" : 4,                                                         #\n",
    "                      \"test_size\" : 0.3                                                                 #\n",
    "                     }                                                                                  #         \n",
    "                                                                                                        #\n",
    "# SIN reduce_lr en callbacks                                                                            #   \n",
    "hiper_params_test2_30 = {\"class_weight\" : class_weight_dict, #\n",
    "                      \"batch_size\" : 16,                                                                #\n",
    "                      \"epochs\" : 160,                                                                   #\n",
    "                      \"define_callbacks\" : [\"early_stopping\", \"model_checkpoint\"],                      #\n",
    "                      \"patience_early_stopping\" : 7,                                                   #\n",
    "                      \"test_size\" : 0.3                                                                 #\n",
    "                     }                                                                                  #\n",
    "#########################################################################################################\n",
    "\n",
    "######################################################################################################\n",
    "###################################### CLASES NO BALANCEADAS #########################################\n",
    "######################################################################################################\n",
    "                                                                                                     #\n",
    "# Reduce_lr en callbacks                                                                             #  \n",
    "hiper_params_test3_30 = {\"class_weight\" : {0: 1, 1: 1},                                              #\n",
    "                      \"batch_size\" : 16,                                                             #\n",
    "                      \"epochs\" : 160,                                                                #\n",
    "                      \"define_callbacks\" : [\"reduce_lr\", \"early_stopping\", \"model_checkpoint\"],      #\n",
    "                      \"patience_early_stopping\" : 7,                                                #\n",
    "                      \"patience_reduce_lr\" : 4,                                                      #\n",
    "                      \"test_size\" : 0.3                                                              #\n",
    "                     }                                                                               #\n",
    "                                                                                                     #\n",
    "# SIN reduce_lr en callbacks                                                                         #      \n",
    "hiper_params_test4_30 = {\"class_weight\" : {0: 1, 1: 1},                                              #\n",
    "                      \"batch_size\" : 16,                                                             #\n",
    "                      \"epochs\" : 160,                                                                #\n",
    "                      \"define_callbacks\" : [\"early_stopping\", \"model_checkpoint\"],                   #\n",
    "                      \"patience_early_stopping\" : 7,                                                #\n",
    "                      \"test_size\" : 0.3                                                              #\n",
    "                     }                                                                               #\n",
    "######################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Hiperparámetros para pruebas: aumento patience en early stopping = 14 y LR descendiente = 8, split de 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################################################\n",
    "########################################## CLASES BALANCEADAS ###########################################\n",
    "#########################################################################################################\n",
    "                                                                                                        #\n",
    "# reduce_lr en callbacks                                                                                #                            \n",
    "hiper_params_test5_20 = {\"class_weight\" : class_weight_dict, #\n",
    "                      \"batch_size\" : 32,                                                                #\n",
    "                      \"epochs\" : 160,                                                                   #\n",
    "                      \"define_callbacks\" : [\"reduce_lr\", \"early_stopping\", \"model_checkpoint\"],         #\n",
    "                      \"patience_early_stopping\" : 14,                                                   #\n",
    "                      \"patience_reduce_lr\" : 8,                                                        #\n",
    "                      \"test_size\" : 0.2                                                                 #\n",
    "                     }                                                                                  #\n",
    "                                                                                                        #\n",
    "# SIN reduce_lr en callbacks                                                                            #\n",
    "hiper_params_test6_20 = {\"class_weight\" : class_weight_dict, #\n",
    "                      \"batch_size\" : 32,                                                                #\n",
    "                      \"epochs\" : 160,                                                                   #\n",
    "                      \"define_callbacks\" : [\"early_stopping\", \"model_checkpoint\"],                      #\n",
    "                      \"patience_early_stopping\" : 14,                                                   #\n",
    "                      \"test_size\" : 0.2                                                                 #\n",
    "                     }                                                                                  #\n",
    "#########################################################################################################\n",
    "\n",
    "#########################################################################################################\n",
    "####################################### CLASES NO BALANCEADAS ###########################################\n",
    "#########################################################################################################\n",
    "                                                                                                        #\n",
    "# Reduce_lr en callbacks                                                                                #\n",
    "hiper_params_test7_20 = {\"class_weight\" : {0: 1, 1: 1},                                                 #\n",
    "                      \"batch_size\" : 32,                                                                #\n",
    "                      \"epochs\" : 160,                                                                   #\n",
    "                      \"define_callbacks\" : [\"reduce_lr\", \"early_stopping\", \"model_checkpoint\"],         #\n",
    "                      \"patience_early_stopping\" : 14,                                                   #\n",
    "                      \"patience_reduce_lr\" : 8,                                                        #\n",
    "                      \"test_size\" : 0.2                                                                 #\n",
    "                     }                                                                                  #\n",
    "#SIN Reduce_lr en callbacks                                                                             #\n",
    "hiper_params_test8_20 = {\"class_weight\" : {0: 1, 1: 1},                                                 #\n",
    "                      \"batch_size\" : 32,                                                                #\n",
    "                      \"epochs\" : 160,                                                                   #\n",
    "                      \"define_callbacks\" : [\"early_stopping\", \"model_checkpoint\"],                      #\n",
    "                      \"patience_early_stopping\" : 14,                                                   #\n",
    "                      \"test_size\" : 0.2                                                                 #\n",
    "                     }                                                                                  #\n",
    "#########################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Hiperparámetros para pruebas: aumento patience en early stopping = 14 y LR descendiente = 8, split de 30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################################################\n",
    "###################################### CLASES BALANCEADAS ###############################################\n",
    "#########################################################################################################\n",
    "                                                                                                        #\n",
    "# Reduce_lr en callbacks                                                                                #\n",
    "hiper_params_test5_30 = {\"class_weight\" : class_weight_dict, #\n",
    "                      \"batch_size\" : 16,                                                                #\n",
    "                      \"epochs\" : 160,                                                                   #\n",
    "                      \"define_callbacks\" : [\"reduce_lr\", \"early_stopping\", \"model_checkpoint\"],         #\n",
    "                      \"patience_early_stopping\" : 14,                                                   #\n",
    "                      \"patience_reduce_lr\" : 8,                                                        #\n",
    "                      \"test_size\" : 0.3                                                                 #\n",
    "                     }                                                                                  #         \n",
    "                                                                                                        #\n",
    "# SIN reduce_lr en callbacks                                                                            #   \n",
    "hiper_params_test6_30 = {\"class_weight\" : class_weight_dict, #\n",
    "                      \"batch_size\" : 16,                                                                #\n",
    "                      \"epochs\" : 160,                                                                   #\n",
    "                      \"define_callbacks\" : [\"early_stopping\", \"model_checkpoint\"],                      #\n",
    "                      \"patience_early_stopping\" : 14,                                                   #\n",
    "                      \"test_size\" : 0.3                                                                 #\n",
    "                     }                                                                                  #\n",
    "#########################################################################################################\n",
    "\n",
    "######################################################################################################\n",
    "###################################### CLASES NO BALANCEADAS #########################################\n",
    "######################################################################################################\n",
    "                                                                                                     #\n",
    "# Reduce_lr en callbacks                                                                             #  \n",
    "hiper_params_test7_30 = {\"class_weight\" : {0: 1, 1: 1},                                              #\n",
    "                      \"batch_size\" : 16,                                                             #\n",
    "                      \"epochs\" : 160,                                                                #\n",
    "                      \"define_callbacks\" : [\"reduce_lr\", \"early_stopping\", \"model_checkpoint\"],      #\n",
    "                      \"patience_early_stopping\" : 14,                                                #\n",
    "                      \"patience_reduce_lr\" : 8,                                                     #\n",
    "                      \"test_size\" : 0.3                                                              #\n",
    "                     }                                                                               #\n",
    "                                                                                                     #\n",
    "# SIN reduce_lr en callbacks                                                                         #      \n",
    "hiper_params_test8_30 = {\"class_weight\" : {0: 1, 1: 1},                                              #\n",
    "                      \"batch_size\" : 16,                                                             #\n",
    "                      \"epochs\" : 160,                                                                #\n",
    "                      \"define_callbacks\" : [\"early_stopping\", \"model_checkpoint\"],                   #\n",
    "                      \"patience_early_stopping\" : 14,                                                #\n",
    "                      \"test_size\" : 0.3                                                              #\n",
    "                     }                                                                               #\n",
    "######################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Hiperparámetros para pruebas: aumento patience en early stopping = 20 y LR descendiente = 10, split de 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################################################\n",
    "########################################## CLASES BALANCEADAS ###########################################\n",
    "#########################################################################################################\n",
    "                                                                                                        #\n",
    "# reduce_lr en callbacks                                                                                #                            \n",
    "hiper_params_test9_20 = {\"class_weight\" : class_weight_dict, #\n",
    "                      \"batch_size\" : 32,                                                                #\n",
    "                      \"epochs\" : 160,                                                                   #\n",
    "                      \"define_callbacks\" : [\"reduce_lr\", \"early_stopping\", \"model_checkpoint\"],         #\n",
    "                      \"patience_early_stopping\" : 20,                                                   #\n",
    "                      \"patience_reduce_lr\" : 10,                                                        #\n",
    "                      \"test_size\" : 0.2                                                                 #\n",
    "                     }                                                                                  #\n",
    "                                                                                                        #\n",
    "# SIN reduce_lr en callbacks                                                                            #\n",
    "hiper_params_test10_20 = {\"class_weight\" : class_weight_dict, #\n",
    "                      \"batch_size\" : 32,                                                                #\n",
    "                      \"epochs\" : 160,                                                                   #\n",
    "                      \"define_callbacks\" : [\"early_stopping\", \"model_checkpoint\"],                      #\n",
    "                      \"patience_early_stopping\" : 20,                                                   #\n",
    "                      \"test_size\" : 0.2                                                                 #\n",
    "                     }                                                                                  #\n",
    "#########################################################################################################\n",
    "\n",
    "#########################################################################################################\n",
    "####################################### CLASES NO BALANCEADAS ###########################################\n",
    "#########################################################################################################\n",
    "                                                                                                        #\n",
    "# Reduce_lr en callbacks                                                                                #\n",
    "hiper_params_test11_20 = {\"class_weight\" : {0: 1, 1: 1},                                                 #\n",
    "                      \"batch_size\" : 32,                                                                #\n",
    "                      \"epochs\" : 160,                                                                   #\n",
    "                      \"define_callbacks\" : [\"reduce_lr\", \"early_stopping\", \"model_checkpoint\"],         #\n",
    "                      \"patience_early_stopping\" : 20,                                                   #\n",
    "                      \"patience_reduce_lr\" : 10,                                                        #\n",
    "                      \"test_size\" : 0.2                                                                 #\n",
    "                     }                                                                                  #\n",
    "#SIN Reduce_lr en callbacks                                                                             #\n",
    "hiper_params_test12_20 = {\"class_weight\" : {0: 1, 1: 1},                                                 #\n",
    "                      \"batch_size\" : 32,                                                                #\n",
    "                      \"epochs\" : 160,                                                                   #\n",
    "                      \"define_callbacks\" : [\"early_stopping\", \"model_checkpoint\"],                      #\n",
    "                      \"patience_early_stopping\" : 14,                                                   #\n",
    "                      \"test_size\" : 0.2                                                                 #\n",
    "                     }                                                                                  #\n",
    "#########################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Hiperparámetros para pruebas: aumento patience en early stopping = 20 y LR descendiente = 10, split de 30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################################################\n",
    "###################################### CLASES BALANCEADAS ###############################################\n",
    "#########################################################################################################\n",
    "                                                                                                        #\n",
    "# Reduce_lr en callbacks                                                                                #\n",
    "hiper_params_test9_30 = {\"class_weight\" : class_weight_dict, #\n",
    "                      \"batch_size\" : 16,                                                                #\n",
    "                      \"epochs\" : 160,                                                                   #\n",
    "                      \"define_callbacks\" : [\"reduce_lr\", \"early_stopping\", \"model_checkpoint\"],         #\n",
    "                      \"patience_early_stopping\" : 20,                                                   #\n",
    "                      \"patience_reduce_lr\" : 10,                                                        #\n",
    "                      \"test_size\" : 0.3                                                                 #\n",
    "                     }                                                                                  #         \n",
    "                                                                                                        #\n",
    "# SIN reduce_lr en callbacks                                                                            #   \n",
    "hiper_params_test10_30 = {\"class_weight\" : class_weight_dict, #\n",
    "                      \"batch_size\" : 16,                                                                #\n",
    "                      \"epochs\" : 160,                                                                   #\n",
    "                      \"define_callbacks\" : [\"early_stopping\", \"model_checkpoint\"],                      #\n",
    "                      \"patience_early_stopping\" : 14,                                                   #\n",
    "                      \"test_size\" : 0.3                                                                 #\n",
    "                     }                                                                                  #\n",
    "#########################################################################################################\n",
    "\n",
    "######################################################################################################\n",
    "###################################### CLASES NO BALANCEADAS #########################################\n",
    "######################################################################################################\n",
    "                                                                                                     #\n",
    "# Reduce_lr en callbacks                                                                             #  \n",
    "hiper_params_test11_30 = {\"class_weight\" : {0: 1, 1: 1},                                              #\n",
    "                      \"batch_size\" : 16,                                                             #\n",
    "                      \"epochs\" : 160,                                                                #\n",
    "                      \"define_callbacks\" : [\"reduce_lr\", \"early_stopping\", \"model_checkpoint\"],      #\n",
    "                      \"patience_early_stopping\" : 20,                                                #\n",
    "                      \"patience_reduce_lr\" : 10,                                                     #\n",
    "                      \"test_size\" : 0.3                                                              #\n",
    "                     }                                                                               #\n",
    "                                                                                                     #\n",
    "# SIN reduce_lr en callbacks                                                                         #      \n",
    "hiper_params_test12_30 = {\"class_weight\" : {0: 1, 1: 1},                                              #\n",
    "                      \"batch_size\" : 16,                                                             #\n",
    "                      \"epochs\" : 160,                                                                #\n",
    "                      \"define_callbacks\" : [\"early_stopping\", \"model_checkpoint\"],                   #\n",
    "                      \"patience_early_stopping\" : 20,                                                #\n",
    "                      \"test_size\" : 0.3                                                              #\n",
    "                     }                                                                               #\n",
    "######################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Generamos una lista con todos los hiperparámetros definidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiperparametros_20 = [hiper_params_test1_20, hiper_params_test2_20, hiper_params_test3_20, hiper_params_test4_20]\n",
    "hiperparametros_30 = [hiper_params_test1_30, hiper_params_test2_30, hiper_params_test3_30, hiper_params_test4_30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiperparametros_20_modified = [hiper_params_test5_20, hiper_params_test6_20, hiper_params_test7_20, hiper_params_test8_20]\n",
    "hiperparametros_30_modified = [hiper_params_test5_30, hiper_params_test6_30, hiper_params_test7_30, hiper_params_test8_30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiperparametros_20_max_patience = [hiper_params_test9_20, hiper_params_test10_20, hiper_params_test11_20, hiper_params_test12_20]\n",
    "hiperparametros_30_max_patience = [hiper_params_test9_30, hiper_params_test10_30, hiper_params_test11_30, hiper_params_test12_30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento de las diferentes arquitecturas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de modelos construidos = 6 pruebas * 4 hiperparámetros/prueba * 2 semillas distintas * 4 arquitecturas distintas = 192 modelos construidos. 48 modelos por cada arquitectura.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total de modelos construidos = 6 pruebas * 4 hiperparámetros/prueba * 2 semillas distintas * 4 arquitecturas distintas = {6*4*2*4} modelos construidos. 48 modelos por cada arquitectura.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = [\n",
    "    [\"split_20\",hiperparametros_20],\n",
    "    [\"split_30\",hiperparametros_30],\n",
    "    [\"split_20_increase_patience\",hiperparametros_20_modified],\n",
    "    [\"split_30_increase_patience\",hiperparametros_30_modified],\n",
    "    [\"split_20_max_patience\",hiperparametros_20_max_patience],\n",
    "    [\"split_30_max_patience\",hiperparametros_30_max_patience]\n",
    "]\n",
    "input_shape = (48,48,12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raulpg/anaconda3/envs/tfm_tf/lib/python3.11/site-packages/keras/src/preprocessing/image.py:2093: UserWarning: Expected input to be images (as Numpy array) following the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3 or 4 channels on axis 3. However, it was passed an array with shape (2865, 48, 48, 12) (12 channels).\n",
      "  warnings.warn(\n",
      "/home/raulpg/anaconda3/envs/tfm_tf/lib/python3.11/site-packages/keras/src/preprocessing/image.py:766: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3, or 4 channels on axis 3. However, it was passed an array with shape (2865, 48, 48, 12) (12 channels).\n",
      "  warnings.warn(\n",
      "/home/raulpg/anaconda3/envs/tfm_tf/lib/python3.11/site-packages/keras/src/preprocessing/image.py:766: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3, or 4 channels on axis 3. However, it was passed an array with shape (1229, 48, 48, 12) (12 channels).\n",
      "  warnings.warn(\n",
      "2024-09-23 08:11:57.537064: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-09-23 08:11:57.555511: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-09-23 08:11:57.555551: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-09-23 08:11:57.561638: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-09-23 08:11:57.561671: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-09-23 08:11:57.561686: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-09-23 08:11:57.675295: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-09-23 08:11:57.675331: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-09-23 08:11:57.675336: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-09-23 08:11:57.675346: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:236] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-09-23 08:11:57.675436: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-09-23 08:11:57.675452: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5529 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Ti, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Epoch 1/160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-23 08:11:59.268040: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n",
      "2024-09-23 08:11:59.333084: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-09-23 08:11:59.698462: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-09-23 08:12:00.292215: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f7c7abb7690 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-09-23 08:12:00.292249: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4060 Ti, Compute Capability 8.9\n",
      "2024-09-23 08:12:00.303622: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1727071920.374521 1582440 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178/180 [============================>.] - ETA: 0s - loss: 0.6823 - acc: 0.5782\n",
      "Epoch 1: val_loss improved from inf to 0.66626, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 7s 23ms/step - loss: 0.6822 - acc: 0.5801 - val_loss: 0.6663 - val_acc: 0.5858 - lr: 3.0000e-04\n",
      "Epoch 2/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.6123 - acc: 0.6961\n",
      "Epoch 2: val_loss improved from 0.66626 to 0.51234, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.6117 - acc: 0.6967 - val_loss: 0.5123 - val_acc: 0.7396 - lr: 3.0000e-04\n",
      "Epoch 3/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.5563 - acc: 0.7420\n",
      "Epoch 3: val_loss did not improve from 0.51234\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.5563 - acc: 0.7417 - val_loss: 0.5756 - val_acc: 0.7136 - lr: 3.0000e-04\n",
      "Epoch 4/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.5379 - acc: 0.7508\n",
      "Epoch 4: val_loss improved from 0.51234 to 0.50853, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.5389 - acc: 0.7504 - val_loss: 0.5085 - val_acc: 0.7413 - lr: 3.0000e-04\n",
      "Epoch 5/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.5299 - acc: 0.7406\n",
      "Epoch 5: val_loss improved from 0.50853 to 0.47889, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.5321 - acc: 0.7400 - val_loss: 0.4789 - val_acc: 0.7657 - lr: 3.0000e-04\n",
      "Epoch 6/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.5284 - acc: 0.7543\n",
      "Epoch 6: val_loss did not improve from 0.47889\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.5257 - acc: 0.7564 - val_loss: 0.4984 - val_acc: 0.7689 - lr: 3.0000e-04\n",
      "Epoch 7/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.5692 - acc: 0.7211\n",
      "Epoch 7: val_loss did not improve from 0.47889\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.5682 - acc: 0.7225 - val_loss: 0.5164 - val_acc: 0.7567 - lr: 3.0000e-04\n",
      "Epoch 8/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.5112 - acc: 0.7642\n",
      "Epoch 8: val_loss improved from 0.47889 to 0.47321, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.5094 - acc: 0.7651 - val_loss: 0.4732 - val_acc: 0.7526 - lr: 3.0000e-04\n",
      "Epoch 9/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.5112 - acc: 0.7533\n",
      "Epoch 9: val_loss did not improve from 0.47321\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.5089 - acc: 0.7550 - val_loss: 0.5032 - val_acc: 0.7608 - lr: 3.0000e-04\n",
      "Epoch 10/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.4990 - acc: 0.7734\n",
      "Epoch 10: val_loss did not improve from 0.47321\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.4995 - acc: 0.7728 - val_loss: 0.5055 - val_acc: 0.7665 - lr: 3.0000e-04\n",
      "Epoch 11/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.4915 - acc: 0.7663\n",
      "Epoch 11: val_loss improved from 0.47321 to 0.43115, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.4918 - acc: 0.7658 - val_loss: 0.4311 - val_acc: 0.7958 - lr: 3.0000e-04\n",
      "Epoch 12/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.4664 - acc: 0.7822\n",
      "Epoch 12: val_loss did not improve from 0.43115\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.4648 - acc: 0.7832 - val_loss: 0.4729 - val_acc: 0.7567 - lr: 3.0000e-04\n",
      "Epoch 13/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.4485 - acc: 0.7924\n",
      "Epoch 13: val_loss did not improve from 0.43115\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.4477 - acc: 0.7923 - val_loss: 0.4441 - val_acc: 0.8031 - lr: 3.0000e-04\n",
      "Epoch 14/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.4285 - acc: 0.8052\n",
      "Epoch 14: val_loss did not improve from 0.43115\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.4283 - acc: 0.8045 - val_loss: 0.4421 - val_acc: 0.7795 - lr: 3.0000e-04\n",
      "Epoch 15/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.4233 - acc: 0.8080\n",
      "Epoch 15: val_loss improved from 0.43115 to 0.42515, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.4238 - acc: 0.8080 - val_loss: 0.4251 - val_acc: 0.8047 - lr: 3.0000e-04\n",
      "Epoch 16/160\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.4310 - acc: 0.8038\n",
      "Epoch 16: val_loss improved from 0.42515 to 0.41924, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.4310 - acc: 0.8038 - val_loss: 0.4192 - val_acc: 0.7982 - lr: 3.0000e-04\n",
      "Epoch 17/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.3985 - acc: 0.8210\n",
      "Epoch 17: val_loss did not improve from 0.41924\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.3983 - acc: 0.8216 - val_loss: 0.4587 - val_acc: 0.7901 - lr: 3.0000e-04\n",
      "Epoch 18/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.3934 - acc: 0.8277\n",
      "Epoch 18: val_loss did not improve from 0.41924\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.3946 - acc: 0.8262 - val_loss: 0.4851 - val_acc: 0.7469 - lr: 3.0000e-04\n",
      "Epoch 19/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.3893 - acc: 0.8239\n",
      "Epoch 19: val_loss did not improve from 0.41924\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.3909 - acc: 0.8234 - val_loss: 0.4747 - val_acc: 0.7795 - lr: 3.0000e-04\n",
      "Epoch 20/160\n",
      "179/180 [============================>.] - ETA: 0s - loss: 0.3795 - acc: 0.8329\n",
      "Epoch 20: val_loss improved from 0.41924 to 0.38135, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.3786 - acc: 0.8335 - val_loss: 0.3814 - val_acc: 0.8031 - lr: 3.0000e-04\n",
      "Epoch 21/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.3753 - acc: 0.8334\n",
      "Epoch 21: val_loss improved from 0.38135 to 0.36901, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.3769 - acc: 0.8321 - val_loss: 0.3690 - val_acc: 0.8275 - lr: 3.0000e-04\n",
      "Epoch 22/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.3633 - acc: 0.8475\n",
      "Epoch 22: val_loss did not improve from 0.36901\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.3632 - acc: 0.8475 - val_loss: 0.4186 - val_acc: 0.8031 - lr: 3.0000e-04\n",
      "Epoch 23/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.3942 - acc: 0.8295\n",
      "Epoch 23: val_loss did not improve from 0.36901\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.3933 - acc: 0.8293 - val_loss: 0.4005 - val_acc: 0.8161 - lr: 3.0000e-04\n",
      "Epoch 24/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.3523 - acc: 0.8500\n",
      "Epoch 24: val_loss improved from 0.36901 to 0.35150, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.3548 - acc: 0.8485 - val_loss: 0.3515 - val_acc: 0.8291 - lr: 3.0000e-04\n",
      "Epoch 25/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.3429 - acc: 0.8581\n",
      "Epoch 25: val_loss did not improve from 0.35150\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.3427 - acc: 0.8583 - val_loss: 0.3577 - val_acc: 0.8283 - lr: 3.0000e-04\n",
      "Epoch 26/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.3358 - acc: 0.8542\n",
      "Epoch 26: val_loss improved from 0.35150 to 0.32570, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.3343 - acc: 0.8548 - val_loss: 0.3257 - val_acc: 0.8568 - lr: 3.0000e-04\n",
      "Epoch 27/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.3314 - acc: 0.8577\n",
      "Epoch 27: val_loss improved from 0.32570 to 0.31866, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.3297 - acc: 0.8590 - val_loss: 0.3187 - val_acc: 0.8641 - lr: 3.0000e-04\n",
      "Epoch 28/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.3064 - acc: 0.8662\n",
      "Epoch 28: val_loss improved from 0.31866 to 0.31129, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.3065 - acc: 0.8663 - val_loss: 0.3113 - val_acc: 0.8617 - lr: 3.0000e-04\n",
      "Epoch 29/160\n",
      "179/180 [============================>.] - ETA: 0s - loss: 0.3121 - acc: 0.8624\n",
      "Epoch 29: val_loss improved from 0.31129 to 0.30519, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.3108 - acc: 0.8632 - val_loss: 0.3052 - val_acc: 0.8617 - lr: 3.0000e-04\n",
      "Epoch 30/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.3164 - acc: 0.8602\n",
      "Epoch 30: val_loss did not improve from 0.30519\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.3163 - acc: 0.8604 - val_loss: 0.3250 - val_acc: 0.8421 - lr: 3.0000e-04\n",
      "Epoch 31/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.3221 - acc: 0.8645\n",
      "Epoch 31: val_loss did not improve from 0.30519\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.3207 - acc: 0.8656 - val_loss: 0.3057 - val_acc: 0.8617 - lr: 3.0000e-04\n",
      "Epoch 32/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.3176 - acc: 0.8719\n",
      "Epoch 32: val_loss did not improve from 0.30519\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.3162 - acc: 0.8719 - val_loss: 0.3176 - val_acc: 0.8576 - lr: 3.0000e-04\n",
      "Epoch 33/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2962 - acc: 0.8712\n",
      "Epoch 33: val_loss did not improve from 0.30519\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.2963 - acc: 0.8709 - val_loss: 0.3061 - val_acc: 0.8568 - lr: 3.0000e-04\n",
      "Epoch 34/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.2849 - acc: 0.8849\n",
      "Epoch 34: val_loss did not improve from 0.30519\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2852 - acc: 0.8848 - val_loss: 0.3076 - val_acc: 0.8657 - lr: 3.0000e-04\n",
      "Epoch 35/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2911 - acc: 0.8793\n",
      "Epoch 35: val_loss improved from 0.30519 to 0.28271, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.2904 - acc: 0.8799 - val_loss: 0.2827 - val_acc: 0.8714 - lr: 3.0000e-04\n",
      "Epoch 36/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.2696 - acc: 0.8931\n",
      "Epoch 36: val_loss did not improve from 0.28271\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.2709 - acc: 0.8921 - val_loss: 0.2969 - val_acc: 0.8836 - lr: 3.0000e-04\n",
      "Epoch 37/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.2918 - acc: 0.8778\n",
      "Epoch 37: val_loss improved from 0.28271 to 0.27290, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.2915 - acc: 0.8785 - val_loss: 0.2729 - val_acc: 0.8910 - lr: 3.0000e-04\n",
      "Epoch 38/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.3105 - acc: 0.8789\n",
      "Epoch 38: val_loss improved from 0.27290 to 0.26009, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.3106 - acc: 0.8792 - val_loss: 0.2601 - val_acc: 0.8885 - lr: 3.0000e-04\n",
      "Epoch 39/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.2499 - acc: 0.8995\n",
      "Epoch 39: val_loss did not improve from 0.26009\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2507 - acc: 0.9002 - val_loss: 0.2807 - val_acc: 0.8739 - lr: 3.0000e-04\n",
      "Epoch 40/160\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.2755 - acc: 0.8848\n",
      "Epoch 40: val_loss did not improve from 0.26009\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.2755 - acc: 0.8848 - val_loss: 0.2725 - val_acc: 0.8869 - lr: 3.0000e-04\n",
      "Epoch 41/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2587 - acc: 0.8987\n",
      "Epoch 41: val_loss improved from 0.26009 to 0.25058, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2600 - acc: 0.8984 - val_loss: 0.2506 - val_acc: 0.8991 - lr: 3.0000e-04\n",
      "Epoch 42/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2658 - acc: 0.8930\n",
      "Epoch 42: val_loss did not improve from 0.25058\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.2641 - acc: 0.8942 - val_loss: 0.2864 - val_acc: 0.8820 - lr: 3.0000e-04\n",
      "Epoch 43/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2512 - acc: 0.8983\n",
      "Epoch 43: val_loss did not improve from 0.25058\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.2515 - acc: 0.8981 - val_loss: 0.2609 - val_acc: 0.8926 - lr: 3.0000e-04\n",
      "Epoch 44/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2470 - acc: 0.8990\n",
      "Epoch 44: val_loss did not improve from 0.25058\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.2469 - acc: 0.8991 - val_loss: 0.2620 - val_acc: 0.8934 - lr: 3.0000e-04\n",
      "Epoch 45/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2288 - acc: 0.9114\n",
      "Epoch 45: val_loss did not improve from 0.25058\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.2303 - acc: 0.9110 - val_loss: 0.3209 - val_acc: 0.8462 - lr: 3.0000e-04\n",
      "Epoch 46/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2350 - acc: 0.9058\n",
      "Epoch 46: val_loss did not improve from 0.25058\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.2345 - acc: 0.9058 - val_loss: 0.2697 - val_acc: 0.8885 - lr: 3.0000e-04\n",
      "Epoch 47/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2407 - acc: 0.9033\n",
      "Epoch 47: val_loss improved from 0.25058 to 0.22875, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2414 - acc: 0.9037 - val_loss: 0.2288 - val_acc: 0.9024 - lr: 3.0000e-04\n",
      "Epoch 48/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2482 - acc: 0.9043\n",
      "Epoch 48: val_loss did not improve from 0.22875\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2467 - acc: 0.9054 - val_loss: 0.2909 - val_acc: 0.8779 - lr: 3.0000e-04\n",
      "Epoch 49/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2510 - acc: 0.9008\n",
      "Epoch 49: val_loss did not improve from 0.22875\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2498 - acc: 0.9016 - val_loss: 0.2941 - val_acc: 0.8926 - lr: 3.0000e-04\n",
      "Epoch 50/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2331 - acc: 0.9068\n",
      "Epoch 50: val_loss did not improve from 0.22875\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2320 - acc: 0.9075 - val_loss: 0.2375 - val_acc: 0.9089 - lr: 3.0000e-04\n",
      "Epoch 51/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2583 - acc: 0.8990\n",
      "Epoch 51: val_loss did not improve from 0.22875\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2579 - acc: 0.8991 - val_loss: 0.2613 - val_acc: 0.8910 - lr: 3.0000e-04\n",
      "Epoch 52/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.2343 - acc: 0.9070\n",
      "Epoch 52: val_loss improved from 0.22875 to 0.22756, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.2339 - acc: 0.9065 - val_loss: 0.2276 - val_acc: 0.9056 - lr: 3.0000e-04\n",
      "Epoch 53/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2351 - acc: 0.9040\n",
      "Epoch 53: val_loss did not improve from 0.22756\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2350 - acc: 0.9040 - val_loss: 0.2480 - val_acc: 0.8967 - lr: 3.0000e-04\n",
      "Epoch 54/160\n",
      "179/180 [============================>.] - ETA: 0s - loss: 0.2399 - acc: 0.9000\n",
      "Epoch 54: val_loss did not improve from 0.22756\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2407 - acc: 0.8995 - val_loss: 0.2762 - val_acc: 0.8918 - lr: 3.0000e-04\n",
      "Epoch 55/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2264 - acc: 0.9153\n",
      "Epoch 55: val_loss did not improve from 0.22756\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2268 - acc: 0.9148 - val_loss: 0.2632 - val_acc: 0.9056 - lr: 3.0000e-04\n",
      "Epoch 56/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2169 - acc: 0.9174\n",
      "Epoch 56: val_loss did not improve from 0.22756\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.2147 - acc: 0.9183 - val_loss: 0.2301 - val_acc: 0.8999 - lr: 3.0000e-04\n",
      "Epoch 57/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.2369 - acc: 0.8992\n",
      "Epoch 57: val_loss did not improve from 0.22756\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.2367 - acc: 0.8991 - val_loss: 0.2871 - val_acc: 0.8714 - lr: 3.0000e-04\n",
      "Epoch 58/160\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.2222 - acc: 0.9103\n",
      "Epoch 58: val_loss did not improve from 0.22756\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.2222 - acc: 0.9103 - val_loss: 0.2514 - val_acc: 0.8877 - lr: 3.0000e-04\n",
      "Epoch 59/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2191 - acc: 0.9142\n",
      "Epoch 59: val_loss improved from 0.22756 to 0.21112, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2192 - acc: 0.9145 - val_loss: 0.2111 - val_acc: 0.9113 - lr: 3.0000e-04\n",
      "Epoch 60/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2061 - acc: 0.9248\n",
      "Epoch 60: val_loss did not improve from 0.21112\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.2080 - acc: 0.9236 - val_loss: 0.2380 - val_acc: 0.9064 - lr: 3.0000e-04\n",
      "Epoch 61/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2091 - acc: 0.9146\n",
      "Epoch 61: val_loss did not improve from 0.21112\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.2100 - acc: 0.9131 - val_loss: 0.3436 - val_acc: 0.8649 - lr: 3.0000e-04\n",
      "Epoch 62/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2127 - acc: 0.9188\n",
      "Epoch 62: val_loss did not improve from 0.21112\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.2131 - acc: 0.9187 - val_loss: 0.2180 - val_acc: 0.9113 - lr: 3.0000e-04\n",
      "Epoch 63/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2083 - acc: 0.9167\n",
      "Epoch 63: val_loss did not improve from 0.21112\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.2093 - acc: 0.9159 - val_loss: 0.2430 - val_acc: 0.8959 - lr: 3.0000e-04\n",
      "Epoch 64/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2046 - acc: 0.9234\n",
      "Epoch 64: val_loss improved from 0.21112 to 0.20554, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2038 - acc: 0.9243 - val_loss: 0.2055 - val_acc: 0.9138 - lr: 3.0000e-04\n",
      "Epoch 65/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.3425 - acc: 0.8941\n",
      "Epoch 65: val_loss did not improve from 0.20554\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.3409 - acc: 0.8942 - val_loss: 0.3509 - val_acc: 0.8584 - lr: 3.0000e-04\n",
      "Epoch 66/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2358 - acc: 0.9086\n",
      "Epoch 66: val_loss did not improve from 0.20554\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.2355 - acc: 0.9089 - val_loss: 0.2466 - val_acc: 0.8950 - lr: 3.0000e-04\n",
      "Epoch 67/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2232 - acc: 0.9093\n",
      "Epoch 67: val_loss did not improve from 0.20554\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2224 - acc: 0.9099 - val_loss: 0.3631 - val_acc: 0.8592 - lr: 3.0000e-04\n",
      "Epoch 68/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2003 - acc: 0.9223\n",
      "Epoch 68: val_loss did not improve from 0.20554\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1993 - acc: 0.9225 - val_loss: 0.2400 - val_acc: 0.9007 - lr: 3.0000e-04\n",
      "Epoch 69/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1985 - acc: 0.9206\n",
      "Epoch 69: val_loss did not improve from 0.20554\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.1970 - acc: 0.9211 - val_loss: 0.2319 - val_acc: 0.9048 - lr: 3.0000e-04\n",
      "Epoch 70/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1960 - acc: 0.9238\n",
      "Epoch 70: val_loss did not improve from 0.20554\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.1967 - acc: 0.9239 - val_loss: 0.2147 - val_acc: 0.9154 - lr: 3.0000e-04\n",
      "Epoch 71/160\n",
      "179/180 [============================>.] - ETA: 0s - loss: 0.1866 - acc: 0.9291\n",
      "Epoch 71: val_loss did not improve from 0.20554\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.1861 - acc: 0.9291 - val_loss: 0.2568 - val_acc: 0.8967 - lr: 3.0000e-04\n",
      "Epoch 72/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1992 - acc: 0.9245\n",
      "Epoch 72: val_loss did not improve from 0.20554\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.2010 - acc: 0.9239 - val_loss: 0.2249 - val_acc: 0.9056 - lr: 3.0000e-04\n",
      "Epoch 73/160\n",
      "179/180 [============================>.] - ETA: 0s - loss: 0.1867 - acc: 0.9277\n",
      "Epoch 73: val_loss improved from 0.20554 to 0.18756, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1861 - acc: 0.9281 - val_loss: 0.1876 - val_acc: 0.9227 - lr: 3.0000e-04\n",
      "Epoch 74/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1755 - acc: 0.9354\n",
      "Epoch 74: val_loss did not improve from 0.18756\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.1746 - acc: 0.9358 - val_loss: 0.2225 - val_acc: 0.9154 - lr: 3.0000e-04\n",
      "Epoch 75/160\n",
      "179/180 [============================>.] - ETA: 0s - loss: 0.1859 - acc: 0.9263\n",
      "Epoch 75: val_loss did not improve from 0.18756\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.1867 - acc: 0.9260 - val_loss: 0.2116 - val_acc: 0.9154 - lr: 3.0000e-04\n",
      "Epoch 76/160\n",
      "179/180 [============================>.] - ETA: 0s - loss: 0.2100 - acc: 0.9270\n",
      "Epoch 76: val_loss did not improve from 0.18756\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.2102 - acc: 0.9271 - val_loss: 0.2209 - val_acc: 0.9121 - lr: 3.0000e-04\n",
      "Epoch 77/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1967 - acc: 0.9230\n",
      "Epoch 77: val_loss did not improve from 0.18756\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.2000 - acc: 0.9229 - val_loss: 0.2565 - val_acc: 0.8983 - lr: 3.0000e-04\n",
      "Epoch 78/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1808 - acc: 0.9252\n",
      "Epoch 78: val_loss did not improve from 0.18756\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1795 - acc: 0.9260 - val_loss: 0.2293 - val_acc: 0.9186 - lr: 3.0000e-04\n",
      "Epoch 79/160\n",
      "179/180 [============================>.] - ETA: 0s - loss: 0.1817 - acc: 0.9294\n",
      "Epoch 79: val_loss did not improve from 0.18756\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1832 - acc: 0.9288 - val_loss: 0.2116 - val_acc: 0.9154 - lr: 3.0000e-04\n",
      "Epoch 80/160\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.1712 - acc: 0.9379\n",
      "Epoch 80: val_loss did not improve from 0.18756\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.1712 - acc: 0.9379 - val_loss: 0.1964 - val_acc: 0.9235 - lr: 3.0000e-04\n",
      "Epoch 81/160\n",
      "179/180 [============================>.] - ETA: 0s - loss: 0.1777 - acc: 0.9309\n",
      "Epoch 81: val_loss improved from 0.18756 to 0.18500, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1782 - acc: 0.9305 - val_loss: 0.1850 - val_acc: 0.9219 - lr: 3.0000e-04\n",
      "Epoch 82/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1757 - acc: 0.9329\n",
      "Epoch 82: val_loss did not improve from 0.18500\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1752 - acc: 0.9330 - val_loss: 0.2138 - val_acc: 0.9121 - lr: 3.0000e-04\n",
      "Epoch 83/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1828 - acc: 0.9280\n",
      "Epoch 83: val_loss did not improve from 0.18500\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1826 - acc: 0.9281 - val_loss: 0.1898 - val_acc: 0.9251 - lr: 3.0000e-04\n",
      "Epoch 84/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1677 - acc: 0.9361\n",
      "Epoch 84: val_loss did not improve from 0.18500\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.1672 - acc: 0.9361 - val_loss: 0.2223 - val_acc: 0.9121 - lr: 3.0000e-04\n",
      "Epoch 85/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1651 - acc: 0.9361\n",
      "Epoch 85: val_loss did not improve from 0.18500\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1635 - acc: 0.9368 - val_loss: 0.2270 - val_acc: 0.9072 - lr: 3.0000e-04\n",
      "Epoch 86/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1686 - acc: 0.9343\n",
      "Epoch 86: val_loss did not improve from 0.18500\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1679 - acc: 0.9344 - val_loss: 0.2135 - val_acc: 0.9178 - lr: 3.0000e-04\n",
      "Epoch 87/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1720 - acc: 0.9421\n",
      "Epoch 87: val_loss did not improve from 0.18500\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.1720 - acc: 0.9417 - val_loss: 0.2203 - val_acc: 0.9089 - lr: 3.0000e-04\n",
      "Epoch 88/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1935 - acc: 0.9322\n",
      "Epoch 88: val_loss improved from 0.18500 to 0.18346, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1936 - acc: 0.9323 - val_loss: 0.1835 - val_acc: 0.9308 - lr: 3.0000e-04\n",
      "Epoch 89/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1580 - acc: 0.9393\n",
      "Epoch 89: val_loss did not improve from 0.18346\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1581 - acc: 0.9393 - val_loss: 0.1887 - val_acc: 0.9260 - lr: 3.0000e-04\n",
      "Epoch 90/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1765 - acc: 0.9336\n",
      "Epoch 90: val_loss did not improve from 0.18346\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1774 - acc: 0.9333 - val_loss: 0.2260 - val_acc: 0.9064 - lr: 3.0000e-04\n",
      "Epoch 91/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1623 - acc: 0.9411\n",
      "Epoch 91: val_loss did not improve from 0.18346\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1639 - acc: 0.9400 - val_loss: 0.1911 - val_acc: 0.9178 - lr: 3.0000e-04\n",
      "Epoch 92/160\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.1767 - acc: 0.9347\n",
      "Epoch 92: val_loss did not improve from 0.18346\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1767 - acc: 0.9347 - val_loss: 0.2403 - val_acc: 0.9089 - lr: 3.0000e-04\n",
      "Epoch 93/160\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.1617 - acc: 0.9393\n",
      "Epoch 93: val_loss did not improve from 0.18346\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1617 - acc: 0.9393 - val_loss: 0.2183 - val_acc: 0.9072 - lr: 3.0000e-04\n",
      "Epoch 94/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1735 - acc: 0.9333\n",
      "Epoch 94: val_loss improved from 0.18346 to 0.17656, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1730 - acc: 0.9337 - val_loss: 0.1766 - val_acc: 0.9162 - lr: 3.0000e-04\n",
      "Epoch 95/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1468 - acc: 0.9460\n",
      "Epoch 95: val_loss did not improve from 0.17656\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1470 - acc: 0.9459 - val_loss: 0.2319 - val_acc: 0.9170 - lr: 3.0000e-04\n",
      "Epoch 96/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1494 - acc: 0.9421\n",
      "Epoch 96: val_loss did not improve from 0.17656\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1495 - acc: 0.9421 - val_loss: 0.2188 - val_acc: 0.9333 - lr: 3.0000e-04\n",
      "Epoch 97/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1743 - acc: 0.9308\n",
      "Epoch 97: val_loss did not improve from 0.17656\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.1739 - acc: 0.9309 - val_loss: 0.2261 - val_acc: 0.9105 - lr: 3.0000e-04\n",
      "Epoch 98/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1775 - acc: 0.9322\n",
      "Epoch 98: val_loss improved from 0.17656 to 0.17566, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1771 - acc: 0.9326 - val_loss: 0.1757 - val_acc: 0.9203 - lr: 3.0000e-04\n",
      "Epoch 99/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1449 - acc: 0.9453\n",
      "Epoch 99: val_loss did not improve from 0.17566\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1439 - acc: 0.9459 - val_loss: 0.1969 - val_acc: 0.9146 - lr: 3.0000e-04\n",
      "Epoch 100/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1679 - acc: 0.9336\n",
      "Epoch 100: val_loss did not improve from 0.17566\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1669 - acc: 0.9340 - val_loss: 0.1798 - val_acc: 0.9308 - lr: 3.0000e-04\n",
      "Epoch 101/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1502 - acc: 0.9428\n",
      "Epoch 101: val_loss did not improve from 0.17566\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1491 - acc: 0.9435 - val_loss: 0.1899 - val_acc: 0.9268 - lr: 3.0000e-04\n",
      "Epoch 102/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1441 - acc: 0.9474\n",
      "Epoch 102: val_loss improved from 0.17566 to 0.17318, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1436 - acc: 0.9476 - val_loss: 0.1732 - val_acc: 0.9300 - lr: 3.0000e-04\n",
      "Epoch 103/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1620 - acc: 0.9347\n",
      "Epoch 103: val_loss did not improve from 0.17318\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1620 - acc: 0.9351 - val_loss: 0.2038 - val_acc: 0.9260 - lr: 3.0000e-04\n",
      "Epoch 104/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1369 - acc: 0.9488\n",
      "Epoch 104: val_loss did not improve from 0.17318\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.1364 - acc: 0.9487 - val_loss: 0.1962 - val_acc: 0.9284 - lr: 3.0000e-04\n",
      "Epoch 105/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1484 - acc: 0.9403\n",
      "Epoch 105: val_loss did not improve from 0.17318\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1489 - acc: 0.9400 - val_loss: 0.1770 - val_acc: 0.9373 - lr: 3.0000e-04\n",
      "Epoch 106/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1419 - acc: 0.9492\n",
      "Epoch 106: val_loss improved from 0.17318 to 0.17116, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1413 - acc: 0.9490 - val_loss: 0.1712 - val_acc: 0.9292 - lr: 3.0000e-04\n",
      "Epoch 107/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1480 - acc: 0.9502\n",
      "Epoch 107: val_loss did not improve from 0.17116\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1475 - acc: 0.9504 - val_loss: 0.2152 - val_acc: 0.9186 - lr: 3.0000e-04\n",
      "Epoch 108/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1576 - acc: 0.9411\n",
      "Epoch 108: val_loss did not improve from 0.17116\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1574 - acc: 0.9414 - val_loss: 0.2019 - val_acc: 0.9268 - lr: 3.0000e-04\n",
      "Epoch 109/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1480 - acc: 0.9403\n",
      "Epoch 109: val_loss did not improve from 0.17116\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1481 - acc: 0.9403 - val_loss: 0.1869 - val_acc: 0.9178 - lr: 3.0000e-04\n",
      "Epoch 110/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1507 - acc: 0.9442\n",
      "Epoch 110: val_loss did not improve from 0.17116\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1510 - acc: 0.9438 - val_loss: 0.1741 - val_acc: 0.9357 - lr: 3.0000e-04\n",
      "Epoch 111/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1498 - acc: 0.9446\n",
      "Epoch 111: val_loss did not improve from 0.17116\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1497 - acc: 0.9442 - val_loss: 0.2496 - val_acc: 0.9032 - lr: 3.0000e-04\n",
      "Epoch 112/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1483 - acc: 0.9495\n",
      "Epoch 112: val_loss did not improve from 0.17116\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1484 - acc: 0.9490 - val_loss: 0.2555 - val_acc: 0.9178 - lr: 3.0000e-04\n",
      "Epoch 113/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1271 - acc: 0.9555\n",
      "Epoch 113: val_loss did not improve from 0.17116\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1266 - acc: 0.9553 - val_loss: 0.2023 - val_acc: 0.9308 - lr: 3.0000e-04\n",
      "Epoch 114/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1667 - acc: 0.9379\n",
      "Epoch 114: val_loss did not improve from 0.17116\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1667 - acc: 0.9375 - val_loss: 0.1776 - val_acc: 0.9317 - lr: 3.0000e-04\n",
      "Epoch 115/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1583 - acc: 0.9414\n",
      "Epoch 115: val_loss did not improve from 0.17116\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1588 - acc: 0.9410 - val_loss: 0.1813 - val_acc: 0.9227 - lr: 3.0000e-04\n",
      "Epoch 116/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1398 - acc: 0.9428\n",
      "Epoch 116: ReduceLROnPlateau reducing learning rate to 0.00022500001068692654.\n",
      "\n",
      "Epoch 116: val_loss did not improve from 0.17116\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1390 - acc: 0.9431 - val_loss: 0.2070 - val_acc: 0.9251 - lr: 3.0000e-04\n",
      "Epoch 117/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1301 - acc: 0.9506\n",
      "Epoch 117: val_loss did not improve from 0.17116\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1316 - acc: 0.9501 - val_loss: 0.1737 - val_acc: 0.9390 - lr: 2.2500e-04\n",
      "Epoch 118/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1246 - acc: 0.9481\n",
      "Epoch 118: val_loss did not improve from 0.17116\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1248 - acc: 0.9473 - val_loss: 0.2655 - val_acc: 0.9040 - lr: 2.2500e-04\n",
      "Epoch 119/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1195 - acc: 0.9562\n",
      "Epoch 119: val_loss improved from 0.17116 to 0.15880, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1206 - acc: 0.9557 - val_loss: 0.1588 - val_acc: 0.9430 - lr: 2.2500e-04\n",
      "Epoch 120/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1234 - acc: 0.9534\n",
      "Epoch 120: val_loss did not improve from 0.15880\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.1239 - acc: 0.9536 - val_loss: 0.1710 - val_acc: 0.9390 - lr: 2.2500e-04\n",
      "Epoch 121/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1033 - acc: 0.9598\n",
      "Epoch 121: val_loss did not improve from 0.15880\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1026 - acc: 0.9602 - val_loss: 0.2068 - val_acc: 0.9325 - lr: 2.2500e-04\n",
      "Epoch 122/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1212 - acc: 0.9531\n",
      "Epoch 122: val_loss did not improve from 0.15880\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.1229 - acc: 0.9515 - val_loss: 0.2114 - val_acc: 0.9300 - lr: 2.2500e-04\n",
      "Epoch 123/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1135 - acc: 0.9569\n",
      "Epoch 123: val_loss did not improve from 0.15880\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1152 - acc: 0.9560 - val_loss: 0.1997 - val_acc: 0.9300 - lr: 2.2500e-04\n",
      "Epoch 124/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.1188 - acc: 0.9528\n",
      "Epoch 124: val_loss did not improve from 0.15880\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1208 - acc: 0.9525 - val_loss: 0.1822 - val_acc: 0.9349 - lr: 2.2500e-04\n",
      "Epoch 125/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.1083 - acc: 0.9585\n",
      "Epoch 125: val_loss did not improve from 0.15880\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1081 - acc: 0.9585 - val_loss: 0.1808 - val_acc: 0.9333 - lr: 2.2500e-04\n",
      "Epoch 126/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1093 - acc: 0.9580\n",
      "Epoch 126: val_loss did not improve from 0.15880\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1086 - acc: 0.9581 - val_loss: 0.2024 - val_acc: 0.9325 - lr: 2.2500e-04\n",
      "Epoch 127/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1173 - acc: 0.9573\n",
      "Epoch 127: val_loss did not improve from 0.15880\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.1178 - acc: 0.9571 - val_loss: 0.1696 - val_acc: 0.9325 - lr: 2.2500e-04\n",
      "Epoch 128/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.1207 - acc: 0.9560\n",
      "Epoch 128: val_loss did not improve from 0.15880\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.1219 - acc: 0.9553 - val_loss: 0.1679 - val_acc: 0.9398 - lr: 2.2500e-04\n",
      "Epoch 129/160\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.1074 - acc: 0.9606\n",
      "Epoch 129: ReduceLROnPlateau reducing learning rate to 0.0001687500080151949.\n",
      "\n",
      "Epoch 129: val_loss did not improve from 0.15880\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1074 - acc: 0.9606 - val_loss: 0.2109 - val_acc: 0.9390 - lr: 2.2500e-04\n",
      "Epoch 130/160\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.0983 - acc: 0.9571\n",
      "Epoch 130: val_loss did not improve from 0.15880\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.0983 - acc: 0.9571 - val_loss: 0.1951 - val_acc: 0.9357 - lr: 1.6875e-04\n",
      "Epoch 131/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0918 - acc: 0.9654\n",
      "Epoch 131: val_loss did not improve from 0.15880\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.0917 - acc: 0.9651 - val_loss: 0.2051 - val_acc: 0.9430 - lr: 1.6875e-04\n",
      "Epoch 132/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0933 - acc: 0.9633\n",
      "Epoch 132: val_loss did not improve from 0.15880\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.0928 - acc: 0.9634 - val_loss: 0.2154 - val_acc: 0.9382 - lr: 1.6875e-04\n",
      "Epoch 133/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0938 - acc: 0.9647\n",
      "Epoch 133: val_loss improved from 0.15880 to 0.15799, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.0932 - acc: 0.9647 - val_loss: 0.1580 - val_acc: 0.9504 - lr: 1.6875e-04\n",
      "Epoch 134/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0807 - acc: 0.9675\n",
      "Epoch 134: val_loss did not improve from 0.15799\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.0808 - acc: 0.9672 - val_loss: 0.1693 - val_acc: 0.9447 - lr: 1.6875e-04\n",
      "Epoch 135/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0962 - acc: 0.9661\n",
      "Epoch 135: val_loss did not improve from 0.15799\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.0958 - acc: 0.9661 - val_loss: 0.1865 - val_acc: 0.9292 - lr: 1.6875e-04\n",
      "Epoch 136/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0924 - acc: 0.9640\n",
      "Epoch 136: val_loss did not improve from 0.15799\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.0918 - acc: 0.9644 - val_loss: 0.2093 - val_acc: 0.9300 - lr: 1.6875e-04\n",
      "Epoch 137/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1005 - acc: 0.9615\n",
      "Epoch 137: val_loss did not improve from 0.15799\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.0999 - acc: 0.9616 - val_loss: 0.2276 - val_acc: 0.9284 - lr: 1.6875e-04\n",
      "Epoch 138/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0994 - acc: 0.9647\n",
      "Epoch 138: val_loss did not improve from 0.15799\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.0994 - acc: 0.9647 - val_loss: 0.2082 - val_acc: 0.9406 - lr: 1.6875e-04\n",
      "Epoch 139/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0834 - acc: 0.9703\n",
      "Epoch 139: val_loss did not improve from 0.15799\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.0827 - acc: 0.9707 - val_loss: 0.2770 - val_acc: 0.9227 - lr: 1.6875e-04\n",
      "Epoch 140/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0997 - acc: 0.9672\n",
      "Epoch 140: val_loss did not improve from 0.15799\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1011 - acc: 0.9668 - val_loss: 0.1799 - val_acc: 0.9455 - lr: 1.6875e-04\n",
      "Epoch 141/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0960 - acc: 0.9608\n",
      "Epoch 141: val_loss did not improve from 0.15799\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.0953 - acc: 0.9609 - val_loss: 0.1950 - val_acc: 0.9373 - lr: 1.6875e-04\n",
      "Epoch 142/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0860 - acc: 0.9682\n",
      "Epoch 142: val_loss did not improve from 0.15799\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.0867 - acc: 0.9679 - val_loss: 0.1819 - val_acc: 0.9382 - lr: 1.6875e-04\n",
      "Epoch 143/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0878 - acc: 0.9668\n",
      "Epoch 143: ReduceLROnPlateau reducing learning rate to 0.00012656250328291208.\n",
      "\n",
      "Epoch 143: val_loss did not improve from 0.15799\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.0873 - acc: 0.9672 - val_loss: 0.1702 - val_acc: 0.9430 - lr: 1.6875e-04\n",
      "Epoch 144/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0763 - acc: 0.9711\n",
      "Epoch 144: val_loss did not improve from 0.15799\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.0758 - acc: 0.9714 - val_loss: 0.1899 - val_acc: 0.9439 - lr: 1.2656e-04\n",
      "Epoch 145/160\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.0709 - acc: 0.9752\n",
      "Epoch 145: val_loss did not improve from 0.15799\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.0709 - acc: 0.9752 - val_loss: 0.1835 - val_acc: 0.9398 - lr: 1.2656e-04\n",
      "Epoch 146/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0793 - acc: 0.9679\n",
      "Epoch 146: val_loss did not improve from 0.15799\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.0788 - acc: 0.9682 - val_loss: 0.2105 - val_acc: 0.9373 - lr: 1.2656e-04\n",
      "Epoch 147/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0693 - acc: 0.9707\n",
      "Epoch 147: val_loss did not improve from 0.15799\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.0688 - acc: 0.9710 - val_loss: 0.1849 - val_acc: 0.9447 - lr: 1.2656e-04\n",
      "Epoch 148/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0785 - acc: 0.9711\n",
      "Epoch 148: val_loss did not improve from 0.15799\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.0786 - acc: 0.9710 - val_loss: 0.1705 - val_acc: 0.9471 - lr: 1.2656e-04\n",
      "Epoch 149/160\n",
      "179/180 [============================>.] - ETA: 0s - loss: 0.0681 - acc: 0.9779\n",
      "Epoch 149: val_loss did not improve from 0.15799\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.0678 - acc: 0.9780 - val_loss: 0.2237 - val_acc: 0.9276 - lr: 1.2656e-04\n",
      "Epoch 150/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0741 - acc: 0.9718\n",
      "Epoch 150: val_loss did not improve from 0.15799\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.0738 - acc: 0.9717 - val_loss: 0.1960 - val_acc: 0.9455 - lr: 1.2656e-04\n",
      "Epoch 151/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0690 - acc: 0.9728\n",
      "Epoch 151: val_loss did not improve from 0.15799\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.0697 - acc: 0.9724 - val_loss: 0.1777 - val_acc: 0.9390 - lr: 1.2656e-04\n",
      "Epoch 152/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0791 - acc: 0.9696\n",
      "Epoch 152: val_loss did not improve from 0.15799\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.0812 - acc: 0.9696 - val_loss: 0.2046 - val_acc: 0.9357 - lr: 1.2656e-04\n",
      "Epoch 153/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0815 - acc: 0.9707\n",
      "Epoch 153: ReduceLROnPlateau reducing learning rate to 9.492187746218406e-05.\n",
      "\n",
      "Epoch 153: val_loss did not improve from 0.15799\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.0811 - acc: 0.9707 - val_loss: 0.2133 - val_acc: 0.9422 - lr: 1.2656e-04\n",
      "Epoch 153: early stopping\n",
      "Epoch 1/160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-23 08:21:38.437618: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_1/dropout_2/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - ETA: 0s - loss: 0.6857 - acc: 0.5361\n",
      "Epoch 1: val_loss improved from inf to 0.68538, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 6s 21ms/step - loss: 0.6857 - acc: 0.5361 - val_loss: 0.6854 - val_acc: 0.5899 - lr: 3.0000e-04\n",
      "Epoch 2/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.6945 - acc: 0.5796\n",
      "Epoch 2: val_loss did not improve from 0.68538\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.6945 - acc: 0.5798 - val_loss: 0.6915 - val_acc: 0.5899 - lr: 3.0000e-04\n",
      "Epoch 3/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.6941 - acc: 0.4952\n",
      "Epoch 3: val_loss did not improve from 0.68538\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.6941 - acc: 0.4960 - val_loss: 0.6931 - val_acc: 0.5899 - lr: 3.0000e-04\n",
      "Epoch 4/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.6940 - acc: 0.4836\n",
      "Epoch 4: val_loss did not improve from 0.68538\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.6938 - acc: 0.4841 - val_loss: 0.6943 - val_acc: 0.4101 - lr: 3.0000e-04\n",
      "Epoch 5/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.6941 - acc: 0.4613\n",
      "Epoch 5: val_loss did not improve from 0.68538\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.6938 - acc: 0.4621 - val_loss: 0.6936 - val_acc: 0.4101 - lr: 3.0000e-04\n",
      "Epoch 6/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.6941 - acc: 0.4920\n",
      "Epoch 6: val_loss did not improve from 0.68538\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.6941 - acc: 0.4890 - val_loss: 0.6935 - val_acc: 0.4101 - lr: 3.0000e-04\n",
      "Epoch 7/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.6941 - acc: 0.4807\n",
      "Epoch 7: val_loss did not improve from 0.68538\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.6940 - acc: 0.4806 - val_loss: 0.6941 - val_acc: 0.4101 - lr: 3.0000e-04\n",
      "Epoch 8/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.6941 - acc: 0.5185\n",
      "Epoch 8: val_loss did not improve from 0.68538\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.6940 - acc: 0.5176 - val_loss: 0.6957 - val_acc: 0.4101 - lr: 3.0000e-04\n",
      "Epoch 9/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.6944 - acc: 0.4363\n",
      "Epoch 9: val_loss did not improve from 0.68538\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.6939 - acc: 0.4353 - val_loss: 0.6937 - val_acc: 0.4101 - lr: 3.0000e-04\n",
      "Epoch 10/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.6943 - acc: 0.4931\n",
      "Epoch 10: val_loss did not improve from 0.68538\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.6941 - acc: 0.4939 - val_loss: 0.6931 - val_acc: 0.5899 - lr: 3.0000e-04\n",
      "Epoch 11/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.6942 - acc: 0.5072\n",
      "Epoch 11: ReduceLROnPlateau reducing learning rate to 0.00022500001068692654.\n",
      "\n",
      "Epoch 11: val_loss did not improve from 0.68538\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.6943 - acc: 0.5051 - val_loss: 0.6925 - val_acc: 0.5899 - lr: 3.0000e-04\n",
      "Epoch 12/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.6935 - acc: 0.5747\n",
      "Epoch 12: val_loss did not improve from 0.68538\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.6938 - acc: 0.5724 - val_loss: 0.6940 - val_acc: 0.4101 - lr: 2.2500e-04\n",
      "Epoch 13/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.6937 - acc: 0.4433\n",
      "Epoch 13: val_loss did not improve from 0.68538\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.6941 - acc: 0.4436 - val_loss: 0.6923 - val_acc: 0.5899 - lr: 2.2500e-04\n",
      "Epoch 14/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.6943 - acc: 0.5044\n",
      "Epoch 14: val_loss did not improve from 0.68538\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.6942 - acc: 0.5047 - val_loss: 0.6928 - val_acc: 0.5899 - lr: 2.2500e-04\n",
      "Epoch 15/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.6941 - acc: 0.5083\n",
      "Epoch 15: val_loss improved from 0.68538 to 0.67820, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.6938 - acc: 0.5096 - val_loss: 0.6782 - val_acc: 0.5810 - lr: 2.2500e-04\n",
      "Epoch 16/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.6948 - acc: 0.4594\n",
      "Epoch 16: val_loss did not improve from 0.67820\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.6943 - acc: 0.4614 - val_loss: 0.6930 - val_acc: 0.5899 - lr: 2.2500e-04\n",
      "Epoch 17/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.6925 - acc: 0.5217\n",
      "Epoch 17: val_loss did not improve from 0.67820\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.6926 - acc: 0.5222 - val_loss: 0.6856 - val_acc: 0.6192 - lr: 2.2500e-04\n",
      "Epoch 18/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.6035 - acc: 0.6972\n",
      "Epoch 18: val_loss improved from 0.67820 to 0.60183, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.6034 - acc: 0.6988 - val_loss: 0.6018 - val_acc: 0.6876 - lr: 2.2500e-04\n",
      "Epoch 19/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.5401 - acc: 0.7494\n",
      "Epoch 19: val_loss improved from 0.60183 to 0.49552, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.5374 - acc: 0.7515 - val_loss: 0.4955 - val_acc: 0.7689 - lr: 2.2500e-04\n",
      "Epoch 20/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.5132 - acc: 0.7543\n",
      "Epoch 20: val_loss did not improve from 0.49552\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.5140 - acc: 0.7536 - val_loss: 0.5026 - val_acc: 0.7941 - lr: 2.2500e-04\n",
      "Epoch 21/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.4597 - acc: 0.7999\n",
      "Epoch 21: val_loss improved from 0.49552 to 0.44223, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.4594 - acc: 0.7997 - val_loss: 0.4422 - val_acc: 0.8023 - lr: 2.2500e-04\n",
      "Epoch 22/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.4309 - acc: 0.8090\n",
      "Epoch 22: val_loss improved from 0.44223 to 0.40210, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.4310 - acc: 0.8094 - val_loss: 0.4021 - val_acc: 0.8308 - lr: 2.2500e-04\n",
      "Epoch 23/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.3859 - acc: 0.8465\n",
      "Epoch 23: val_loss did not improve from 0.40210\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.3857 - acc: 0.8471 - val_loss: 0.4278 - val_acc: 0.8226 - lr: 2.2500e-04\n",
      "Epoch 24/160\n",
      "176/180 [============================>.] - ETA: 0s - loss: 0.3471 - acc: 0.8526\n",
      "Epoch 24: val_loss improved from 0.40210 to 0.35383, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.3474 - acc: 0.8524 - val_loss: 0.3538 - val_acc: 0.8381 - lr: 2.2500e-04\n",
      "Epoch 25/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.3346 - acc: 0.8641\n",
      "Epoch 25: val_loss did not improve from 0.35383\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.3354 - acc: 0.8639 - val_loss: 0.3791 - val_acc: 0.8365 - lr: 2.2500e-04\n",
      "Epoch 26/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.3260 - acc: 0.8592\n",
      "Epoch 26: val_loss improved from 0.35383 to 0.33488, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.3244 - acc: 0.8604 - val_loss: 0.3349 - val_acc: 0.8487 - lr: 2.2500e-04\n",
      "Epoch 27/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.3351 - acc: 0.8539\n",
      "Epoch 27: val_loss improved from 0.33488 to 0.33253, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.3340 - acc: 0.8541 - val_loss: 0.3325 - val_acc: 0.8600 - lr: 2.2500e-04\n",
      "Epoch 28/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.3125 - acc: 0.8627\n",
      "Epoch 28: val_loss improved from 0.33253 to 0.31567, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.3107 - acc: 0.8639 - val_loss: 0.3157 - val_acc: 0.8682 - lr: 2.2500e-04\n",
      "Epoch 29/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.3042 - acc: 0.8708\n",
      "Epoch 29: val_loss improved from 0.31567 to 0.29782, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.3026 - acc: 0.8719 - val_loss: 0.2978 - val_acc: 0.8723 - lr: 2.2500e-04\n",
      "Epoch 30/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.2962 - acc: 0.8779\n",
      "Epoch 30: val_loss did not improve from 0.29782\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2957 - acc: 0.8771 - val_loss: 0.3173 - val_acc: 0.8690 - lr: 2.2500e-04\n",
      "Epoch 31/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.3060 - acc: 0.8690\n",
      "Epoch 31: val_loss improved from 0.29782 to 0.28766, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.3047 - acc: 0.8695 - val_loss: 0.2877 - val_acc: 0.8902 - lr: 2.2500e-04\n",
      "Epoch 32/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2967 - acc: 0.8768\n",
      "Epoch 32: val_loss did not improve from 0.28766\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.2964 - acc: 0.8768 - val_loss: 0.3027 - val_acc: 0.8861 - lr: 2.2500e-04\n",
      "Epoch 33/160\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.2991 - acc: 0.8785\n",
      "Epoch 33: val_loss did not improve from 0.28766\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.2991 - acc: 0.8785 - val_loss: 0.2916 - val_acc: 0.8779 - lr: 2.2500e-04\n",
      "Epoch 34/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2949 - acc: 0.8761\n",
      "Epoch 34: val_loss did not improve from 0.28766\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.2938 - acc: 0.8761 - val_loss: 0.3223 - val_acc: 0.8739 - lr: 2.2500e-04\n",
      "Epoch 35/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2755 - acc: 0.8902\n",
      "Epoch 35: val_loss did not improve from 0.28766\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2758 - acc: 0.8897 - val_loss: 0.3007 - val_acc: 0.8853 - lr: 2.2500e-04\n",
      "Epoch 36/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2679 - acc: 0.8878\n",
      "Epoch 36: val_loss did not improve from 0.28766\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.2684 - acc: 0.8880 - val_loss: 0.2985 - val_acc: 0.8731 - lr: 2.2500e-04\n",
      "Epoch 37/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2768 - acc: 0.8888\n",
      "Epoch 37: val_loss improved from 0.28766 to 0.27822, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2754 - acc: 0.8897 - val_loss: 0.2782 - val_acc: 0.8885 - lr: 2.2500e-04\n",
      "Epoch 38/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2650 - acc: 0.8952\n",
      "Epoch 38: val_loss did not improve from 0.27822\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2646 - acc: 0.8956 - val_loss: 0.2828 - val_acc: 0.8910 - lr: 2.2500e-04\n",
      "Epoch 39/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.2634 - acc: 0.8903\n",
      "Epoch 39: val_loss improved from 0.27822 to 0.24564, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2624 - acc: 0.8918 - val_loss: 0.2456 - val_acc: 0.9056 - lr: 2.2500e-04\n",
      "Epoch 40/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2602 - acc: 0.8895\n",
      "Epoch 40: val_loss did not improve from 0.24564\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2583 - acc: 0.8908 - val_loss: 0.2662 - val_acc: 0.8926 - lr: 2.2500e-04\n",
      "Epoch 41/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2560 - acc: 0.8955\n",
      "Epoch 41: val_loss did not improve from 0.24564\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.2541 - acc: 0.8967 - val_loss: 0.2718 - val_acc: 0.8999 - lr: 2.2500e-04\n",
      "Epoch 42/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2580 - acc: 0.8980\n",
      "Epoch 42: val_loss did not improve from 0.24564\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2590 - acc: 0.8967 - val_loss: 0.2525 - val_acc: 0.8999 - lr: 2.2500e-04\n",
      "Epoch 43/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.2657 - acc: 0.8900\n",
      "Epoch 43: val_loss did not improve from 0.24564\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2650 - acc: 0.8908 - val_loss: 0.3010 - val_acc: 0.8682 - lr: 2.2500e-04\n",
      "Epoch 44/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2458 - acc: 0.9043\n",
      "Epoch 44: val_loss did not improve from 0.24564\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.2450 - acc: 0.9047 - val_loss: 0.2755 - val_acc: 0.8942 - lr: 2.2500e-04\n",
      "Epoch 45/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.2480 - acc: 0.8967\n",
      "Epoch 45: val_loss did not improve from 0.24564\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.2488 - acc: 0.8953 - val_loss: 0.2573 - val_acc: 0.9048 - lr: 2.2500e-04\n",
      "Epoch 46/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2389 - acc: 0.9029\n",
      "Epoch 46: val_loss did not improve from 0.24564\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.2381 - acc: 0.9033 - val_loss: 0.2726 - val_acc: 0.9024 - lr: 2.2500e-04\n",
      "Epoch 47/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2391 - acc: 0.9061\n",
      "Epoch 47: val_loss did not improve from 0.24564\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.2397 - acc: 0.9051 - val_loss: 0.2942 - val_acc: 0.9064 - lr: 2.2500e-04\n",
      "Epoch 48/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2357 - acc: 0.9072\n",
      "Epoch 48: val_loss did not improve from 0.24564\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.2379 - acc: 0.9061 - val_loss: 0.2691 - val_acc: 0.9007 - lr: 2.2500e-04\n",
      "Epoch 49/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2404 - acc: 0.9082\n",
      "Epoch 49: val_loss improved from 0.24564 to 0.22324, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2393 - acc: 0.9089 - val_loss: 0.2232 - val_acc: 0.9194 - lr: 2.2500e-04\n",
      "Epoch 50/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.2403 - acc: 0.9077\n",
      "Epoch 50: val_loss did not improve from 0.22324\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.2422 - acc: 0.9082 - val_loss: 0.2481 - val_acc: 0.9048 - lr: 2.2500e-04\n",
      "Epoch 51/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2200 - acc: 0.9170\n",
      "Epoch 51: val_loss did not improve from 0.22324\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.2198 - acc: 0.9162 - val_loss: 0.2687 - val_acc: 0.8942 - lr: 2.2500e-04\n",
      "Epoch 52/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.2147 - acc: 0.9141\n",
      "Epoch 52: val_loss did not improve from 0.22324\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.2175 - acc: 0.9124 - val_loss: 0.2295 - val_acc: 0.9146 - lr: 2.2500e-04\n",
      "Epoch 53/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2255 - acc: 0.9093\n",
      "Epoch 53: val_loss did not improve from 0.22324\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.2247 - acc: 0.9092 - val_loss: 0.2734 - val_acc: 0.8853 - lr: 2.2500e-04\n",
      "Epoch 54/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2196 - acc: 0.9086\n",
      "Epoch 54: val_loss did not improve from 0.22324\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.2199 - acc: 0.9089 - val_loss: 0.2737 - val_acc: 0.8861 - lr: 2.2500e-04\n",
      "Epoch 55/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2332 - acc: 0.9086\n",
      "Epoch 55: val_loss did not improve from 0.22324\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.2328 - acc: 0.9082 - val_loss: 0.2588 - val_acc: 0.9015 - lr: 2.2500e-04\n",
      "Epoch 56/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2229 - acc: 0.9188\n",
      "Epoch 56: val_loss did not improve from 0.22324\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.2221 - acc: 0.9187 - val_loss: 0.3027 - val_acc: 0.8641 - lr: 2.2500e-04\n",
      "Epoch 57/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2098 - acc: 0.9206\n",
      "Epoch 57: val_loss improved from 0.22324 to 0.21206, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.2105 - acc: 0.9208 - val_loss: 0.2121 - val_acc: 0.9235 - lr: 2.2500e-04\n",
      "Epoch 58/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2194 - acc: 0.9202\n",
      "Epoch 58: val_loss did not improve from 0.21206\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.2186 - acc: 0.9204 - val_loss: 0.2518 - val_acc: 0.9007 - lr: 2.2500e-04\n",
      "Epoch 59/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1987 - acc: 0.9248\n",
      "Epoch 59: val_loss improved from 0.21206 to 0.21079, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.1996 - acc: 0.9243 - val_loss: 0.2108 - val_acc: 0.9186 - lr: 2.2500e-04\n",
      "Epoch 60/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2292 - acc: 0.9100\n",
      "Epoch 60: val_loss did not improve from 0.21079\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.2296 - acc: 0.9092 - val_loss: 0.2346 - val_acc: 0.9089 - lr: 2.2500e-04\n",
      "Epoch 61/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2195 - acc: 0.9185\n",
      "Epoch 61: val_loss did not improve from 0.21079\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.2193 - acc: 0.9190 - val_loss: 0.2530 - val_acc: 0.9048 - lr: 2.2500e-04\n",
      "Epoch 62/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2074 - acc: 0.9248\n",
      "Epoch 62: val_loss did not improve from 0.21079\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.2074 - acc: 0.9250 - val_loss: 0.2405 - val_acc: 0.9089 - lr: 2.2500e-04\n",
      "Epoch 63/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2086 - acc: 0.9188\n",
      "Epoch 63: val_loss improved from 0.21079 to 0.20623, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2073 - acc: 0.9194 - val_loss: 0.2062 - val_acc: 0.9276 - lr: 2.2500e-04\n",
      "Epoch 64/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2208 - acc: 0.9163\n",
      "Epoch 64: val_loss did not improve from 0.20623\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2215 - acc: 0.9159 - val_loss: 0.2341 - val_acc: 0.9227 - lr: 2.2500e-04\n",
      "Epoch 65/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2116 - acc: 0.9223\n",
      "Epoch 65: val_loss did not improve from 0.20623\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2113 - acc: 0.9218 - val_loss: 0.2517 - val_acc: 0.8942 - lr: 2.2500e-04\n",
      "Epoch 66/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2099 - acc: 0.9149\n",
      "Epoch 66: val_loss did not improve from 0.20623\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2093 - acc: 0.9155 - val_loss: 0.2457 - val_acc: 0.9056 - lr: 2.2500e-04\n",
      "Epoch 67/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1962 - acc: 0.9273\n",
      "Epoch 67: val_loss improved from 0.20623 to 0.20032, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1955 - acc: 0.9277 - val_loss: 0.2003 - val_acc: 0.9260 - lr: 2.2500e-04\n",
      "Epoch 68/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1970 - acc: 0.9248\n",
      "Epoch 68: val_loss did not improve from 0.20032\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1972 - acc: 0.9243 - val_loss: 0.2254 - val_acc: 0.9211 - lr: 2.2500e-04\n",
      "Epoch 69/160\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.1873 - acc: 0.9281\n",
      "Epoch 69: val_loss did not improve from 0.20032\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1873 - acc: 0.9281 - val_loss: 0.2308 - val_acc: 0.9129 - lr: 2.2500e-04\n",
      "Epoch 70/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1996 - acc: 0.9248\n",
      "Epoch 70: val_loss did not improve from 0.20032\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.1995 - acc: 0.9246 - val_loss: 0.2327 - val_acc: 0.9154 - lr: 2.2500e-04\n",
      "Epoch 71/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.1990 - acc: 0.9205\n",
      "Epoch 71: val_loss did not improve from 0.20032\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1992 - acc: 0.9201 - val_loss: 0.2217 - val_acc: 0.9251 - lr: 2.2500e-04\n",
      "Epoch 72/160\n",
      "179/180 [============================>.] - ETA: 0s - loss: 0.1995 - acc: 0.9263\n",
      "Epoch 72: val_loss improved from 0.20032 to 0.20029, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1995 - acc: 0.9264 - val_loss: 0.2003 - val_acc: 0.9268 - lr: 2.2500e-04\n",
      "Epoch 73/160\n",
      "179/180 [============================>.] - ETA: 0s - loss: 0.1955 - acc: 0.9280\n",
      "Epoch 73: val_loss improved from 0.20029 to 0.19669, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.1964 - acc: 0.9274 - val_loss: 0.1967 - val_acc: 0.9170 - lr: 2.2500e-04\n",
      "Epoch 74/160\n",
      "179/180 [============================>.] - ETA: 0s - loss: 0.1865 - acc: 0.9333\n",
      "Epoch 74: val_loss improved from 0.19669 to 0.19473, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.1860 - acc: 0.9333 - val_loss: 0.1947 - val_acc: 0.9243 - lr: 2.2500e-04\n",
      "Epoch 75/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2019 - acc: 0.9195\n",
      "Epoch 75: val_loss improved from 0.19473 to 0.18895, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2006 - acc: 0.9197 - val_loss: 0.1890 - val_acc: 0.9308 - lr: 2.2500e-04\n",
      "Epoch 76/160\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.1928 - acc: 0.9305\n",
      "Epoch 76: val_loss did not improve from 0.18895\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1928 - acc: 0.9305 - val_loss: 0.2201 - val_acc: 0.9138 - lr: 2.2500e-04\n",
      "Epoch 77/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1866 - acc: 0.9276\n",
      "Epoch 77: val_loss improved from 0.18895 to 0.18619, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1861 - acc: 0.9277 - val_loss: 0.1862 - val_acc: 0.9276 - lr: 2.2500e-04\n",
      "Epoch 78/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1905 - acc: 0.9315\n",
      "Epoch 78: val_loss did not improve from 0.18619\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1891 - acc: 0.9319 - val_loss: 0.1874 - val_acc: 0.9251 - lr: 2.2500e-04\n",
      "Epoch 79/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1644 - acc: 0.9396\n",
      "Epoch 79: val_loss did not improve from 0.18619\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1660 - acc: 0.9386 - val_loss: 0.1876 - val_acc: 0.9341 - lr: 2.2500e-04\n",
      "Epoch 80/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.1746 - acc: 0.9340\n",
      "Epoch 80: val_loss improved from 0.18619 to 0.16495, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.1729 - acc: 0.9347 - val_loss: 0.1649 - val_acc: 0.9365 - lr: 2.2500e-04\n",
      "Epoch 81/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1727 - acc: 0.9280\n",
      "Epoch 81: val_loss did not improve from 0.16495\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1715 - acc: 0.9288 - val_loss: 0.1919 - val_acc: 0.9390 - lr: 2.2500e-04\n",
      "Epoch 82/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1806 - acc: 0.9351\n",
      "Epoch 82: val_loss did not improve from 0.16495\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1812 - acc: 0.9351 - val_loss: 0.1737 - val_acc: 0.9308 - lr: 2.2500e-04\n",
      "Epoch 83/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1704 - acc: 0.9365\n",
      "Epoch 83: val_loss did not improve from 0.16495\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1703 - acc: 0.9368 - val_loss: 0.1769 - val_acc: 0.9317 - lr: 2.2500e-04\n",
      "Epoch 84/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1794 - acc: 0.9340\n",
      "Epoch 84: val_loss did not improve from 0.16495\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1784 - acc: 0.9344 - val_loss: 0.1912 - val_acc: 0.9251 - lr: 2.2500e-04\n",
      "Epoch 85/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1710 - acc: 0.9389\n",
      "Epoch 85: val_loss did not improve from 0.16495\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1706 - acc: 0.9393 - val_loss: 0.1987 - val_acc: 0.9365 - lr: 2.2500e-04\n",
      "Epoch 86/160\n",
      "179/180 [============================>.] - ETA: 0s - loss: 0.1835 - acc: 0.9330\n",
      "Epoch 86: val_loss did not improve from 0.16495\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.1833 - acc: 0.9330 - val_loss: 0.1856 - val_acc: 0.9341 - lr: 2.2500e-04\n",
      "Epoch 87/160\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.1611 - acc: 0.9389\n",
      "Epoch 87: val_loss did not improve from 0.16495\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1611 - acc: 0.9389 - val_loss: 0.1968 - val_acc: 0.9292 - lr: 2.2500e-04\n",
      "Epoch 88/160\n",
      "179/180 [============================>.] - ETA: 0s - loss: 0.1690 - acc: 0.9316\n",
      "Epoch 88: val_loss did not improve from 0.16495\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.1690 - acc: 0.9316 - val_loss: 0.1969 - val_acc: 0.9170 - lr: 2.2500e-04\n",
      "Epoch 89/160\n",
      "179/180 [============================>.] - ETA: 0s - loss: 0.1679 - acc: 0.9368\n",
      "Epoch 89: val_loss did not improve from 0.16495\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1675 - acc: 0.9368 - val_loss: 0.1809 - val_acc: 0.9357 - lr: 2.2500e-04\n",
      "Epoch 90/160\n",
      "179/180 [============================>.] - ETA: 0s - loss: 0.1654 - acc: 0.9396\n",
      "Epoch 90: ReduceLROnPlateau reducing learning rate to 0.0001687500080151949.\n",
      "\n",
      "Epoch 90: val_loss did not improve from 0.16495\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1654 - acc: 0.9396 - val_loss: 0.1818 - val_acc: 0.9300 - lr: 2.2500e-04\n",
      "Epoch 91/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.1508 - acc: 0.9471\n",
      "Epoch 91: val_loss did not improve from 0.16495\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1511 - acc: 0.9469 - val_loss: 0.1850 - val_acc: 0.9325 - lr: 1.6875e-04\n",
      "Epoch 92/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1483 - acc: 0.9463\n",
      "Epoch 92: val_loss did not improve from 0.16495\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1472 - acc: 0.9469 - val_loss: 0.1714 - val_acc: 0.9398 - lr: 1.6875e-04\n",
      "Epoch 93/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1568 - acc: 0.9414\n",
      "Epoch 93: val_loss did not improve from 0.16495\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.1570 - acc: 0.9410 - val_loss: 0.2255 - val_acc: 0.9170 - lr: 1.6875e-04\n",
      "Epoch 94/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1493 - acc: 0.9485\n",
      "Epoch 94: val_loss did not improve from 0.16495\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.1489 - acc: 0.9487 - val_loss: 0.1853 - val_acc: 0.9251 - lr: 1.6875e-04\n",
      "Epoch 95/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.1463 - acc: 0.9471\n",
      "Epoch 95: val_loss improved from 0.16495 to 0.16440, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1489 - acc: 0.9462 - val_loss: 0.1644 - val_acc: 0.9414 - lr: 1.6875e-04\n",
      "Epoch 96/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1425 - acc: 0.9435\n",
      "Epoch 96: val_loss did not improve from 0.16440\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1421 - acc: 0.9438 - val_loss: 0.1717 - val_acc: 0.9365 - lr: 1.6875e-04\n",
      "Epoch 97/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1508 - acc: 0.9463\n",
      "Epoch 97: val_loss improved from 0.16440 to 0.15963, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.1501 - acc: 0.9462 - val_loss: 0.1596 - val_acc: 0.9373 - lr: 1.6875e-04\n",
      "Epoch 98/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1457 - acc: 0.9471\n",
      "Epoch 98: val_loss did not improve from 0.15963\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1467 - acc: 0.9466 - val_loss: 0.1864 - val_acc: 0.9365 - lr: 1.6875e-04\n",
      "Epoch 99/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1384 - acc: 0.9488\n",
      "Epoch 99: val_loss improved from 0.15963 to 0.14589, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1399 - acc: 0.9483 - val_loss: 0.1459 - val_acc: 0.9512 - lr: 1.6875e-04\n",
      "Epoch 100/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1412 - acc: 0.9481\n",
      "Epoch 100: val_loss did not improve from 0.14589\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1399 - acc: 0.9487 - val_loss: 0.1642 - val_acc: 0.9382 - lr: 1.6875e-04\n",
      "Epoch 101/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1486 - acc: 0.9435\n",
      "Epoch 101: val_loss did not improve from 0.14589\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1471 - acc: 0.9442 - val_loss: 0.1710 - val_acc: 0.9373 - lr: 1.6875e-04\n",
      "Epoch 102/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.1462 - acc: 0.9439\n",
      "Epoch 102: val_loss did not improve from 0.14589\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.1466 - acc: 0.9435 - val_loss: 0.1817 - val_acc: 0.9333 - lr: 1.6875e-04\n",
      "Epoch 103/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1447 - acc: 0.9474\n",
      "Epoch 103: val_loss did not improve from 0.14589\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1436 - acc: 0.9480 - val_loss: 0.1578 - val_acc: 0.9520 - lr: 1.6875e-04\n",
      "Epoch 104/160\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.1316 - acc: 0.9490\n",
      "Epoch 104: val_loss did not improve from 0.14589\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1316 - acc: 0.9490 - val_loss: 0.1894 - val_acc: 0.9178 - lr: 1.6875e-04\n",
      "Epoch 105/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1450 - acc: 0.9463\n",
      "Epoch 105: val_loss did not improve from 0.14589\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1445 - acc: 0.9466 - val_loss: 0.1595 - val_acc: 0.9341 - lr: 1.6875e-04\n",
      "Epoch 106/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1356 - acc: 0.9485\n",
      "Epoch 106: val_loss did not improve from 0.14589\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1360 - acc: 0.9480 - val_loss: 0.1814 - val_acc: 0.9398 - lr: 1.6875e-04\n",
      "Epoch 107/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1752 - acc: 0.9407\n",
      "Epoch 107: val_loss did not improve from 0.14589\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1734 - acc: 0.9414 - val_loss: 0.2239 - val_acc: 0.9129 - lr: 1.6875e-04\n",
      "Epoch 108/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1526 - acc: 0.9400\n",
      "Epoch 108: val_loss did not improve from 0.14589\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.1530 - acc: 0.9400 - val_loss: 0.1690 - val_acc: 0.9333 - lr: 1.6875e-04\n",
      "Epoch 109/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.1245 - acc: 0.9546\n",
      "Epoch 109: ReduceLROnPlateau reducing learning rate to 0.00012656250328291208.\n",
      "\n",
      "Epoch 109: val_loss did not improve from 0.14589\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1268 - acc: 0.9543 - val_loss: 0.2126 - val_acc: 0.9113 - lr: 1.6875e-04\n",
      "Epoch 110/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1239 - acc: 0.9531\n",
      "Epoch 110: val_loss improved from 0.14589 to 0.14563, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1233 - acc: 0.9532 - val_loss: 0.1456 - val_acc: 0.9496 - lr: 1.2656e-04\n",
      "Epoch 111/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1207 - acc: 0.9573\n",
      "Epoch 111: val_loss improved from 0.14563 to 0.13225, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1205 - acc: 0.9574 - val_loss: 0.1323 - val_acc: 0.9504 - lr: 1.2656e-04\n",
      "Epoch 112/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1225 - acc: 0.9548\n",
      "Epoch 112: val_loss did not improve from 0.13225\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.1221 - acc: 0.9546 - val_loss: 0.1448 - val_acc: 0.9439 - lr: 1.2656e-04\n",
      "Epoch 113/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.1253 - acc: 0.9521\n",
      "Epoch 113: val_loss did not improve from 0.13225\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1240 - acc: 0.9529 - val_loss: 0.1468 - val_acc: 0.9512 - lr: 1.2656e-04\n",
      "Epoch 114/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1147 - acc: 0.9573\n",
      "Epoch 114: val_loss did not improve from 0.13225\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1144 - acc: 0.9574 - val_loss: 0.1415 - val_acc: 0.9390 - lr: 1.2656e-04\n",
      "Epoch 115/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1187 - acc: 0.9552\n",
      "Epoch 115: val_loss did not improve from 0.13225\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1191 - acc: 0.9550 - val_loss: 0.1791 - val_acc: 0.9382 - lr: 1.2656e-04\n",
      "Epoch 116/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1325 - acc: 0.9509\n",
      "Epoch 116: val_loss did not improve from 0.13225\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1324 - acc: 0.9508 - val_loss: 0.1525 - val_acc: 0.9471 - lr: 1.2656e-04\n",
      "Epoch 117/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1168 - acc: 0.9562\n",
      "Epoch 117: val_loss did not improve from 0.13225\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.1169 - acc: 0.9564 - val_loss: 0.1755 - val_acc: 0.9317 - lr: 1.2656e-04\n",
      "Epoch 118/160\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.1197 - acc: 0.9574\n",
      "Epoch 118: val_loss did not improve from 0.13225\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.1197 - acc: 0.9574 - val_loss: 0.1464 - val_acc: 0.9414 - lr: 1.2656e-04\n",
      "Epoch 119/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.1128 - acc: 0.9592\n",
      "Epoch 119: val_loss did not improve from 0.13225\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.1134 - acc: 0.9585 - val_loss: 0.1449 - val_acc: 0.9455 - lr: 1.2656e-04\n",
      "Epoch 120/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1143 - acc: 0.9573\n",
      "Epoch 120: val_loss did not improve from 0.13225\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1142 - acc: 0.9571 - val_loss: 0.1440 - val_acc: 0.9520 - lr: 1.2656e-04\n",
      "Epoch 121/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1222 - acc: 0.9541\n",
      "Epoch 121: ReduceLROnPlateau reducing learning rate to 9.492187746218406e-05.\n",
      "\n",
      "Epoch 121: val_loss did not improve from 0.13225\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1214 - acc: 0.9546 - val_loss: 0.1632 - val_acc: 0.9447 - lr: 1.2656e-04\n",
      "Epoch 122/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1155 - acc: 0.9562\n",
      "Epoch 122: val_loss did not improve from 0.13225\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.1152 - acc: 0.9560 - val_loss: 0.1583 - val_acc: 0.9455 - lr: 9.4922e-05\n",
      "Epoch 123/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1055 - acc: 0.9622\n",
      "Epoch 123: val_loss did not improve from 0.13225\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.1054 - acc: 0.9616 - val_loss: 0.1339 - val_acc: 0.9471 - lr: 9.4922e-05\n",
      "Epoch 124/160\n",
      "179/180 [============================>.] - ETA: 0s - loss: 0.1012 - acc: 0.9621\n",
      "Epoch 124: val_loss did not improve from 0.13225\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1008 - acc: 0.9623 - val_loss: 0.1539 - val_acc: 0.9357 - lr: 9.4922e-05\n",
      "Epoch 125/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.1146 - acc: 0.9588\n",
      "Epoch 125: val_loss did not improve from 0.13225\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.1151 - acc: 0.9592 - val_loss: 0.1374 - val_acc: 0.9561 - lr: 9.4922e-05\n",
      "Epoch 126/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1023 - acc: 0.9643\n",
      "Epoch 126: val_loss did not improve from 0.13225\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1058 - acc: 0.9637 - val_loss: 0.1434 - val_acc: 0.9414 - lr: 9.4922e-05\n",
      "Epoch 127/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1015 - acc: 0.9643\n",
      "Epoch 127: val_loss improved from 0.13225 to 0.12962, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1014 - acc: 0.9644 - val_loss: 0.1296 - val_acc: 0.9552 - lr: 9.4922e-05\n",
      "Epoch 128/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1113 - acc: 0.9622\n",
      "Epoch 128: val_loss did not improve from 0.12962\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1118 - acc: 0.9616 - val_loss: 0.1624 - val_acc: 0.9422 - lr: 9.4922e-05\n",
      "Epoch 129/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1097 - acc: 0.9569\n",
      "Epoch 129: val_loss did not improve from 0.12962\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.1094 - acc: 0.9571 - val_loss: 0.1457 - val_acc: 0.9479 - lr: 9.4922e-05\n",
      "Epoch 130/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1100 - acc: 0.9587\n",
      "Epoch 130: val_loss improved from 0.12962 to 0.12136, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1108 - acc: 0.9585 - val_loss: 0.1214 - val_acc: 0.9552 - lr: 9.4922e-05\n",
      "Epoch 131/160\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.1030 - acc: 0.9606\n",
      "Epoch 131: val_loss did not improve from 0.12136\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1030 - acc: 0.9606 - val_loss: 0.1526 - val_acc: 0.9471 - lr: 9.4922e-05\n",
      "Epoch 132/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.1160 - acc: 0.9549\n",
      "Epoch 132: val_loss did not improve from 0.12136\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1161 - acc: 0.9546 - val_loss: 0.1392 - val_acc: 0.9520 - lr: 9.4922e-05\n",
      "Epoch 133/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0937 - acc: 0.9647\n",
      "Epoch 133: val_loss did not improve from 0.12136\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.0955 - acc: 0.9637 - val_loss: 0.1320 - val_acc: 0.9552 - lr: 9.4922e-05\n",
      "Epoch 134/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1048 - acc: 0.9612\n",
      "Epoch 134: val_loss did not improve from 0.12136\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1043 - acc: 0.9616 - val_loss: 0.1378 - val_acc: 0.9520 - lr: 9.4922e-05\n",
      "Epoch 135/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0981 - acc: 0.9636\n",
      "Epoch 135: val_loss did not improve from 0.12136\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.0990 - acc: 0.9630 - val_loss: 0.1531 - val_acc: 0.9455 - lr: 9.4922e-05\n",
      "Epoch 136/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1029 - acc: 0.9619\n",
      "Epoch 136: val_loss did not improve from 0.12136\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1020 - acc: 0.9623 - val_loss: 0.1214 - val_acc: 0.9577 - lr: 9.4922e-05\n",
      "Epoch 137/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1145 - acc: 0.9562\n",
      "Epoch 137: val_loss did not improve from 0.12136\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1140 - acc: 0.9564 - val_loss: 0.1292 - val_acc: 0.9528 - lr: 9.4922e-05\n",
      "Epoch 138/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1013 - acc: 0.9647\n",
      "Epoch 138: val_loss did not improve from 0.12136\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1012 - acc: 0.9651 - val_loss: 0.1723 - val_acc: 0.9414 - lr: 9.4922e-05\n",
      "Epoch 139/160\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.1009 - acc: 0.9613\n",
      "Epoch 139: val_loss did not improve from 0.12136\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1009 - acc: 0.9613 - val_loss: 0.1346 - val_acc: 0.9544 - lr: 9.4922e-05\n",
      "Epoch 140/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1040 - acc: 0.9636\n",
      "Epoch 140: ReduceLROnPlateau reducing learning rate to 7.119141082512215e-05.\n",
      "\n",
      "Epoch 140: val_loss did not improve from 0.12136\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1033 - acc: 0.9637 - val_loss: 0.1250 - val_acc: 0.9561 - lr: 9.4922e-05\n",
      "Epoch 141/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.1058 - acc: 0.9627\n",
      "Epoch 141: val_loss did not improve from 0.12136\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.1043 - acc: 0.9634 - val_loss: 0.1219 - val_acc: 0.9528 - lr: 7.1191e-05\n",
      "Epoch 142/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0978 - acc: 0.9658\n",
      "Epoch 142: val_loss improved from 0.12136 to 0.11996, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.0977 - acc: 0.9658 - val_loss: 0.1200 - val_acc: 0.9642 - lr: 7.1191e-05\n",
      "Epoch 143/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.0989 - acc: 0.9634\n",
      "Epoch 143: val_loss improved from 0.11996 to 0.11596, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.0994 - acc: 0.9634 - val_loss: 0.1160 - val_acc: 0.9609 - lr: 7.1191e-05\n",
      "Epoch 144/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0930 - acc: 0.9693\n",
      "Epoch 144: val_loss did not improve from 0.11596\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.0940 - acc: 0.9686 - val_loss: 0.1445 - val_acc: 0.9471 - lr: 7.1191e-05\n",
      "Epoch 145/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.0869 - acc: 0.9707\n",
      "Epoch 145: val_loss did not improve from 0.11596\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.0863 - acc: 0.9710 - val_loss: 0.1332 - val_acc: 0.9455 - lr: 7.1191e-05\n",
      "Epoch 146/160\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.0829 - acc: 0.9700\n",
      "Epoch 146: val_loss did not improve from 0.11596\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.0829 - acc: 0.9700 - val_loss: 0.1827 - val_acc: 0.9300 - lr: 7.1191e-05\n",
      "Epoch 147/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0989 - acc: 0.9633\n",
      "Epoch 147: val_loss did not improve from 0.11596\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.0980 - acc: 0.9637 - val_loss: 0.1236 - val_acc: 0.9536 - lr: 7.1191e-05\n",
      "Epoch 148/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0828 - acc: 0.9693\n",
      "Epoch 148: val_loss did not improve from 0.11596\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.0829 - acc: 0.9689 - val_loss: 0.1405 - val_acc: 0.9471 - lr: 7.1191e-05\n",
      "Epoch 149/160\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.0845 - acc: 0.9696\n",
      "Epoch 149: val_loss did not improve from 0.11596\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.0845 - acc: 0.9696 - val_loss: 0.1408 - val_acc: 0.9463 - lr: 7.1191e-05\n",
      "Epoch 150/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0916 - acc: 0.9647\n",
      "Epoch 150: val_loss did not improve from 0.11596\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.0912 - acc: 0.9647 - val_loss: 0.1425 - val_acc: 0.9585 - lr: 7.1191e-05\n",
      "Epoch 151/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0817 - acc: 0.9711\n",
      "Epoch 151: val_loss did not improve from 0.11596\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.0810 - acc: 0.9714 - val_loss: 0.1178 - val_acc: 0.9528 - lr: 7.1191e-05\n",
      "Epoch 152/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0883 - acc: 0.9686\n",
      "Epoch 152: val_loss did not improve from 0.11596\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.0878 - acc: 0.9686 - val_loss: 0.1260 - val_acc: 0.9504 - lr: 7.1191e-05\n",
      "Epoch 153/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0902 - acc: 0.9643\n",
      "Epoch 153: ReduceLROnPlateau reducing learning rate to 5.339355811884161e-05.\n",
      "\n",
      "Epoch 153: val_loss did not improve from 0.11596\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.0905 - acc: 0.9644 - val_loss: 0.1366 - val_acc: 0.9552 - lr: 7.1191e-05\n",
      "Epoch 154/160\n",
      "179/180 [============================>.] - ETA: 0s - loss: 0.0823 - acc: 0.9709\n",
      "Epoch 154: val_loss did not improve from 0.11596\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.0834 - acc: 0.9707 - val_loss: 0.1189 - val_acc: 0.9561 - lr: 5.3394e-05\n",
      "Epoch 155/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0978 - acc: 0.9672\n",
      "Epoch 155: val_loss improved from 0.11596 to 0.11429, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.0977 - acc: 0.9668 - val_loss: 0.1143 - val_acc: 0.9601 - lr: 5.3394e-05\n",
      "Epoch 156/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0847 - acc: 0.9703\n",
      "Epoch 156: val_loss did not improve from 0.11429\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.0847 - acc: 0.9700 - val_loss: 0.1185 - val_acc: 0.9634 - lr: 5.3394e-05\n",
      "Epoch 157/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0812 - acc: 0.9718\n",
      "Epoch 157: val_loss did not improve from 0.11429\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.0805 - acc: 0.9721 - val_loss: 0.1330 - val_acc: 0.9439 - lr: 5.3394e-05\n",
      "Epoch 158/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.0876 - acc: 0.9677\n",
      "Epoch 158: val_loss did not improve from 0.11429\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.0868 - acc: 0.9682 - val_loss: 0.1315 - val_acc: 0.9569 - lr: 5.3394e-05\n",
      "Epoch 159/160\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.0771 - acc: 0.9731\n",
      "Epoch 159: val_loss did not improve from 0.11429\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.0771 - acc: 0.9731 - val_loss: 0.1268 - val_acc: 0.9520 - lr: 5.3394e-05\n",
      "Epoch 160/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0803 - acc: 0.9700\n",
      "Epoch 160: val_loss did not improve from 0.11429\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.0805 - acc: 0.9700 - val_loss: 0.1217 - val_acc: 0.9585 - lr: 5.3394e-05\n",
      "Epoch 1/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.7053 - acc: 0.5203\n",
      "Epoch 1: val_loss improved from inf to 0.75285, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_vgg16_weights.h5\n",
      "180/180 [==============================] - 7s 24ms/step - loss: 0.7058 - acc: 0.5197 - val_loss: 0.7528 - val_acc: 0.4101 - lr: 3.0000e-04\n",
      "Epoch 2/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.6919 - acc: 0.5372\n",
      "Epoch 2: val_loss did not improve from 0.75285\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.6919 - acc: 0.5372 - val_loss: 0.7650 - val_acc: 0.4101 - lr: 3.0000e-04\n",
      "Epoch 3/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.6975 - acc: 0.4991\n",
      "Epoch 3: val_loss improved from 0.75285 to 0.69293, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_vgg16_weights.h5\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.6970 - acc: 0.5002 - val_loss: 0.6929 - val_acc: 0.5899 - lr: 3.0000e-04\n",
      "Epoch 4/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.6938 - acc: 0.4956\n",
      "Epoch 4: val_loss improved from 0.69293 to 0.69268, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_vgg16_weights.h5\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.6939 - acc: 0.4963 - val_loss: 0.6927 - val_acc: 0.5899 - lr: 3.0000e-04\n",
      "Epoch 5/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.6937 - acc: 0.5367\n",
      "Epoch 5: val_loss did not improve from 0.69268\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.6939 - acc: 0.5361 - val_loss: 0.6930 - val_acc: 0.5899 - lr: 3.0000e-04\n",
      "Epoch 6/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.6937 - acc: 0.5199\n",
      "Epoch 6: val_loss did not improve from 0.69268\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.6939 - acc: 0.5194 - val_loss: 0.6936 - val_acc: 0.4101 - lr: 3.0000e-04\n",
      "Epoch 7/160\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.6938 - acc: 0.4286\n",
      "Epoch 7: val_loss did not improve from 0.69268\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.6938 - acc: 0.4286 - val_loss: 0.6932 - val_acc: 0.4101 - lr: 3.0000e-04\n",
      "Epoch 8/160\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.6939 - acc: 0.5288\n",
      "Epoch 8: val_loss did not improve from 0.69268\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.6939 - acc: 0.5288 - val_loss: 0.6935 - val_acc: 0.4101 - lr: 3.0000e-04\n",
      "Epoch 9/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.6941 - acc: 0.4324\n",
      "Epoch 9: val_loss did not improve from 0.69268\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.6938 - acc: 0.4311 - val_loss: 0.6938 - val_acc: 0.4101 - lr: 3.0000e-04\n",
      "Epoch 10/160\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.6939 - acc: 0.4750\n",
      "Epoch 10: val_loss did not improve from 0.69268\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.6939 - acc: 0.4750 - val_loss: 0.6937 - val_acc: 0.4101 - lr: 3.0000e-04\n",
      "Epoch 11/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.6936 - acc: 0.4836\n",
      "Epoch 11: val_loss did not improve from 0.69268\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.6938 - acc: 0.4834 - val_loss: 0.6932 - val_acc: 0.4101 - lr: 3.0000e-04\n",
      "Epoch 12/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.6937 - acc: 0.4338\n",
      "Epoch 12: val_loss did not improve from 0.69268\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.6938 - acc: 0.4339 - val_loss: 0.6936 - val_acc: 0.4101 - lr: 3.0000e-04\n",
      "Epoch 13/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.6934 - acc: 0.5146\n",
      "Epoch 13: val_loss did not improve from 0.69268\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.6938 - acc: 0.5124 - val_loss: 0.6934 - val_acc: 0.4101 - lr: 3.0000e-04\n",
      "Epoch 14/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.6937 - acc: 0.4818\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.00022500001068692654.\n",
      "\n",
      "Epoch 14: val_loss did not improve from 0.69268\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.6938 - acc: 0.4817 - val_loss: 0.6940 - val_acc: 0.4101 - lr: 3.0000e-04\n",
      "Epoch 15/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.6938 - acc: 0.4197\n",
      "Epoch 15: val_loss did not improve from 0.69268\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.6938 - acc: 0.4199 - val_loss: 0.6938 - val_acc: 0.4101 - lr: 2.2500e-04\n",
      "Epoch 16/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.6941 - acc: 0.4927\n",
      "Epoch 16: val_loss did not improve from 0.69268\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.6939 - acc: 0.4908 - val_loss: 0.6937 - val_acc: 0.4101 - lr: 2.2500e-04\n",
      "Epoch 17/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.6942 - acc: 0.4532\n",
      "Epoch 17: val_loss did not improve from 0.69268\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.6938 - acc: 0.4524 - val_loss: 0.6935 - val_acc: 0.4101 - lr: 2.2500e-04\n",
      "Epoch 18/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.6941 - acc: 0.4303\n",
      "Epoch 18: val_loss did not improve from 0.69268\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.6939 - acc: 0.4297 - val_loss: 0.6933 - val_acc: 0.4101 - lr: 2.2500e-04\n",
      "Epoch 19/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.6936 - acc: 0.4863\n",
      "Epoch 19: val_loss did not improve from 0.69268\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.6938 - acc: 0.4855 - val_loss: 0.6933 - val_acc: 0.4101 - lr: 2.2500e-04\n",
      "Epoch 20/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.6938 - acc: 0.4299\n",
      "Epoch 20: val_loss did not improve from 0.69268\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.6938 - acc: 0.4304 - val_loss: 0.6934 - val_acc: 0.4101 - lr: 2.2500e-04\n",
      "Epoch 21/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.6941 - acc: 0.5073\n",
      "Epoch 21: val_loss did not improve from 0.69268\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.6939 - acc: 0.5054 - val_loss: 0.6935 - val_acc: 0.4101 - lr: 2.2500e-04\n",
      "Epoch 22/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.6943 - acc: 0.4203\n",
      "Epoch 22: val_loss did not improve from 0.69268\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.6939 - acc: 0.4185 - val_loss: 0.6938 - val_acc: 0.4101 - lr: 2.2500e-04\n",
      "Epoch 23/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.6944 - acc: 0.4217\n",
      "Epoch 23: val_loss did not improve from 0.69268\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.6938 - acc: 0.4195 - val_loss: 0.6937 - val_acc: 0.4101 - lr: 2.2500e-04\n",
      "Epoch 24/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.6939 - acc: 0.5115\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0001687500080151949.\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.69268\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.6938 - acc: 0.5103 - val_loss: 0.6935 - val_acc: 0.4101 - lr: 2.2500e-04\n",
      "Epoch 24: early stopping\n",
      "Epoch 1/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.6196 - acc: 0.7916\n",
      "Epoch 1: val_loss improved from inf to 1.56361, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_mobilenet_weights.h5\n",
      "180/180 [==============================] - 9s 25ms/step - loss: 0.6168 - acc: 0.7927 - val_loss: 1.5636 - val_acc: 0.5924 - lr: 3.0000e-04\n",
      "Epoch 2/160\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.4116 - acc: 0.8408\n",
      "Epoch 2: val_loss improved from 1.56361 to 1.53636, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_mobilenet_weights.h5\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.4116 - acc: 0.8408 - val_loss: 1.5364 - val_acc: 0.6151 - lr: 3.0000e-04\n",
      "Epoch 3/160\n",
      "179/180 [============================>.] - ETA: 0s - loss: 0.3561 - acc: 0.8635\n",
      "Epoch 3: val_loss improved from 1.53636 to 0.37543, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_mobilenet_weights.h5\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.3609 - acc: 0.8628 - val_loss: 0.3754 - val_acc: 0.8568 - lr: 3.0000e-04\n",
      "Epoch 4/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.3191 - acc: 0.8807\n",
      "Epoch 4: val_loss improved from 0.37543 to 0.30404, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_mobilenet_weights.h5\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.3164 - acc: 0.8813 - val_loss: 0.3040 - val_acc: 0.8918 - lr: 3.0000e-04\n",
      "Epoch 5/160\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.2941 - acc: 0.8845\n",
      "Epoch 5: val_loss improved from 0.30404 to 0.21822, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_mobilenet_weights.h5\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.2941 - acc: 0.8845 - val_loss: 0.2182 - val_acc: 0.9129 - lr: 3.0000e-04\n",
      "Epoch 6/160\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.2863 - acc: 0.8953\n",
      "Epoch 6: val_loss did not improve from 0.21822\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2863 - acc: 0.8953 - val_loss: 0.2629 - val_acc: 0.8853 - lr: 3.0000e-04\n",
      "Epoch 7/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.2401 - acc: 0.9006\n",
      "Epoch 7: val_loss improved from 0.21822 to 0.19057, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_mobilenet_weights.h5\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.2390 - acc: 0.9016 - val_loss: 0.1906 - val_acc: 0.9308 - lr: 3.0000e-04\n",
      "Epoch 8/160\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.2155 - acc: 0.9169\n",
      "Epoch 8: val_loss did not improve from 0.19057\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2155 - acc: 0.9169 - val_loss: 0.2391 - val_acc: 0.9121 - lr: 3.0000e-04\n",
      "Epoch 9/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2027 - acc: 0.9213\n",
      "Epoch 9: val_loss improved from 0.19057 to 0.16751, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_mobilenet_weights.h5\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.2017 - acc: 0.9211 - val_loss: 0.1675 - val_acc: 0.9390 - lr: 3.0000e-04\n",
      "Epoch 10/160\n",
      "179/180 [============================>.] - ETA: 0s - loss: 0.2085 - acc: 0.9238\n",
      "Epoch 10: val_loss did not improve from 0.16751\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2081 - acc: 0.9243 - val_loss: 0.2807 - val_acc: 0.8959 - lr: 3.0000e-04\n",
      "Epoch 11/160\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.1989 - acc: 0.9264\n",
      "Epoch 11: val_loss did not improve from 0.16751\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1989 - acc: 0.9264 - val_loss: 0.2678 - val_acc: 0.8967 - lr: 3.0000e-04\n",
      "Epoch 12/160\n",
      "179/180 [============================>.] - ETA: 0s - loss: 0.2031 - acc: 0.9277\n",
      "Epoch 12: val_loss improved from 0.16751 to 0.15792, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_mobilenet_weights.h5\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.2024 - acc: 0.9281 - val_loss: 0.1579 - val_acc: 0.9357 - lr: 3.0000e-04\n",
      "Epoch 13/160\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.1676 - acc: 0.9365\n",
      "Epoch 13: val_loss did not improve from 0.15792\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1676 - acc: 0.9365 - val_loss: 0.3060 - val_acc: 0.8836 - lr: 3.0000e-04\n",
      "Epoch 14/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.1705 - acc: 0.9407\n",
      "Epoch 14: val_loss improved from 0.15792 to 0.15518, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_mobilenet_weights.h5\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.1703 - acc: 0.9407 - val_loss: 0.1552 - val_acc: 0.9439 - lr: 3.0000e-04\n",
      "Epoch 15/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1552 - acc: 0.9442\n",
      "Epoch 15: val_loss did not improve from 0.15518\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1560 - acc: 0.9438 - val_loss: 0.1792 - val_acc: 0.9243 - lr: 3.0000e-04\n",
      "Epoch 16/160\n",
      "179/180 [============================>.] - ETA: 0s - loss: 0.1502 - acc: 0.9488\n",
      "Epoch 16: val_loss did not improve from 0.15518\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1499 - acc: 0.9487 - val_loss: 0.2614 - val_acc: 0.9032 - lr: 3.0000e-04\n",
      "Epoch 17/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.1502 - acc: 0.9507\n",
      "Epoch 17: val_loss did not improve from 0.15518\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1510 - acc: 0.9497 - val_loss: 0.2167 - val_acc: 0.9235 - lr: 3.0000e-04\n",
      "Epoch 18/160\n",
      "179/180 [============================>.] - ETA: 0s - loss: 0.1372 - acc: 0.9505\n",
      "Epoch 18: val_loss did not improve from 0.15518\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1365 - acc: 0.9508 - val_loss: 0.2059 - val_acc: 0.9260 - lr: 3.0000e-04\n",
      "Epoch 19/160\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.1241 - acc: 0.9497\n",
      "Epoch 19: val_loss did not improve from 0.15518\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1241 - acc: 0.9497 - val_loss: 0.5790 - val_acc: 0.8129 - lr: 3.0000e-04\n",
      "Epoch 20/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.1226 - acc: 0.9496\n",
      "Epoch 20: val_loss did not improve from 0.15518\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1229 - acc: 0.9494 - val_loss: 0.2384 - val_acc: 0.9325 - lr: 3.0000e-04\n",
      "Epoch 21/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1144 - acc: 0.9580\n",
      "Epoch 21: val_loss did not improve from 0.15518\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1143 - acc: 0.9581 - val_loss: 0.1819 - val_acc: 0.9325 - lr: 3.0000e-04\n",
      "Epoch 22/160\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.1369 - acc: 0.9476\n",
      "Epoch 22: val_loss did not improve from 0.15518\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1369 - acc: 0.9476 - val_loss: 0.2354 - val_acc: 0.9162 - lr: 3.0000e-04\n",
      "Epoch 23/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.1314 - acc: 0.9553\n",
      "Epoch 23: val_loss did not improve from 0.15518\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1329 - acc: 0.9536 - val_loss: 0.2980 - val_acc: 0.8983 - lr: 3.0000e-04\n",
      "Epoch 24/160\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.1230 - acc: 0.9560\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 0.00022500001068692654.\n",
      "\n",
      "Epoch 24: val_loss did not improve from 0.15518\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1230 - acc: 0.9560 - val_loss: 0.3347 - val_acc: 0.8983 - lr: 3.0000e-04\n",
      "Epoch 25/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.1045 - acc: 0.9595\n",
      "Epoch 25: val_loss did not improve from 0.15518\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1047 - acc: 0.9592 - val_loss: 0.1703 - val_acc: 0.9406 - lr: 2.2500e-04\n",
      "Epoch 26/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.0843 - acc: 0.9673\n",
      "Epoch 26: val_loss did not improve from 0.15518\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.0864 - acc: 0.9668 - val_loss: 0.1662 - val_acc: 0.9447 - lr: 2.2500e-04\n",
      "Epoch 27/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0853 - acc: 0.9686\n",
      "Epoch 27: val_loss did not improve from 0.15518\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.0872 - acc: 0.9682 - val_loss: 0.2208 - val_acc: 0.9203 - lr: 2.2500e-04\n",
      "Epoch 28/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0673 - acc: 0.9760\n",
      "Epoch 28: val_loss did not improve from 0.15518\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.0669 - acc: 0.9763 - val_loss: 0.1604 - val_acc: 0.9463 - lr: 2.2500e-04\n",
      "Epoch 29/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.0611 - acc: 0.9787\n",
      "Epoch 29: val_loss did not improve from 0.15518\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.0606 - acc: 0.9791 - val_loss: 0.2212 - val_acc: 0.9373 - lr: 2.2500e-04\n",
      "Epoch 30/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.0778 - acc: 0.9673\n",
      "Epoch 30: val_loss did not improve from 0.15518\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.0793 - acc: 0.9665 - val_loss: 0.2268 - val_acc: 0.9276 - lr: 2.2500e-04\n",
      "Epoch 31/160\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.0728 - acc: 0.9759\n",
      "Epoch 31: val_loss did not improve from 0.15518\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.0728 - acc: 0.9759 - val_loss: 0.2366 - val_acc: 0.9235 - lr: 2.2500e-04\n",
      "Epoch 32/160\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.0612 - acc: 0.9784\n",
      "Epoch 32: val_loss did not improve from 0.15518\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.0612 - acc: 0.9784 - val_loss: 0.3044 - val_acc: 0.8983 - lr: 2.2500e-04\n",
      "Epoch 33/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0469 - acc: 0.9831\n",
      "Epoch 33: val_loss did not improve from 0.15518\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.0467 - acc: 0.9832 - val_loss: 0.2266 - val_acc: 0.9268 - lr: 2.2500e-04\n",
      "Epoch 34/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.0703 - acc: 0.9741\n",
      "Epoch 34: val_loss improved from 0.15518 to 0.14210, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_mobilenet_weights.h5\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.0693 - acc: 0.9745 - val_loss: 0.1421 - val_acc: 0.9569 - lr: 2.2500e-04\n",
      "Epoch 35/160\n",
      "179/180 [============================>.] - ETA: 0s - loss: 0.0776 - acc: 0.9719\n",
      "Epoch 35: val_loss did not improve from 0.14210\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.0775 - acc: 0.9717 - val_loss: 0.2203 - val_acc: 0.9447 - lr: 2.2500e-04\n",
      "Epoch 36/160\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.0601 - acc: 0.9770\n",
      "Epoch 36: val_loss did not improve from 0.14210\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.0601 - acc: 0.9770 - val_loss: 0.1677 - val_acc: 0.9561 - lr: 2.2500e-04\n",
      "Epoch 37/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0468 - acc: 0.9841\n",
      "Epoch 37: val_loss did not improve from 0.14210\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.0467 - acc: 0.9843 - val_loss: 0.1870 - val_acc: 0.9455 - lr: 2.2500e-04\n",
      "Epoch 38/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.0567 - acc: 0.9794\n",
      "Epoch 38: val_loss did not improve from 0.14210\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.0565 - acc: 0.9794 - val_loss: 0.1721 - val_acc: 0.9422 - lr: 2.2500e-04\n",
      "Epoch 39/160\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.0599 - acc: 0.9791\n",
      "Epoch 39: val_loss did not improve from 0.14210\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.0599 - acc: 0.9791 - val_loss: 0.4632 - val_acc: 0.9178 - lr: 2.2500e-04\n",
      "Epoch 40/160\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.0577 - acc: 0.9784\n",
      "Epoch 40: val_loss did not improve from 0.14210\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.0577 - acc: 0.9784 - val_loss: 0.2004 - val_acc: 0.9382 - lr: 2.2500e-04\n",
      "Epoch 41/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0649 - acc: 0.9785\n",
      "Epoch 41: val_loss did not improve from 0.14210\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.0647 - acc: 0.9787 - val_loss: 0.2785 - val_acc: 0.9276 - lr: 2.2500e-04\n",
      "Epoch 42/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0508 - acc: 0.9813\n",
      "Epoch 42: val_loss did not improve from 0.14210\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.0503 - acc: 0.9815 - val_loss: 0.4130 - val_acc: 0.9235 - lr: 2.2500e-04\n",
      "Epoch 43/160\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.0449 - acc: 0.9832\n",
      "Epoch 43: val_loss did not improve from 0.14210\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.0449 - acc: 0.9832 - val_loss: 0.2279 - val_acc: 0.9414 - lr: 2.2500e-04\n",
      "Epoch 44/160\n",
      "179/180 [============================>.] - ETA: 0s - loss: 0.0438 - acc: 0.9853\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.0001687500080151949.\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.14210\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.0436 - acc: 0.9853 - val_loss: 0.3091 - val_acc: 0.9398 - lr: 2.2500e-04\n",
      "Epoch 45/160\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.0238 - acc: 0.9923\n",
      "Epoch 45: val_loss did not improve from 0.14210\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.0238 - acc: 0.9923 - val_loss: 0.3728 - val_acc: 0.9251 - lr: 1.6875e-04\n",
      "Epoch 46/160\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.0317 - acc: 0.9888\n",
      "Epoch 46: val_loss did not improve from 0.14210\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.0317 - acc: 0.9888 - val_loss: 0.1963 - val_acc: 0.9430 - lr: 1.6875e-04\n",
      "Epoch 47/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.0324 - acc: 0.9872\n",
      "Epoch 47: val_loss did not improve from 0.14210\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.0343 - acc: 0.9867 - val_loss: 0.2588 - val_acc: 0.9284 - lr: 1.6875e-04\n",
      "Epoch 48/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.0357 - acc: 0.9854\n",
      "Epoch 48: val_loss did not improve from 0.14210\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.0367 - acc: 0.9850 - val_loss: 0.1683 - val_acc: 0.9577 - lr: 1.6875e-04\n",
      "Epoch 49/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0256 - acc: 0.9905\n",
      "Epoch 49: val_loss did not improve from 0.14210\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.0260 - acc: 0.9899 - val_loss: 0.1591 - val_acc: 0.9544 - lr: 1.6875e-04\n",
      "Epoch 50/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.0252 - acc: 0.9922\n",
      "Epoch 50: val_loss did not improve from 0.14210\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.0248 - acc: 0.9923 - val_loss: 0.2965 - val_acc: 0.9577 - lr: 1.6875e-04\n",
      "Epoch 51/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.0435 - acc: 0.9883\n",
      "Epoch 51: val_loss did not improve from 0.14210\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.0433 - acc: 0.9881 - val_loss: 0.2097 - val_acc: 0.9390 - lr: 1.6875e-04\n",
      "Epoch 52/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0239 - acc: 0.9908\n",
      "Epoch 52: val_loss did not improve from 0.14210\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.0251 - acc: 0.9906 - val_loss: 0.2392 - val_acc: 0.9512 - lr: 1.6875e-04\n",
      "Epoch 53/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0252 - acc: 0.9940\n",
      "Epoch 53: val_loss did not improve from 0.14210\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.0249 - acc: 0.9941 - val_loss: 0.2404 - val_acc: 0.9487 - lr: 1.6875e-04\n",
      "Epoch 54/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.0378 - acc: 0.9865\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 0.00012656250328291208.\n",
      "\n",
      "Epoch 54: val_loss did not improve from 0.14210\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.0373 - acc: 0.9867 - val_loss: 0.1803 - val_acc: 0.9585 - lr: 1.6875e-04\n",
      "Epoch 54: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raulpg/anaconda3/envs/tfm_tf/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/raulpg/anaconda3/envs/tfm_tf/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/raulpg/anaconda3/envs/tfm_tf/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/raulpg/anaconda3/envs/tfm_tf/lib/python3.11/site-packages/keras/src/preprocessing/image.py:2093: UserWarning: Expected input to be images (as Numpy array) following the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3 or 4 channels on axis 3. However, it was passed an array with shape (2865, 48, 48, 12) (12 channels).\n",
      "  warnings.warn(\n",
      "/home/raulpg/anaconda3/envs/tfm_tf/lib/python3.11/site-packages/keras/src/preprocessing/image.py:766: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3, or 4 channels on axis 3. However, it was passed an array with shape (2865, 48, 48, 12) (12 channels).\n",
      "  warnings.warn(\n",
      "/home/raulpg/anaconda3/envs/tfm_tf/lib/python3.11/site-packages/keras/src/preprocessing/image.py:766: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3, or 4 channels on axis 3. However, it was passed an array with shape (1229, 48, 48, 12) (12 channels).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Epoch 1/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.6779 - acc: 0.5644\n",
      "Epoch 1: val_loss improved from inf to 0.66983, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 5s 20ms/step - loss: 0.6776 - acc: 0.5651 - val_loss: 0.6698 - val_acc: 0.5899 - lr: 3.0000e-04\n",
      "Epoch 2/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.6023 - acc: 0.6844\n",
      "Epoch 2: val_loss improved from 0.66983 to 0.51910, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.6013 - acc: 0.6848 - val_loss: 0.5191 - val_acc: 0.7323 - lr: 3.0000e-04\n",
      "Epoch 3/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.5509 - acc: 0.7349\n",
      "Epoch 3: val_loss did not improve from 0.51910\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.5515 - acc: 0.7340 - val_loss: 0.6013 - val_acc: 0.5997 - lr: 3.0000e-04\n",
      "Epoch 4/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.5438 - acc: 0.7254\n",
      "Epoch 4: val_loss improved from 0.51910 to 0.49634, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.5431 - acc: 0.7250 - val_loss: 0.4963 - val_acc: 0.7526 - lr: 3.0000e-04\n",
      "Epoch 5/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.5218 - acc: 0.7617\n",
      "Epoch 5: val_loss improved from 0.49634 to 0.49399, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.5226 - acc: 0.7613 - val_loss: 0.4940 - val_acc: 0.7510 - lr: 3.0000e-04\n",
      "Epoch 6/160\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.5316 - acc: 0.7459\n",
      "Epoch 6: val_loss improved from 0.49399 to 0.47814, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.5316 - acc: 0.7459 - val_loss: 0.4781 - val_acc: 0.7714 - lr: 3.0000e-04\n",
      "Epoch 7/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.4971 - acc: 0.7663\n",
      "Epoch 7: val_loss improved from 0.47814 to 0.44645, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.4979 - acc: 0.7668 - val_loss: 0.4464 - val_acc: 0.7876 - lr: 3.0000e-04\n",
      "Epoch 8/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.5422 - acc: 0.7462\n",
      "Epoch 8: val_loss did not improve from 0.44645\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.5420 - acc: 0.7473 - val_loss: 0.5169 - val_acc: 0.7445 - lr: 3.0000e-04\n",
      "Epoch 9/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.4778 - acc: 0.7783\n",
      "Epoch 9: val_loss did not improve from 0.44645\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.4803 - acc: 0.7766 - val_loss: 0.4985 - val_acc: 0.7461 - lr: 3.0000e-04\n",
      "Epoch 10/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.4630 - acc: 0.7906\n",
      "Epoch 10: val_loss did not improve from 0.44645\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.4647 - acc: 0.7892 - val_loss: 0.4708 - val_acc: 0.7592 - lr: 3.0000e-04\n",
      "Epoch 11/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.4612 - acc: 0.7917\n",
      "Epoch 11: val_loss did not improve from 0.44645\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.4612 - acc: 0.7913 - val_loss: 0.5066 - val_acc: 0.7201 - lr: 3.0000e-04\n",
      "Epoch 12/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.4328 - acc: 0.8108\n",
      "Epoch 12: val_loss improved from 0.44645 to 0.43582, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.4321 - acc: 0.8115 - val_loss: 0.4358 - val_acc: 0.7990 - lr: 3.0000e-04\n",
      "Epoch 13/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.4188 - acc: 0.8101\n",
      "Epoch 13: val_loss improved from 0.43582 to 0.38442, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.4182 - acc: 0.8101 - val_loss: 0.3844 - val_acc: 0.8226 - lr: 3.0000e-04\n",
      "Epoch 14/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.4121 - acc: 0.8118\n",
      "Epoch 14: val_loss did not improve from 0.38442\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.4113 - acc: 0.8119 - val_loss: 0.4267 - val_acc: 0.8031 - lr: 3.0000e-04\n",
      "Epoch 15/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.3866 - acc: 0.8337\n",
      "Epoch 15: val_loss improved from 0.38442 to 0.37457, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.3883 - acc: 0.8332 - val_loss: 0.3746 - val_acc: 0.8275 - lr: 3.0000e-04\n",
      "Epoch 16/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.3821 - acc: 0.8314\n",
      "Epoch 16: val_loss improved from 0.37457 to 0.36476, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.3806 - acc: 0.8325 - val_loss: 0.3648 - val_acc: 0.8324 - lr: 3.0000e-04\n",
      "Epoch 17/160\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.3697 - acc: 0.8373\n",
      "Epoch 17: val_loss did not improve from 0.36476\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.3697 - acc: 0.8373 - val_loss: 0.4019 - val_acc: 0.8259 - lr: 3.0000e-04\n",
      "Epoch 18/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.3630 - acc: 0.8442\n",
      "Epoch 18: val_loss did not improve from 0.36476\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.3623 - acc: 0.8436 - val_loss: 0.4853 - val_acc: 0.7714 - lr: 3.0000e-04\n",
      "Epoch 19/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.3546 - acc: 0.8468\n",
      "Epoch 19: val_loss improved from 0.36476 to 0.32889, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.3543 - acc: 0.8471 - val_loss: 0.3289 - val_acc: 0.8430 - lr: 3.0000e-04\n",
      "Epoch 20/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.3344 - acc: 0.8517\n",
      "Epoch 20: val_loss did not improve from 0.32889\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.3355 - acc: 0.8513 - val_loss: 0.3308 - val_acc: 0.8446 - lr: 3.0000e-04\n",
      "Epoch 21/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.3379 - acc: 0.8553\n",
      "Epoch 21: val_loss did not improve from 0.32889\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.3390 - acc: 0.8545 - val_loss: 0.3725 - val_acc: 0.8446 - lr: 3.0000e-04\n",
      "Epoch 22/160\n",
      "179/180 [============================>.] - ETA: 0s - loss: 0.3303 - acc: 0.8592\n",
      "Epoch 22: val_loss improved from 0.32889 to 0.32112, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.3292 - acc: 0.8597 - val_loss: 0.3211 - val_acc: 0.8592 - lr: 3.0000e-04\n",
      "Epoch 23/160\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.3115 - acc: 0.8663\n",
      "Epoch 23: val_loss improved from 0.32112 to 0.31830, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.3115 - acc: 0.8663 - val_loss: 0.3183 - val_acc: 0.8544 - lr: 3.0000e-04\n",
      "Epoch 24/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.3030 - acc: 0.8722\n",
      "Epoch 24: val_loss improved from 0.31830 to 0.31158, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.3034 - acc: 0.8723 - val_loss: 0.3116 - val_acc: 0.8723 - lr: 3.0000e-04\n",
      "Epoch 25/160\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.3059 - acc: 0.8729\n",
      "Epoch 25: val_loss improved from 0.31158 to 0.27684, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.3059 - acc: 0.8729 - val_loss: 0.2768 - val_acc: 0.8836 - lr: 3.0000e-04\n",
      "Epoch 26/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.3097 - acc: 0.8669\n",
      "Epoch 26: val_loss did not improve from 0.27684\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.3102 - acc: 0.8660 - val_loss: 0.2956 - val_acc: 0.8714 - lr: 3.0000e-04\n",
      "Epoch 27/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.3031 - acc: 0.8754\n",
      "Epoch 27: val_loss did not improve from 0.27684\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.3022 - acc: 0.8761 - val_loss: 0.2772 - val_acc: 0.8845 - lr: 3.0000e-04\n",
      "Epoch 28/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.3338 - acc: 0.8655\n",
      "Epoch 28: val_loss did not improve from 0.27684\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.3340 - acc: 0.8649 - val_loss: 0.3393 - val_acc: 0.8544 - lr: 3.0000e-04\n",
      "Epoch 29/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2918 - acc: 0.8835\n",
      "Epoch 29: val_loss improved from 0.27684 to 0.26857, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2919 - acc: 0.8831 - val_loss: 0.2686 - val_acc: 0.8820 - lr: 3.0000e-04\n",
      "Epoch 30/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2819 - acc: 0.8867\n",
      "Epoch 30: val_loss did not improve from 0.26857\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.2808 - acc: 0.8880 - val_loss: 0.3352 - val_acc: 0.8535 - lr: 3.0000e-04\n",
      "Epoch 31/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2778 - acc: 0.8853\n",
      "Epoch 31: val_loss did not improve from 0.26857\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2780 - acc: 0.8855 - val_loss: 0.2958 - val_acc: 0.8706 - lr: 3.0000e-04\n",
      "Epoch 32/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2792 - acc: 0.8878\n",
      "Epoch 32: val_loss did not improve from 0.26857\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2782 - acc: 0.8887 - val_loss: 0.2757 - val_acc: 0.8779 - lr: 3.0000e-04\n",
      "Epoch 33/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2700 - acc: 0.8800\n",
      "Epoch 33: val_loss did not improve from 0.26857\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2686 - acc: 0.8806 - val_loss: 0.2920 - val_acc: 0.8779 - lr: 3.0000e-04\n",
      "Epoch 34/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.3037 - acc: 0.8750\n",
      "Epoch 34: val_loss did not improve from 0.26857\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.3027 - acc: 0.8757 - val_loss: 0.2924 - val_acc: 0.8779 - lr: 3.0000e-04\n",
      "Epoch 35/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.2637 - acc: 0.8924\n",
      "Epoch 35: val_loss improved from 0.26857 to 0.25180, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.2647 - acc: 0.8918 - val_loss: 0.2518 - val_acc: 0.8950 - lr: 3.0000e-04\n",
      "Epoch 36/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2633 - acc: 0.8930\n",
      "Epoch 36: val_loss did not improve from 0.25180\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2643 - acc: 0.8928 - val_loss: 0.2799 - val_acc: 0.8779 - lr: 3.0000e-04\n",
      "Epoch 37/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2650 - acc: 0.8948\n",
      "Epoch 37: val_loss did not improve from 0.25180\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2652 - acc: 0.8949 - val_loss: 0.3759 - val_acc: 0.8373 - lr: 3.0000e-04\n",
      "Epoch 38/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2549 - acc: 0.8948\n",
      "Epoch 38: val_loss improved from 0.25180 to 0.25163, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2557 - acc: 0.8932 - val_loss: 0.2516 - val_acc: 0.8820 - lr: 3.0000e-04\n",
      "Epoch 39/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2619 - acc: 0.8998\n",
      "Epoch 39: val_loss did not improve from 0.25163\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2619 - acc: 0.9002 - val_loss: 0.2959 - val_acc: 0.8788 - lr: 3.0000e-04\n",
      "Epoch 40/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2592 - acc: 0.8899\n",
      "Epoch 40: val_loss improved from 0.25163 to 0.24181, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2580 - acc: 0.8904 - val_loss: 0.2418 - val_acc: 0.9048 - lr: 3.0000e-04\n",
      "Epoch 41/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2493 - acc: 0.8952\n",
      "Epoch 41: val_loss did not improve from 0.24181\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.2486 - acc: 0.8953 - val_loss: 0.2439 - val_acc: 0.8910 - lr: 3.0000e-04\n",
      "Epoch 42/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2387 - acc: 0.9096\n",
      "Epoch 42: val_loss did not improve from 0.24181\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.2380 - acc: 0.9103 - val_loss: 0.2533 - val_acc: 0.8967 - lr: 3.0000e-04\n",
      "Epoch 43/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2386 - acc: 0.9022\n",
      "Epoch 43: val_loss did not improve from 0.24181\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.2402 - acc: 0.9012 - val_loss: 0.2938 - val_acc: 0.8739 - lr: 3.0000e-04\n",
      "Epoch 44/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2329 - acc: 0.9079\n",
      "Epoch 44: val_loss did not improve from 0.24181\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.2337 - acc: 0.9075 - val_loss: 0.2622 - val_acc: 0.8845 - lr: 3.0000e-04\n",
      "Epoch 45/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2518 - acc: 0.9012\n",
      "Epoch 45: val_loss did not improve from 0.24181\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.2526 - acc: 0.9009 - val_loss: 0.2963 - val_acc: 0.8820 - lr: 3.0000e-04\n",
      "Epoch 46/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2393 - acc: 0.9082\n",
      "Epoch 46: val_loss did not improve from 0.24181\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.2402 - acc: 0.9079 - val_loss: 0.2427 - val_acc: 0.8967 - lr: 3.0000e-04\n",
      "Epoch 47/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.2201 - acc: 0.9141\n",
      "Epoch 47: val_loss did not improve from 0.24181\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.2197 - acc: 0.9141 - val_loss: 0.2446 - val_acc: 0.8893 - lr: 3.0000e-04\n",
      "Epoch 48/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2355 - acc: 0.9114\n",
      "Epoch 48: val_loss improved from 0.24181 to 0.23654, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2340 - acc: 0.9120 - val_loss: 0.2365 - val_acc: 0.9024 - lr: 3.0000e-04\n",
      "Epoch 49/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2350 - acc: 0.9036\n",
      "Epoch 49: val_loss improved from 0.23654 to 0.23445, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2330 - acc: 0.9044 - val_loss: 0.2344 - val_acc: 0.9081 - lr: 3.0000e-04\n",
      "Epoch 50/160\n",
      "179/180 [============================>.] - ETA: 0s - loss: 0.2173 - acc: 0.9115\n",
      "Epoch 50: val_loss did not improve from 0.23445\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.2177 - acc: 0.9113 - val_loss: 0.2537 - val_acc: 0.8975 - lr: 3.0000e-04\n",
      "Epoch 51/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2238 - acc: 0.9135\n",
      "Epoch 51: val_loss improved from 0.23445 to 0.23359, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2229 - acc: 0.9138 - val_loss: 0.2336 - val_acc: 0.8975 - lr: 3.0000e-04\n",
      "Epoch 52/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2143 - acc: 0.9199\n",
      "Epoch 52: val_loss improved from 0.23359 to 0.21021, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2131 - acc: 0.9204 - val_loss: 0.2102 - val_acc: 0.9186 - lr: 3.0000e-04\n",
      "Epoch 53/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2127 - acc: 0.9163\n",
      "Epoch 53: val_loss did not improve from 0.21021\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.2110 - acc: 0.9173 - val_loss: 0.2250 - val_acc: 0.9072 - lr: 3.0000e-04\n",
      "Epoch 54/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2184 - acc: 0.9149\n",
      "Epoch 54: val_loss did not improve from 0.21021\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2173 - acc: 0.9152 - val_loss: 0.2287 - val_acc: 0.9089 - lr: 3.0000e-04\n",
      "Epoch 55/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2132 - acc: 0.9163\n",
      "Epoch 55: val_loss did not improve from 0.21021\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.2128 - acc: 0.9155 - val_loss: 0.2393 - val_acc: 0.8999 - lr: 3.0000e-04\n",
      "Epoch 56/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2114 - acc: 0.9153\n",
      "Epoch 56: val_loss improved from 0.21021 to 0.18451, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2121 - acc: 0.9155 - val_loss: 0.1845 - val_acc: 0.9292 - lr: 3.0000e-04\n",
      "Epoch 57/160\n",
      "179/180 [============================>.] - ETA: 0s - loss: 0.2160 - acc: 0.9130\n",
      "Epoch 57: val_loss did not improve from 0.18451\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.2154 - acc: 0.9131 - val_loss: 0.1981 - val_acc: 0.9186 - lr: 3.0000e-04\n",
      "Epoch 58/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2311 - acc: 0.9170\n",
      "Epoch 58: val_loss did not improve from 0.18451\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2303 - acc: 0.9173 - val_loss: 0.2304 - val_acc: 0.9040 - lr: 3.0000e-04\n",
      "Epoch 59/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2469 - acc: 0.9114\n",
      "Epoch 59: val_loss did not improve from 0.18451\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2478 - acc: 0.9113 - val_loss: 0.3119 - val_acc: 0.8771 - lr: 3.0000e-04\n",
      "Epoch 60/160\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.2517 - acc: 0.9016\n",
      "Epoch 60: val_loss did not improve from 0.18451\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.2517 - acc: 0.9016 - val_loss: 0.2212 - val_acc: 0.9121 - lr: 3.0000e-04\n",
      "Epoch 61/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.2074 - acc: 0.9176\n",
      "Epoch 61: val_loss did not improve from 0.18451\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.2077 - acc: 0.9173 - val_loss: 0.2441 - val_acc: 0.9024 - lr: 3.0000e-04\n",
      "Epoch 62/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2183 - acc: 0.9132\n",
      "Epoch 62: val_loss did not improve from 0.18451\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.2237 - acc: 0.9117 - val_loss: 0.2798 - val_acc: 0.8959 - lr: 3.0000e-04\n",
      "Epoch 63/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2543 - acc: 0.9079\n",
      "Epoch 63: val_loss did not improve from 0.18451\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2539 - acc: 0.9082 - val_loss: 0.2234 - val_acc: 0.8967 - lr: 3.0000e-04\n",
      "Epoch 64/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1993 - acc: 0.9167\n",
      "Epoch 64: val_loss did not improve from 0.18451\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1996 - acc: 0.9173 - val_loss: 0.2026 - val_acc: 0.9138 - lr: 3.0000e-04\n",
      "Epoch 65/160\n",
      "179/180 [============================>.] - ETA: 0s - loss: 0.1890 - acc: 0.9266\n",
      "Epoch 65: val_loss did not improve from 0.18451\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.1898 - acc: 0.9264 - val_loss: 0.2054 - val_acc: 0.9170 - lr: 3.0000e-04\n",
      "Epoch 66/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1883 - acc: 0.9234\n",
      "Epoch 66: ReduceLROnPlateau reducing learning rate to 0.00022500001068692654.\n",
      "\n",
      "Epoch 66: val_loss did not improve from 0.18451\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1874 - acc: 0.9232 - val_loss: 0.2794 - val_acc: 0.8959 - lr: 3.0000e-04\n",
      "Epoch 67/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.1868 - acc: 0.9294\n",
      "Epoch 67: val_loss did not improve from 0.18451\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1850 - acc: 0.9302 - val_loss: 0.1996 - val_acc: 0.9186 - lr: 2.2500e-04\n",
      "Epoch 68/160\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.1796 - acc: 0.9291\n",
      "Epoch 68: val_loss did not improve from 0.18451\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1796 - acc: 0.9291 - val_loss: 0.1872 - val_acc: 0.9243 - lr: 2.2500e-04\n",
      "Epoch 69/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1658 - acc: 0.9382\n",
      "Epoch 69: val_loss did not improve from 0.18451\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1649 - acc: 0.9389 - val_loss: 0.1983 - val_acc: 0.9260 - lr: 2.2500e-04\n",
      "Epoch 70/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1595 - acc: 0.9361\n",
      "Epoch 70: val_loss did not improve from 0.18451\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1594 - acc: 0.9361 - val_loss: 0.2455 - val_acc: 0.9081 - lr: 2.2500e-04\n",
      "Epoch 71/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1684 - acc: 0.9298\n",
      "Epoch 71: val_loss did not improve from 0.18451\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1683 - acc: 0.9295 - val_loss: 0.2196 - val_acc: 0.9129 - lr: 2.2500e-04\n",
      "Epoch 72/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1576 - acc: 0.9379\n",
      "Epoch 72: val_loss improved from 0.18451 to 0.17952, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1576 - acc: 0.9372 - val_loss: 0.1795 - val_acc: 0.9317 - lr: 2.2500e-04\n",
      "Epoch 73/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1715 - acc: 0.9319\n",
      "Epoch 73: val_loss did not improve from 0.17952\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1720 - acc: 0.9316 - val_loss: 0.2541 - val_acc: 0.9024 - lr: 2.2500e-04\n",
      "Epoch 74/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1689 - acc: 0.9241\n",
      "Epoch 74: val_loss did not improve from 0.17952\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.1690 - acc: 0.9239 - val_loss: 0.2004 - val_acc: 0.9219 - lr: 2.2500e-04\n",
      "Epoch 75/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1602 - acc: 0.9368\n",
      "Epoch 75: val_loss did not improve from 0.17952\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.1612 - acc: 0.9365 - val_loss: 0.2475 - val_acc: 0.9105 - lr: 2.2500e-04\n",
      "Epoch 76/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1601 - acc: 0.9336\n",
      "Epoch 76: val_loss did not improve from 0.17952\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1607 - acc: 0.9333 - val_loss: 0.1964 - val_acc: 0.9308 - lr: 2.2500e-04\n",
      "Epoch 77/160\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.1572 - acc: 0.9393\n",
      "Epoch 77: val_loss did not improve from 0.17952\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.1572 - acc: 0.9393 - val_loss: 0.1890 - val_acc: 0.9251 - lr: 2.2500e-04\n",
      "Epoch 78/160\n",
      "179/180 [============================>.] - ETA: 0s - loss: 0.1597 - acc: 0.9368\n",
      "Epoch 78: val_loss improved from 0.17952 to 0.17803, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.1593 - acc: 0.9372 - val_loss: 0.1780 - val_acc: 0.9349 - lr: 2.2500e-04\n",
      "Epoch 79/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.1579 - acc: 0.9354\n",
      "Epoch 79: val_loss did not improve from 0.17803\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1584 - acc: 0.9351 - val_loss: 0.1861 - val_acc: 0.9243 - lr: 2.2500e-04\n",
      "Epoch 80/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1503 - acc: 0.9425\n",
      "Epoch 80: val_loss did not improve from 0.17803\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1505 - acc: 0.9424 - val_loss: 0.3032 - val_acc: 0.8975 - lr: 2.2500e-04\n",
      "Epoch 81/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1584 - acc: 0.9418\n",
      "Epoch 81: val_loss did not improve from 0.17803\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1597 - acc: 0.9414 - val_loss: 0.2024 - val_acc: 0.9260 - lr: 2.2500e-04\n",
      "Epoch 82/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1535 - acc: 0.9421\n",
      "Epoch 82: val_loss did not improve from 0.17803\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1545 - acc: 0.9424 - val_loss: 0.2187 - val_acc: 0.9211 - lr: 2.2500e-04\n",
      "Epoch 83/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1547 - acc: 0.9396\n",
      "Epoch 83: val_loss did not improve from 0.17803\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1561 - acc: 0.9386 - val_loss: 0.1835 - val_acc: 0.9406 - lr: 2.2500e-04\n",
      "Epoch 84/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1628 - acc: 0.9372\n",
      "Epoch 84: val_loss did not improve from 0.17803\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1621 - acc: 0.9379 - val_loss: 0.2415 - val_acc: 0.9032 - lr: 2.2500e-04\n",
      "Epoch 85/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1652 - acc: 0.9358\n",
      "Epoch 85: val_loss did not improve from 0.17803\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1654 - acc: 0.9358 - val_loss: 0.1849 - val_acc: 0.9284 - lr: 2.2500e-04\n",
      "Epoch 86/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1509 - acc: 0.9446\n",
      "Epoch 86: val_loss did not improve from 0.17803\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1507 - acc: 0.9449 - val_loss: 0.2142 - val_acc: 0.9203 - lr: 2.2500e-04\n",
      "Epoch 87/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1649 - acc: 0.9365\n",
      "Epoch 87: val_loss did not improve from 0.17803\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1644 - acc: 0.9368 - val_loss: 0.2398 - val_acc: 0.9032 - lr: 2.2500e-04\n",
      "Epoch 88/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1409 - acc: 0.9425\n",
      "Epoch 88: ReduceLROnPlateau reducing learning rate to 0.0001687500080151949.\n",
      "\n",
      "Epoch 88: val_loss did not improve from 0.17803\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1394 - acc: 0.9431 - val_loss: 0.2039 - val_acc: 0.9260 - lr: 2.2500e-04\n",
      "Epoch 89/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1442 - acc: 0.9460\n",
      "Epoch 89: val_loss improved from 0.17803 to 0.17200, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.1430 - acc: 0.9462 - val_loss: 0.1720 - val_acc: 0.9398 - lr: 1.6875e-04\n",
      "Epoch 90/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1380 - acc: 0.9449\n",
      "Epoch 90: val_loss did not improve from 0.17200\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1376 - acc: 0.9452 - val_loss: 0.1820 - val_acc: 0.9292 - lr: 1.6875e-04\n",
      "Epoch 91/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1428 - acc: 0.9449\n",
      "Epoch 91: val_loss did not improve from 0.17200\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1420 - acc: 0.9455 - val_loss: 0.1887 - val_acc: 0.9260 - lr: 1.6875e-04\n",
      "Epoch 92/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1363 - acc: 0.9393\n",
      "Epoch 92: val_loss did not improve from 0.17200\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1356 - acc: 0.9400 - val_loss: 0.2046 - val_acc: 0.9317 - lr: 1.6875e-04\n",
      "Epoch 93/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2023 - acc: 0.9245\n",
      "Epoch 93: val_loss did not improve from 0.17200\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.2027 - acc: 0.9236 - val_loss: 0.2124 - val_acc: 0.9178 - lr: 1.6875e-04\n",
      "Epoch 94/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1450 - acc: 0.9403\n",
      "Epoch 94: val_loss did not improve from 0.17200\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1460 - acc: 0.9396 - val_loss: 0.2075 - val_acc: 0.9268 - lr: 1.6875e-04\n",
      "Epoch 95/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1401 - acc: 0.9499\n",
      "Epoch 95: val_loss did not improve from 0.17200\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1395 - acc: 0.9501 - val_loss: 0.2497 - val_acc: 0.9154 - lr: 1.6875e-04\n",
      "Epoch 96/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1240 - acc: 0.9548\n",
      "Epoch 96: val_loss did not improve from 0.17200\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1239 - acc: 0.9546 - val_loss: 0.2711 - val_acc: 0.8910 - lr: 1.6875e-04\n",
      "Epoch 97/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1340 - acc: 0.9435\n",
      "Epoch 97: val_loss improved from 0.17200 to 0.16895, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1360 - acc: 0.9428 - val_loss: 0.1689 - val_acc: 0.9365 - lr: 1.6875e-04\n",
      "Epoch 98/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1317 - acc: 0.9495\n",
      "Epoch 98: val_loss did not improve from 0.16895\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1307 - acc: 0.9501 - val_loss: 0.2071 - val_acc: 0.9317 - lr: 1.6875e-04\n",
      "Epoch 99/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1234 - acc: 0.9534\n",
      "Epoch 99: val_loss improved from 0.16895 to 0.16293, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1241 - acc: 0.9532 - val_loss: 0.1629 - val_acc: 0.9455 - lr: 1.6875e-04\n",
      "Epoch 100/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1291 - acc: 0.9506\n",
      "Epoch 100: val_loss did not improve from 0.16293\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1285 - acc: 0.9508 - val_loss: 0.3201 - val_acc: 0.9024 - lr: 1.6875e-04\n",
      "Epoch 101/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1138 - acc: 0.9566\n",
      "Epoch 101: val_loss did not improve from 0.16293\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1132 - acc: 0.9567 - val_loss: 0.1942 - val_acc: 0.9349 - lr: 1.6875e-04\n",
      "Epoch 102/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1263 - acc: 0.9485\n",
      "Epoch 102: val_loss did not improve from 0.16293\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1253 - acc: 0.9490 - val_loss: 0.2556 - val_acc: 0.9105 - lr: 1.6875e-04\n",
      "Epoch 103/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1219 - acc: 0.9523\n",
      "Epoch 103: val_loss did not improve from 0.16293\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1234 - acc: 0.9522 - val_loss: 0.1891 - val_acc: 0.9357 - lr: 1.6875e-04\n",
      "Epoch 104/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1079 - acc: 0.9541\n",
      "Epoch 104: val_loss did not improve from 0.16293\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1073 - acc: 0.9546 - val_loss: 0.1886 - val_acc: 0.9317 - lr: 1.6875e-04\n",
      "Epoch 105/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1271 - acc: 0.9527\n",
      "Epoch 105: val_loss did not improve from 0.16293\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1286 - acc: 0.9518 - val_loss: 0.1863 - val_acc: 0.9365 - lr: 1.6875e-04\n",
      "Epoch 106/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1265 - acc: 0.9552\n",
      "Epoch 106: val_loss did not improve from 0.16293\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1270 - acc: 0.9546 - val_loss: 0.1974 - val_acc: 0.9292 - lr: 1.6875e-04\n",
      "Epoch 107/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1069 - acc: 0.9576\n",
      "Epoch 107: val_loss did not improve from 0.16293\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1066 - acc: 0.9578 - val_loss: 0.1947 - val_acc: 0.9276 - lr: 1.6875e-04\n",
      "Epoch 108/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1100 - acc: 0.9598\n",
      "Epoch 108: val_loss did not improve from 0.16293\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1091 - acc: 0.9602 - val_loss: 0.1906 - val_acc: 0.9308 - lr: 1.6875e-04\n",
      "Epoch 109/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1059 - acc: 0.9583\n",
      "Epoch 109: ReduceLROnPlateau reducing learning rate to 0.00012656250328291208.\n",
      "\n",
      "Epoch 109: val_loss did not improve from 0.16293\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1056 - acc: 0.9588 - val_loss: 0.1972 - val_acc: 0.9308 - lr: 1.6875e-04\n",
      "Epoch 110/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1026 - acc: 0.9598\n",
      "Epoch 110: val_loss did not improve from 0.16293\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1026 - acc: 0.9595 - val_loss: 0.1987 - val_acc: 0.9317 - lr: 1.2656e-04\n",
      "Epoch 111/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1109 - acc: 0.9566\n",
      "Epoch 111: val_loss did not improve from 0.16293\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1099 - acc: 0.9571 - val_loss: 0.1824 - val_acc: 0.9382 - lr: 1.2656e-04\n",
      "Epoch 112/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0948 - acc: 0.9651\n",
      "Epoch 112: val_loss improved from 0.16293 to 0.15720, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.0944 - acc: 0.9651 - val_loss: 0.1572 - val_acc: 0.9439 - lr: 1.2656e-04\n",
      "Epoch 113/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1075 - acc: 0.9569\n",
      "Epoch 113: val_loss did not improve from 0.15720\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1073 - acc: 0.9567 - val_loss: 0.2059 - val_acc: 0.9284 - lr: 1.2656e-04\n",
      "Epoch 114/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0939 - acc: 0.9640\n",
      "Epoch 114: val_loss did not improve from 0.15720\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.0938 - acc: 0.9637 - val_loss: 0.1935 - val_acc: 0.9398 - lr: 1.2656e-04\n",
      "Epoch 115/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0912 - acc: 0.9601\n",
      "Epoch 115: val_loss did not improve from 0.15720\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.0917 - acc: 0.9602 - val_loss: 0.1768 - val_acc: 0.9414 - lr: 1.2656e-04\n",
      "Epoch 116/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.0959 - acc: 0.9617\n",
      "Epoch 116: val_loss did not improve from 0.15720\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.0961 - acc: 0.9613 - val_loss: 0.2051 - val_acc: 0.9349 - lr: 1.2656e-04\n",
      "Epoch 117/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1004 - acc: 0.9633\n",
      "Epoch 117: val_loss did not improve from 0.15720\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.0995 - acc: 0.9637 - val_loss: 0.2149 - val_acc: 0.9422 - lr: 1.2656e-04\n",
      "Epoch 118/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1018 - acc: 0.9619\n",
      "Epoch 118: val_loss did not improve from 0.15720\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.1017 - acc: 0.9620 - val_loss: 0.2042 - val_acc: 0.9365 - lr: 1.2656e-04\n",
      "Epoch 119/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0932 - acc: 0.9612\n",
      "Epoch 119: val_loss did not improve from 0.15720\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.0929 - acc: 0.9609 - val_loss: 0.2061 - val_acc: 0.9414 - lr: 1.2656e-04\n",
      "Epoch 120/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.0948 - acc: 0.9563\n",
      "Epoch 120: val_loss did not improve from 0.15720\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.0953 - acc: 0.9560 - val_loss: 0.1950 - val_acc: 0.9341 - lr: 1.2656e-04\n",
      "Epoch 121/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0882 - acc: 0.9622\n",
      "Epoch 121: val_loss did not improve from 0.15720\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.0888 - acc: 0.9623 - val_loss: 0.2166 - val_acc: 0.9341 - lr: 1.2656e-04\n",
      "Epoch 122/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1207 - acc: 0.9534\n",
      "Epoch 122: ReduceLROnPlateau reducing learning rate to 9.492187746218406e-05.\n",
      "\n",
      "Epoch 122: val_loss did not improve from 0.15720\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1207 - acc: 0.9536 - val_loss: 0.1995 - val_acc: 0.9300 - lr: 1.2656e-04\n",
      "Epoch 123/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0857 - acc: 0.9707\n",
      "Epoch 123: val_loss did not improve from 0.15720\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.0853 - acc: 0.9710 - val_loss: 0.2211 - val_acc: 0.9333 - lr: 9.4922e-05\n",
      "Epoch 124/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0756 - acc: 0.9700\n",
      "Epoch 124: val_loss did not improve from 0.15720\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.0754 - acc: 0.9703 - val_loss: 0.2233 - val_acc: 0.9341 - lr: 9.4922e-05\n",
      "Epoch 125/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0762 - acc: 0.9675\n",
      "Epoch 125: val_loss did not improve from 0.15720\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.0761 - acc: 0.9675 - val_loss: 0.2252 - val_acc: 0.9439 - lr: 9.4922e-05\n",
      "Epoch 126/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0897 - acc: 0.9643\n",
      "Epoch 126: val_loss did not improve from 0.15720\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.0894 - acc: 0.9640 - val_loss: 0.1969 - val_acc: 0.9447 - lr: 9.4922e-05\n",
      "Epoch 127/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0773 - acc: 0.9700\n",
      "Epoch 127: val_loss did not improve from 0.15720\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.0768 - acc: 0.9703 - val_loss: 0.1788 - val_acc: 0.9479 - lr: 9.4922e-05\n",
      "Epoch 128/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0874 - acc: 0.9619\n",
      "Epoch 128: val_loss did not improve from 0.15720\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.0874 - acc: 0.9620 - val_loss: 0.1738 - val_acc: 0.9479 - lr: 9.4922e-05\n",
      "Epoch 129/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0815 - acc: 0.9693\n",
      "Epoch 129: val_loss did not improve from 0.15720\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.0809 - acc: 0.9693 - val_loss: 0.1899 - val_acc: 0.9382 - lr: 9.4922e-05\n",
      "Epoch 130/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.0871 - acc: 0.9670\n",
      "Epoch 130: val_loss did not improve from 0.15720\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.0875 - acc: 0.9672 - val_loss: 0.1966 - val_acc: 0.9341 - lr: 9.4922e-05\n",
      "Epoch 131/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0741 - acc: 0.9714\n",
      "Epoch 131: val_loss did not improve from 0.15720\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.0742 - acc: 0.9714 - val_loss: 0.2138 - val_acc: 0.9439 - lr: 9.4922e-05\n",
      "Epoch 132/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0654 - acc: 0.9742\n",
      "Epoch 132: ReduceLROnPlateau reducing learning rate to 7.119141082512215e-05.\n",
      "\n",
      "Epoch 132: val_loss did not improve from 0.15720\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.0658 - acc: 0.9742 - val_loss: 0.2487 - val_acc: 0.9365 - lr: 9.4922e-05\n",
      "Epoch 132: early stopping\n",
      "Epoch 1/160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-23 08:45:06.593471: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_1/dropout_2/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - ETA: 0s - loss: 0.6865 - acc: 0.5620\n",
      "Epoch 1: val_loss improved from inf to 0.62573, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 5s 19ms/step - loss: 0.6865 - acc: 0.5620 - val_loss: 0.6257 - val_acc: 0.7266 - lr: 3.0000e-04\n",
      "Epoch 2/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.5889 - acc: 0.7088\n",
      "Epoch 2: val_loss improved from 0.62573 to 0.56301, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.5883 - acc: 0.7096 - val_loss: 0.5630 - val_acc: 0.7347 - lr: 3.0000e-04\n",
      "Epoch 3/160\n",
      "179/180 [============================>.] - ETA: 0s - loss: 0.5114 - acc: 0.7592\n",
      "Epoch 3: val_loss improved from 0.56301 to 0.54982, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.5129 - acc: 0.7585 - val_loss: 0.5498 - val_acc: 0.7779 - lr: 3.0000e-04\n",
      "Epoch 4/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.4892 - acc: 0.7797\n",
      "Epoch 4: val_loss did not improve from 0.54982\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.4895 - acc: 0.7787 - val_loss: 0.5760 - val_acc: 0.7730 - lr: 3.0000e-04\n",
      "Epoch 5/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.4691 - acc: 0.7882\n",
      "Epoch 5: val_loss improved from 0.54982 to 0.43008, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.4710 - acc: 0.7867 - val_loss: 0.4301 - val_acc: 0.8120 - lr: 3.0000e-04\n",
      "Epoch 6/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.4386 - acc: 0.8090\n",
      "Epoch 6: val_loss improved from 0.43008 to 0.41094, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.4380 - acc: 0.8087 - val_loss: 0.4109 - val_acc: 0.8340 - lr: 3.0000e-04\n",
      "Epoch 7/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.3991 - acc: 0.8292\n",
      "Epoch 7: val_loss did not improve from 0.41094\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.3994 - acc: 0.8283 - val_loss: 0.4195 - val_acc: 0.8186 - lr: 3.0000e-04\n",
      "Epoch 8/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.3905 - acc: 0.8260\n",
      "Epoch 8: val_loss did not improve from 0.41094\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.3903 - acc: 0.8262 - val_loss: 0.4157 - val_acc: 0.8161 - lr: 3.0000e-04\n",
      "Epoch 9/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.3873 - acc: 0.8256\n",
      "Epoch 9: val_loss improved from 0.41094 to 0.37932, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.3876 - acc: 0.8248 - val_loss: 0.3793 - val_acc: 0.8267 - lr: 3.0000e-04\n",
      "Epoch 10/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.3574 - acc: 0.8457\n",
      "Epoch 10: val_loss did not improve from 0.37932\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.3557 - acc: 0.8471 - val_loss: 0.4071 - val_acc: 0.8112 - lr: 3.0000e-04\n",
      "Epoch 11/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.3361 - acc: 0.8556\n",
      "Epoch 11: val_loss improved from 0.37932 to 0.33877, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.3394 - acc: 0.8541 - val_loss: 0.3388 - val_acc: 0.8592 - lr: 3.0000e-04\n",
      "Epoch 12/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.3532 - acc: 0.8577\n",
      "Epoch 12: val_loss improved from 0.33877 to 0.31458, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.3520 - acc: 0.8579 - val_loss: 0.3146 - val_acc: 0.8535 - lr: 3.0000e-04\n",
      "Epoch 13/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.3377 - acc: 0.8577\n",
      "Epoch 13: val_loss did not improve from 0.31458\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.3380 - acc: 0.8576 - val_loss: 0.3541 - val_acc: 0.8511 - lr: 3.0000e-04\n",
      "Epoch 14/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.3059 - acc: 0.8747\n",
      "Epoch 14: val_loss did not improve from 0.31458\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.3063 - acc: 0.8736 - val_loss: 0.3278 - val_acc: 0.8584 - lr: 3.0000e-04\n",
      "Epoch 15/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.3253 - acc: 0.8592\n",
      "Epoch 15: val_loss improved from 0.31458 to 0.28056, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.3240 - acc: 0.8597 - val_loss: 0.2806 - val_acc: 0.8877 - lr: 3.0000e-04\n",
      "Epoch 16/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.2987 - acc: 0.8775\n",
      "Epoch 16: val_loss did not improve from 0.28056\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.2974 - acc: 0.8785 - val_loss: 0.3259 - val_acc: 0.8641 - lr: 3.0000e-04\n",
      "Epoch 17/160\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.2873 - acc: 0.8775\n",
      "Epoch 17: val_loss did not improve from 0.28056\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2873 - acc: 0.8775 - val_loss: 0.3629 - val_acc: 0.8552 - lr: 3.0000e-04\n",
      "Epoch 18/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2743 - acc: 0.8899\n",
      "Epoch 18: val_loss did not improve from 0.28056\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2739 - acc: 0.8894 - val_loss: 0.2809 - val_acc: 0.8918 - lr: 3.0000e-04\n",
      "Epoch 19/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2857 - acc: 0.8885\n",
      "Epoch 19: val_loss did not improve from 0.28056\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2837 - acc: 0.8894 - val_loss: 0.2856 - val_acc: 0.8934 - lr: 3.0000e-04\n",
      "Epoch 20/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2596 - acc: 0.8969\n",
      "Epoch 20: val_loss improved from 0.28056 to 0.26636, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2597 - acc: 0.8963 - val_loss: 0.2664 - val_acc: 0.8820 - lr: 3.0000e-04\n",
      "Epoch 21/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2789 - acc: 0.8959\n",
      "Epoch 21: val_loss did not improve from 0.26636\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2804 - acc: 0.8949 - val_loss: 0.2874 - val_acc: 0.8828 - lr: 3.0000e-04\n",
      "Epoch 22/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.2667 - acc: 0.8928\n",
      "Epoch 22: val_loss did not improve from 0.26636\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2689 - acc: 0.8918 - val_loss: 0.2957 - val_acc: 0.8861 - lr: 3.0000e-04\n",
      "Epoch 23/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.2558 - acc: 0.9010\n",
      "Epoch 23: val_loss improved from 0.26636 to 0.24713, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2587 - acc: 0.8998 - val_loss: 0.2471 - val_acc: 0.9024 - lr: 3.0000e-04\n",
      "Epoch 24/160\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.2684 - acc: 0.8928\n",
      "Epoch 24: val_loss did not improve from 0.24713\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2684 - acc: 0.8928 - val_loss: 0.2919 - val_acc: 0.8853 - lr: 3.0000e-04\n",
      "Epoch 25/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2492 - acc: 0.9040\n",
      "Epoch 25: val_loss did not improve from 0.24713\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2510 - acc: 0.9033 - val_loss: 0.3550 - val_acc: 0.8511 - lr: 3.0000e-04\n",
      "Epoch 26/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.2567 - acc: 0.9027\n",
      "Epoch 26: val_loss did not improve from 0.24713\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2596 - acc: 0.9019 - val_loss: 0.2655 - val_acc: 0.8959 - lr: 3.0000e-04\n",
      "Epoch 27/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2384 - acc: 0.9019\n",
      "Epoch 27: val_loss did not improve from 0.24713\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2409 - acc: 0.9016 - val_loss: 0.2484 - val_acc: 0.8959 - lr: 3.0000e-04\n",
      "Epoch 28/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2562 - acc: 0.9015\n",
      "Epoch 28: val_loss did not improve from 0.24713\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2567 - acc: 0.9019 - val_loss: 0.3488 - val_acc: 0.8519 - lr: 3.0000e-04\n",
      "Epoch 29/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2419 - acc: 0.9061\n",
      "Epoch 29: val_loss did not improve from 0.24713\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2423 - acc: 0.9061 - val_loss: 0.2620 - val_acc: 0.8934 - lr: 3.0000e-04\n",
      "Epoch 30/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2283 - acc: 0.9110\n",
      "Epoch 30: val_loss did not improve from 0.24713\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2281 - acc: 0.9106 - val_loss: 0.2582 - val_acc: 0.9007 - lr: 3.0000e-04\n",
      "Epoch 31/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.2284 - acc: 0.9130\n",
      "Epoch 31: val_loss did not improve from 0.24713\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2260 - acc: 0.9141 - val_loss: 0.2495 - val_acc: 0.8942 - lr: 3.0000e-04\n",
      "Epoch 32/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.2197 - acc: 0.9201\n",
      "Epoch 32: val_loss did not improve from 0.24713\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2198 - acc: 0.9201 - val_loss: 0.2554 - val_acc: 0.9015 - lr: 3.0000e-04\n",
      "Epoch 33/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2420 - acc: 0.8994\n",
      "Epoch 33: val_loss improved from 0.24713 to 0.24520, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2404 - acc: 0.9002 - val_loss: 0.2452 - val_acc: 0.8983 - lr: 3.0000e-04\n",
      "Epoch 34/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2180 - acc: 0.9170\n",
      "Epoch 34: val_loss did not improve from 0.24520\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2191 - acc: 0.9166 - val_loss: 0.2503 - val_acc: 0.8991 - lr: 3.0000e-04\n",
      "Epoch 35/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2113 - acc: 0.9206\n",
      "Epoch 35: val_loss did not improve from 0.24520\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2127 - acc: 0.9208 - val_loss: 0.3077 - val_acc: 0.8877 - lr: 3.0000e-04\n",
      "Epoch 36/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2295 - acc: 0.9160\n",
      "Epoch 36: val_loss improved from 0.24520 to 0.23028, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2286 - acc: 0.9162 - val_loss: 0.2303 - val_acc: 0.9081 - lr: 3.0000e-04\n",
      "Epoch 37/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2360 - acc: 0.9082\n",
      "Epoch 37: val_loss improved from 0.23028 to 0.22948, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2346 - acc: 0.9089 - val_loss: 0.2295 - val_acc: 0.9064 - lr: 3.0000e-04\n",
      "Epoch 38/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2261 - acc: 0.9086\n",
      "Epoch 38: val_loss did not improve from 0.22948\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2261 - acc: 0.9086 - val_loss: 0.2312 - val_acc: 0.9178 - lr: 3.0000e-04\n",
      "Epoch 39/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.2251 - acc: 0.9098\n",
      "Epoch 39: val_loss did not improve from 0.22948\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.2247 - acc: 0.9096 - val_loss: 0.2298 - val_acc: 0.9146 - lr: 3.0000e-04\n",
      "Epoch 40/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2105 - acc: 0.9209\n",
      "Epoch 40: val_loss did not improve from 0.22948\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.2095 - acc: 0.9211 - val_loss: 0.2427 - val_acc: 0.9007 - lr: 3.0000e-04\n",
      "Epoch 41/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2257 - acc: 0.9153\n",
      "Epoch 41: val_loss did not improve from 0.22948\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2248 - acc: 0.9162 - val_loss: 0.2418 - val_acc: 0.9097 - lr: 3.0000e-04\n",
      "Epoch 42/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.2106 - acc: 0.9215\n",
      "Epoch 42: val_loss improved from 0.22948 to 0.22550, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2118 - acc: 0.9215 - val_loss: 0.2255 - val_acc: 0.9170 - lr: 3.0000e-04\n",
      "Epoch 43/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2005 - acc: 0.9202\n",
      "Epoch 43: val_loss did not improve from 0.22550\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.2018 - acc: 0.9201 - val_loss: 0.2299 - val_acc: 0.9105 - lr: 3.0000e-04\n",
      "Epoch 44/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2122 - acc: 0.9220\n",
      "Epoch 44: val_loss did not improve from 0.22550\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2113 - acc: 0.9222 - val_loss: 0.2384 - val_acc: 0.9105 - lr: 3.0000e-04\n",
      "Epoch 45/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2160 - acc: 0.9216\n",
      "Epoch 45: val_loss improved from 0.22550 to 0.22125, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2144 - acc: 0.9225 - val_loss: 0.2213 - val_acc: 0.9203 - lr: 3.0000e-04\n",
      "Epoch 46/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.1958 - acc: 0.9280\n",
      "Epoch 46: val_loss did not improve from 0.22125\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1964 - acc: 0.9277 - val_loss: 0.2704 - val_acc: 0.8820 - lr: 3.0000e-04\n",
      "Epoch 47/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2018 - acc: 0.9209\n",
      "Epoch 47: val_loss did not improve from 0.22125\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.2027 - acc: 0.9204 - val_loss: 0.2222 - val_acc: 0.9194 - lr: 3.0000e-04\n",
      "Epoch 48/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.2006 - acc: 0.9237\n",
      "Epoch 48: val_loss improved from 0.22125 to 0.20587, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2009 - acc: 0.9243 - val_loss: 0.2059 - val_acc: 0.9154 - lr: 3.0000e-04\n",
      "Epoch 49/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2086 - acc: 0.9153\n",
      "Epoch 49: val_loss did not improve from 0.20587\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2105 - acc: 0.9145 - val_loss: 0.2424 - val_acc: 0.8991 - lr: 3.0000e-04\n",
      "Epoch 50/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2006 - acc: 0.9252\n",
      "Epoch 50: val_loss did not improve from 0.20587\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2008 - acc: 0.9250 - val_loss: 0.2240 - val_acc: 0.9162 - lr: 3.0000e-04\n",
      "Epoch 51/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1910 - acc: 0.9315\n",
      "Epoch 51: val_loss improved from 0.20587 to 0.20354, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1905 - acc: 0.9312 - val_loss: 0.2035 - val_acc: 0.9227 - lr: 3.0000e-04\n",
      "Epoch 52/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1942 - acc: 0.9305\n",
      "Epoch 52: val_loss did not improve from 0.20354\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1940 - acc: 0.9305 - val_loss: 0.2052 - val_acc: 0.9186 - lr: 3.0000e-04\n",
      "Epoch 53/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1876 - acc: 0.9322\n",
      "Epoch 53: val_loss improved from 0.20354 to 0.18389, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1875 - acc: 0.9319 - val_loss: 0.1839 - val_acc: 0.9308 - lr: 3.0000e-04\n",
      "Epoch 54/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.1993 - acc: 0.9286\n",
      "Epoch 54: val_loss did not improve from 0.18389\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1979 - acc: 0.9295 - val_loss: 0.2168 - val_acc: 0.9219 - lr: 3.0000e-04\n",
      "Epoch 55/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1955 - acc: 0.9230\n",
      "Epoch 55: val_loss did not improve from 0.18389\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1955 - acc: 0.9229 - val_loss: 0.2123 - val_acc: 0.9186 - lr: 3.0000e-04\n",
      "Epoch 56/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2022 - acc: 0.9291\n",
      "Epoch 56: val_loss did not improve from 0.18389\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2021 - acc: 0.9295 - val_loss: 0.3049 - val_acc: 0.8885 - lr: 3.0000e-04\n",
      "Epoch 57/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2070 - acc: 0.9245\n",
      "Epoch 57: val_loss did not improve from 0.18389\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.2064 - acc: 0.9250 - val_loss: 0.2043 - val_acc: 0.9251 - lr: 3.0000e-04\n",
      "Epoch 58/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1799 - acc: 0.9329\n",
      "Epoch 58: val_loss did not improve from 0.18389\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1803 - acc: 0.9330 - val_loss: 0.1883 - val_acc: 0.9251 - lr: 3.0000e-04\n",
      "Epoch 59/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1819 - acc: 0.9336\n",
      "Epoch 59: val_loss improved from 0.18389 to 0.18158, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1835 - acc: 0.9330 - val_loss: 0.1816 - val_acc: 0.9357 - lr: 3.0000e-04\n",
      "Epoch 60/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1727 - acc: 0.9386\n",
      "Epoch 60: val_loss did not improve from 0.18158\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1724 - acc: 0.9386 - val_loss: 0.1873 - val_acc: 0.9365 - lr: 3.0000e-04\n",
      "Epoch 61/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1727 - acc: 0.9386\n",
      "Epoch 61: val_loss did not improve from 0.18158\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1730 - acc: 0.9386 - val_loss: 0.1836 - val_acc: 0.9349 - lr: 3.0000e-04\n",
      "Epoch 62/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1872 - acc: 0.9308\n",
      "Epoch 62: val_loss did not improve from 0.18158\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1866 - acc: 0.9312 - val_loss: 0.1926 - val_acc: 0.9308 - lr: 3.0000e-04\n",
      "Epoch 63/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1833 - acc: 0.9361\n",
      "Epoch 63: val_loss did not improve from 0.18158\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1843 - acc: 0.9358 - val_loss: 0.2048 - val_acc: 0.9203 - lr: 3.0000e-04\n",
      "Epoch 64/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1747 - acc: 0.9375\n",
      "Epoch 64: val_loss did not improve from 0.18158\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.1752 - acc: 0.9372 - val_loss: 0.2469 - val_acc: 0.9056 - lr: 3.0000e-04\n",
      "Epoch 65/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1729 - acc: 0.9396\n",
      "Epoch 65: val_loss did not improve from 0.18158\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1740 - acc: 0.9389 - val_loss: 0.2339 - val_acc: 0.9048 - lr: 3.0000e-04\n",
      "Epoch 66/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1738 - acc: 0.9354\n",
      "Epoch 66: val_loss did not improve from 0.18158\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1731 - acc: 0.9358 - val_loss: 0.2070 - val_acc: 0.9194 - lr: 3.0000e-04\n",
      "Epoch 67/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1642 - acc: 0.9375\n",
      "Epoch 67: val_loss did not improve from 0.18158\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1651 - acc: 0.9375 - val_loss: 0.1880 - val_acc: 0.9251 - lr: 3.0000e-04\n",
      "Epoch 68/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1794 - acc: 0.9343\n",
      "Epoch 68: val_loss improved from 0.18158 to 0.17270, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1781 - acc: 0.9351 - val_loss: 0.1727 - val_acc: 0.9357 - lr: 3.0000e-04\n",
      "Epoch 69/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1728 - acc: 0.9389\n",
      "Epoch 69: val_loss did not improve from 0.17270\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1740 - acc: 0.9382 - val_loss: 0.1756 - val_acc: 0.9308 - lr: 3.0000e-04\n",
      "Epoch 70/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.1705 - acc: 0.9379\n",
      "Epoch 70: val_loss did not improve from 0.17270\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.1730 - acc: 0.9372 - val_loss: 0.1887 - val_acc: 0.9251 - lr: 3.0000e-04\n",
      "Epoch 71/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1623 - acc: 0.9372\n",
      "Epoch 71: val_loss did not improve from 0.17270\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.1626 - acc: 0.9365 - val_loss: 0.2004 - val_acc: 0.9260 - lr: 3.0000e-04\n",
      "Epoch 72/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1863 - acc: 0.9294\n",
      "Epoch 72: val_loss did not improve from 0.17270\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.1864 - acc: 0.9298 - val_loss: 0.2004 - val_acc: 0.9260 - lr: 3.0000e-04\n",
      "Epoch 73/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1679 - acc: 0.9368\n",
      "Epoch 73: val_loss improved from 0.17270 to 0.16646, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1663 - acc: 0.9375 - val_loss: 0.1665 - val_acc: 0.9390 - lr: 3.0000e-04\n",
      "Epoch 74/160\n",
      "179/180 [============================>.] - ETA: 0s - loss: 0.1786 - acc: 0.9354\n",
      "Epoch 74: val_loss did not improve from 0.16646\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.1788 - acc: 0.9354 - val_loss: 0.1707 - val_acc: 0.9422 - lr: 3.0000e-04\n",
      "Epoch 75/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1614 - acc: 0.9467\n",
      "Epoch 75: val_loss did not improve from 0.16646\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.1621 - acc: 0.9466 - val_loss: 0.1892 - val_acc: 0.9243 - lr: 3.0000e-04\n",
      "Epoch 76/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1628 - acc: 0.9432\n",
      "Epoch 76: val_loss did not improve from 0.16646\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1625 - acc: 0.9435 - val_loss: 0.2027 - val_acc: 0.9292 - lr: 3.0000e-04\n",
      "Epoch 77/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.1654 - acc: 0.9439\n",
      "Epoch 77: val_loss did not improve from 0.16646\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1687 - acc: 0.9424 - val_loss: 0.1823 - val_acc: 0.9333 - lr: 3.0000e-04\n",
      "Epoch 78/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1549 - acc: 0.9421\n",
      "Epoch 78: val_loss did not improve from 0.16646\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.1550 - acc: 0.9424 - val_loss: 0.2476 - val_acc: 0.9064 - lr: 3.0000e-04\n",
      "Epoch 79/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.1795 - acc: 0.9343\n",
      "Epoch 79: val_loss did not improve from 0.16646\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1800 - acc: 0.9344 - val_loss: 0.1751 - val_acc: 0.9406 - lr: 3.0000e-04\n",
      "Epoch 80/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1550 - acc: 0.9421\n",
      "Epoch 80: val_loss did not improve from 0.16646\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1553 - acc: 0.9417 - val_loss: 0.1951 - val_acc: 0.9317 - lr: 3.0000e-04\n",
      "Epoch 81/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1603 - acc: 0.9446\n",
      "Epoch 81: val_loss did not improve from 0.16646\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1592 - acc: 0.9452 - val_loss: 0.1824 - val_acc: 0.9308 - lr: 3.0000e-04\n",
      "Epoch 82/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.1657 - acc: 0.9404\n",
      "Epoch 82: val_loss did not improve from 0.16646\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1669 - acc: 0.9393 - val_loss: 0.3293 - val_acc: 0.8771 - lr: 3.0000e-04\n",
      "Epoch 83/160\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.1561 - acc: 0.9428\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 0.00022500001068692654.\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.16646\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.1561 - acc: 0.9428 - val_loss: 0.1772 - val_acc: 0.9349 - lr: 3.0000e-04\n",
      "Epoch 84/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1496 - acc: 0.9474\n",
      "Epoch 84: val_loss did not improve from 0.16646\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1503 - acc: 0.9469 - val_loss: 0.1889 - val_acc: 0.9317 - lr: 2.2500e-04\n",
      "Epoch 85/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.1405 - acc: 0.9507\n",
      "Epoch 85: val_loss did not improve from 0.16646\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.1399 - acc: 0.9504 - val_loss: 0.1925 - val_acc: 0.9203 - lr: 2.2500e-04\n",
      "Epoch 86/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.1281 - acc: 0.9521\n",
      "Epoch 86: val_loss improved from 0.16646 to 0.14787, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1286 - acc: 0.9525 - val_loss: 0.1479 - val_acc: 0.9455 - lr: 2.2500e-04\n",
      "Epoch 87/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.1296 - acc: 0.9489\n",
      "Epoch 87: val_loss did not improve from 0.14787\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.1292 - acc: 0.9490 - val_loss: 0.1489 - val_acc: 0.9463 - lr: 2.2500e-04\n",
      "Epoch 88/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1425 - acc: 0.9509\n",
      "Epoch 88: val_loss did not improve from 0.14787\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1419 - acc: 0.9511 - val_loss: 0.1647 - val_acc: 0.9463 - lr: 2.2500e-04\n",
      "Epoch 89/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1455 - acc: 0.9481\n",
      "Epoch 89: val_loss did not improve from 0.14787\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1443 - acc: 0.9487 - val_loss: 0.1714 - val_acc: 0.9430 - lr: 2.2500e-04\n",
      "Epoch 90/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1323 - acc: 0.9509\n",
      "Epoch 90: val_loss did not improve from 0.14787\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1316 - acc: 0.9515 - val_loss: 0.1683 - val_acc: 0.9398 - lr: 2.2500e-04\n",
      "Epoch 91/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1332 - acc: 0.9534\n",
      "Epoch 91: val_loss did not improve from 0.14787\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1331 - acc: 0.9536 - val_loss: 0.1736 - val_acc: 0.9406 - lr: 2.2500e-04\n",
      "Epoch 92/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1394 - acc: 0.9495\n",
      "Epoch 92: val_loss did not improve from 0.14787\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1386 - acc: 0.9494 - val_loss: 0.1551 - val_acc: 0.9414 - lr: 2.2500e-04\n",
      "Epoch 93/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1236 - acc: 0.9523\n",
      "Epoch 93: val_loss did not improve from 0.14787\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1239 - acc: 0.9515 - val_loss: 0.1671 - val_acc: 0.9422 - lr: 2.2500e-04\n",
      "Epoch 94/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1349 - acc: 0.9513\n",
      "Epoch 94: val_loss did not improve from 0.14787\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1341 - acc: 0.9515 - val_loss: 0.1607 - val_acc: 0.9390 - lr: 2.2500e-04\n",
      "Epoch 95/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1174 - acc: 0.9534\n",
      "Epoch 95: val_loss did not improve from 0.14787\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1179 - acc: 0.9532 - val_loss: 0.1531 - val_acc: 0.9349 - lr: 2.2500e-04\n",
      "Epoch 96/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1338 - acc: 0.9513\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 0.0001687500080151949.\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.14787\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1329 - acc: 0.9515 - val_loss: 0.1495 - val_acc: 0.9439 - lr: 2.2500e-04\n",
      "Epoch 97/160\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.1219 - acc: 0.9550\n",
      "Epoch 97: val_loss did not improve from 0.14787\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1219 - acc: 0.9550 - val_loss: 0.1716 - val_acc: 0.9317 - lr: 1.6875e-04\n",
      "Epoch 98/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1123 - acc: 0.9580\n",
      "Epoch 98: val_loss improved from 0.14787 to 0.12628, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1148 - acc: 0.9571 - val_loss: 0.1263 - val_acc: 0.9520 - lr: 1.6875e-04\n",
      "Epoch 99/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1072 - acc: 0.9636\n",
      "Epoch 99: val_loss did not improve from 0.12628\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.1061 - acc: 0.9640 - val_loss: 0.1375 - val_acc: 0.9487 - lr: 1.6875e-04\n",
      "Epoch 100/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1128 - acc: 0.9566\n",
      "Epoch 100: val_loss did not improve from 0.12628\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1127 - acc: 0.9564 - val_loss: 0.1458 - val_acc: 0.9479 - lr: 1.6875e-04\n",
      "Epoch 101/160\n",
      "179/180 [============================>.] - ETA: 0s - loss: 0.1067 - acc: 0.9617\n",
      "Epoch 101: val_loss did not improve from 0.12628\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1087 - acc: 0.9613 - val_loss: 0.1608 - val_acc: 0.9463 - lr: 1.6875e-04\n",
      "Epoch 102/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1076 - acc: 0.9636\n",
      "Epoch 102: val_loss did not improve from 0.12628\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1083 - acc: 0.9634 - val_loss: 0.1852 - val_acc: 0.9325 - lr: 1.6875e-04\n",
      "Epoch 103/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1109 - acc: 0.9626\n",
      "Epoch 103: val_loss did not improve from 0.12628\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1100 - acc: 0.9630 - val_loss: 0.1358 - val_acc: 0.9585 - lr: 1.6875e-04\n",
      "Epoch 104/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1123 - acc: 0.9573\n",
      "Epoch 104: val_loss did not improve from 0.12628\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1131 - acc: 0.9571 - val_loss: 0.1991 - val_acc: 0.9325 - lr: 1.6875e-04\n",
      "Epoch 105/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1054 - acc: 0.9636\n",
      "Epoch 105: val_loss did not improve from 0.12628\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1052 - acc: 0.9637 - val_loss: 0.1594 - val_acc: 0.9390 - lr: 1.6875e-04\n",
      "Epoch 106/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1048 - acc: 0.9636\n",
      "Epoch 106: val_loss did not improve from 0.12628\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1040 - acc: 0.9637 - val_loss: 0.1859 - val_acc: 0.9260 - lr: 1.6875e-04\n",
      "Epoch 107/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1096 - acc: 0.9587\n",
      "Epoch 107: val_loss did not improve from 0.12628\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1094 - acc: 0.9585 - val_loss: 0.1504 - val_acc: 0.9439 - lr: 1.6875e-04\n",
      "Epoch 108/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1017 - acc: 0.9622\n",
      "Epoch 108: ReduceLROnPlateau reducing learning rate to 0.00012656250328291208.\n",
      "\n",
      "Epoch 108: val_loss did not improve from 0.12628\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.1015 - acc: 0.9623 - val_loss: 0.1432 - val_acc: 0.9504 - lr: 1.6875e-04\n",
      "Epoch 109/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1037 - acc: 0.9643\n",
      "Epoch 109: val_loss did not improve from 0.12628\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1031 - acc: 0.9647 - val_loss: 0.1364 - val_acc: 0.9487 - lr: 1.2656e-04\n",
      "Epoch 110/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0931 - acc: 0.9672\n",
      "Epoch 110: val_loss did not improve from 0.12628\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.0928 - acc: 0.9672 - val_loss: 0.1346 - val_acc: 0.9479 - lr: 1.2656e-04\n",
      "Epoch 111/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1022 - acc: 0.9608\n",
      "Epoch 111: val_loss did not improve from 0.12628\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.1013 - acc: 0.9613 - val_loss: 0.1355 - val_acc: 0.9504 - lr: 1.2656e-04\n",
      "Epoch 112/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0910 - acc: 0.9672\n",
      "Epoch 112: val_loss did not improve from 0.12628\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.0916 - acc: 0.9672 - val_loss: 0.1868 - val_acc: 0.9333 - lr: 1.2656e-04\n",
      "Epoch 113/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0924 - acc: 0.9643\n",
      "Epoch 113: val_loss did not improve from 0.12628\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.0921 - acc: 0.9644 - val_loss: 0.1416 - val_acc: 0.9536 - lr: 1.2656e-04\n",
      "Epoch 114/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1015 - acc: 0.9636\n",
      "Epoch 114: val_loss did not improve from 0.12628\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1006 - acc: 0.9640 - val_loss: 0.1473 - val_acc: 0.9439 - lr: 1.2656e-04\n",
      "Epoch 115/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0923 - acc: 0.9665\n",
      "Epoch 115: val_loss did not improve from 0.12628\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.0927 - acc: 0.9658 - val_loss: 0.1826 - val_acc: 0.9357 - lr: 1.2656e-04\n",
      "Epoch 116/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1059 - acc: 0.9679\n",
      "Epoch 116: val_loss did not improve from 0.12628\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1053 - acc: 0.9679 - val_loss: 0.1615 - val_acc: 0.9439 - lr: 1.2656e-04\n",
      "Epoch 117/160\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.0989 - acc: 0.9644\n",
      "Epoch 117: val_loss did not improve from 0.12628\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.0989 - acc: 0.9644 - val_loss: 0.1750 - val_acc: 0.9308 - lr: 1.2656e-04\n",
      "Epoch 118/160\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.0961 - acc: 0.9623\n",
      "Epoch 118: val_loss improved from 0.12628 to 0.10802, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 23ms/step - loss: 0.0961 - acc: 0.9623 - val_loss: 0.1080 - val_acc: 0.9601 - lr: 1.2656e-04\n",
      "Epoch 119/160\n",
      "179/180 [============================>.] - ETA: 0s - loss: 0.1032 - acc: 0.9614\n",
      "Epoch 119: val_loss did not improve from 0.10802\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.1040 - acc: 0.9609 - val_loss: 0.1569 - val_acc: 0.9496 - lr: 1.2656e-04\n",
      "Epoch 120/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.0925 - acc: 0.9695\n",
      "Epoch 120: val_loss did not improve from 0.10802\n",
      "180/180 [==============================] - 4s 23ms/step - loss: 0.0914 - acc: 0.9696 - val_loss: 0.1330 - val_acc: 0.9504 - lr: 1.2656e-04\n",
      "Epoch 121/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0734 - acc: 0.9728\n",
      "Epoch 121: val_loss did not improve from 0.10802\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.0735 - acc: 0.9724 - val_loss: 0.1164 - val_acc: 0.9609 - lr: 1.2656e-04\n",
      "Epoch 122/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0998 - acc: 0.9626\n",
      "Epoch 122: val_loss did not improve from 0.10802\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.0989 - acc: 0.9630 - val_loss: 0.1393 - val_acc: 0.9561 - lr: 1.2656e-04\n",
      "Epoch 123/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0950 - acc: 0.9640\n",
      "Epoch 123: val_loss did not improve from 0.10802\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.0943 - acc: 0.9640 - val_loss: 0.1127 - val_acc: 0.9642 - lr: 1.2656e-04\n",
      "Epoch 124/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0949 - acc: 0.9654\n",
      "Epoch 124: val_loss did not improve from 0.10802\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.0940 - acc: 0.9658 - val_loss: 0.1386 - val_acc: 0.9601 - lr: 1.2656e-04\n",
      "Epoch 125/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0923 - acc: 0.9668\n",
      "Epoch 125: val_loss did not improve from 0.10802\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.0918 - acc: 0.9672 - val_loss: 0.2415 - val_acc: 0.9129 - lr: 1.2656e-04\n",
      "Epoch 126/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0837 - acc: 0.9679\n",
      "Epoch 126: val_loss did not improve from 0.10802\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.0831 - acc: 0.9682 - val_loss: 0.2194 - val_acc: 0.9203 - lr: 1.2656e-04\n",
      "Epoch 127/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0963 - acc: 0.9640\n",
      "Epoch 127: val_loss did not improve from 0.10802\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.0986 - acc: 0.9634 - val_loss: 0.1377 - val_acc: 0.9528 - lr: 1.2656e-04\n",
      "Epoch 128/160\n",
      "176/180 [============================>.] - ETA: 0s - loss: 0.0868 - acc: 0.9695\n",
      "Epoch 128: ReduceLROnPlateau reducing learning rate to 9.492187746218406e-05.\n",
      "\n",
      "Epoch 128: val_loss did not improve from 0.10802\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.0881 - acc: 0.9686 - val_loss: 0.1277 - val_acc: 0.9512 - lr: 1.2656e-04\n",
      "Epoch 129/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0974 - acc: 0.9658\n",
      "Epoch 129: val_loss did not improve from 0.10802\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.0971 - acc: 0.9661 - val_loss: 0.1157 - val_acc: 0.9544 - lr: 9.4922e-05\n",
      "Epoch 130/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0739 - acc: 0.9732\n",
      "Epoch 130: val_loss did not improve from 0.10802\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.0734 - acc: 0.9731 - val_loss: 0.1561 - val_acc: 0.9430 - lr: 9.4922e-05\n",
      "Epoch 131/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0757 - acc: 0.9725\n",
      "Epoch 131: val_loss did not improve from 0.10802\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.0778 - acc: 0.9721 - val_loss: 0.1275 - val_acc: 0.9585 - lr: 9.4922e-05\n",
      "Epoch 132/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0709 - acc: 0.9742\n",
      "Epoch 132: val_loss did not improve from 0.10802\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.0714 - acc: 0.9742 - val_loss: 0.1747 - val_acc: 0.9398 - lr: 9.4922e-05\n",
      "Epoch 133/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0832 - acc: 0.9714\n",
      "Epoch 133: val_loss did not improve from 0.10802\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.0834 - acc: 0.9714 - val_loss: 0.1337 - val_acc: 0.9577 - lr: 9.4922e-05\n",
      "Epoch 134/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0704 - acc: 0.9721\n",
      "Epoch 134: val_loss did not improve from 0.10802\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.0698 - acc: 0.9724 - val_loss: 0.1340 - val_acc: 0.9577 - lr: 9.4922e-05\n",
      "Epoch 135/160\n",
      "179/180 [============================>.] - ETA: 0s - loss: 0.0811 - acc: 0.9691\n",
      "Epoch 135: val_loss did not improve from 0.10802\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.0807 - acc: 0.9693 - val_loss: 0.1237 - val_acc: 0.9577 - lr: 9.4922e-05\n",
      "Epoch 136/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0764 - acc: 0.9714\n",
      "Epoch 136: val_loss did not improve from 0.10802\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.0760 - acc: 0.9717 - val_loss: 0.1595 - val_acc: 0.9422 - lr: 9.4922e-05\n",
      "Epoch 137/160\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.0838 - acc: 0.9675\n",
      "Epoch 137: val_loss did not improve from 0.10802\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.0838 - acc: 0.9675 - val_loss: 0.1561 - val_acc: 0.9504 - lr: 9.4922e-05\n",
      "Epoch 138/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0845 - acc: 0.9714\n",
      "Epoch 138: ReduceLROnPlateau reducing learning rate to 7.119141082512215e-05.\n",
      "\n",
      "Epoch 138: val_loss did not improve from 0.10802\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.0843 - acc: 0.9714 - val_loss: 0.1454 - val_acc: 0.9528 - lr: 9.4922e-05\n",
      "Epoch 138: early stopping\n",
      "Epoch 1/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.6890 - acc: 0.5365\n",
      "Epoch 1: val_loss improved from inf to 0.58742, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_vgg16_weights.h5\n",
      "180/180 [==============================] - 5s 20ms/step - loss: 0.6874 - acc: 0.5386 - val_loss: 0.5874 - val_acc: 0.6981 - lr: 3.0000e-04\n",
      "Epoch 2/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.5550 - acc: 0.7264\n",
      "Epoch 2: val_loss improved from 0.58742 to 0.51840, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_vgg16_weights.h5\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.5554 - acc: 0.7253 - val_loss: 0.5184 - val_acc: 0.7242 - lr: 3.0000e-04\n",
      "Epoch 3/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.4639 - acc: 0.7819\n",
      "Epoch 3: val_loss improved from 0.51840 to 0.44457, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_vgg16_weights.h5\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.4626 - acc: 0.7822 - val_loss: 0.4446 - val_acc: 0.7795 - lr: 3.0000e-04\n",
      "Epoch 4/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.4313 - acc: 0.8052\n",
      "Epoch 4: val_loss improved from 0.44457 to 0.42374, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_vgg16_weights.h5\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.4306 - acc: 0.8052 - val_loss: 0.4237 - val_acc: 0.8137 - lr: 3.0000e-04\n",
      "Epoch 5/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.4120 - acc: 0.8179\n",
      "Epoch 5: val_loss improved from 0.42374 to 0.38221, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_vgg16_weights.h5\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.4120 - acc: 0.8178 - val_loss: 0.3822 - val_acc: 0.8194 - lr: 3.0000e-04\n",
      "Epoch 6/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.3862 - acc: 0.8387\n",
      "Epoch 6: val_loss did not improve from 0.38221\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.3849 - acc: 0.8391 - val_loss: 0.4343 - val_acc: 0.7901 - lr: 3.0000e-04\n",
      "Epoch 7/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.3720 - acc: 0.8405\n",
      "Epoch 7: val_loss improved from 0.38221 to 0.34863, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_vgg16_weights.h5\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.3724 - acc: 0.8405 - val_loss: 0.3486 - val_acc: 0.8340 - lr: 3.0000e-04\n",
      "Epoch 8/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.3612 - acc: 0.8514\n",
      "Epoch 8: val_loss did not improve from 0.34863\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.3642 - acc: 0.8489 - val_loss: 0.4735 - val_acc: 0.7714 - lr: 3.0000e-04\n",
      "Epoch 9/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.3674 - acc: 0.8376\n",
      "Epoch 9: val_loss improved from 0.34863 to 0.31114, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_vgg16_weights.h5\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.3688 - acc: 0.8373 - val_loss: 0.3111 - val_acc: 0.8641 - lr: 3.0000e-04\n",
      "Epoch 10/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.3228 - acc: 0.8627\n",
      "Epoch 10: val_loss did not improve from 0.31114\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.3225 - acc: 0.8621 - val_loss: 0.3585 - val_acc: 0.8600 - lr: 3.0000e-04\n",
      "Epoch 11/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.3153 - acc: 0.8690\n",
      "Epoch 11: val_loss did not improve from 0.31114\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.3159 - acc: 0.8691 - val_loss: 0.3206 - val_acc: 0.8731 - lr: 3.0000e-04\n",
      "Epoch 12/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2941 - acc: 0.8768\n",
      "Epoch 12: val_loss did not improve from 0.31114\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.2941 - acc: 0.8764 - val_loss: 0.3515 - val_acc: 0.8641 - lr: 3.0000e-04\n",
      "Epoch 13/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.3040 - acc: 0.8870\n",
      "Epoch 13: val_loss did not improve from 0.31114\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.3045 - acc: 0.8866 - val_loss: 0.3548 - val_acc: 0.8527 - lr: 3.0000e-04\n",
      "Epoch 14/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.3329 - acc: 0.8640\n",
      "Epoch 14: val_loss did not improve from 0.31114\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.3330 - acc: 0.8639 - val_loss: 0.3537 - val_acc: 0.8397 - lr: 3.0000e-04\n",
      "Epoch 15/160\n",
      "179/180 [============================>.] - ETA: 0s - loss: 0.2999 - acc: 0.8793\n",
      "Epoch 15: val_loss improved from 0.31114 to 0.28259, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_vgg16_weights.h5\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.3000 - acc: 0.8789 - val_loss: 0.2826 - val_acc: 0.8845 - lr: 3.0000e-04\n",
      "Epoch 16/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2690 - acc: 0.8853\n",
      "Epoch 16: val_loss did not improve from 0.28259\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.2685 - acc: 0.8848 - val_loss: 0.3453 - val_acc: 0.8462 - lr: 3.0000e-04\n",
      "Epoch 17/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2716 - acc: 0.8867\n",
      "Epoch 17: val_loss did not improve from 0.28259\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.2708 - acc: 0.8873 - val_loss: 0.3304 - val_acc: 0.8495 - lr: 3.0000e-04\n",
      "Epoch 18/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.3434 - acc: 0.8810\n",
      "Epoch 18: val_loss did not improve from 0.28259\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.3426 - acc: 0.8813 - val_loss: 0.3370 - val_acc: 0.8633 - lr: 3.0000e-04\n",
      "Epoch 19/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2765 - acc: 0.8909\n",
      "Epoch 19: val_loss improved from 0.28259 to 0.27686, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_vgg16_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2748 - acc: 0.8921 - val_loss: 0.2769 - val_acc: 0.8942 - lr: 3.0000e-04\n",
      "Epoch 20/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2819 - acc: 0.8867\n",
      "Epoch 20: val_loss did not improve from 0.27686\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.2830 - acc: 0.8866 - val_loss: 0.4492 - val_acc: 0.8080 - lr: 3.0000e-04\n",
      "Epoch 21/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.3112 - acc: 0.8722\n",
      "Epoch 21: val_loss did not improve from 0.27686\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.3117 - acc: 0.8723 - val_loss: 0.2983 - val_acc: 0.8893 - lr: 3.0000e-04\n",
      "Epoch 22/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2445 - acc: 0.9040\n",
      "Epoch 22: val_loss improved from 0.27686 to 0.24622, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_vgg16_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2440 - acc: 0.9044 - val_loss: 0.2462 - val_acc: 0.9032 - lr: 3.0000e-04\n",
      "Epoch 23/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2396 - acc: 0.9050\n",
      "Epoch 23: val_loss did not improve from 0.24622\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.2394 - acc: 0.9051 - val_loss: 0.3017 - val_acc: 0.8682 - lr: 3.0000e-04\n",
      "Epoch 24/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2403 - acc: 0.9040\n",
      "Epoch 24: val_loss improved from 0.24622 to 0.21531, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_vgg16_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2401 - acc: 0.9044 - val_loss: 0.2153 - val_acc: 0.9113 - lr: 3.0000e-04\n",
      "Epoch 25/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2220 - acc: 0.9125\n",
      "Epoch 25: val_loss did not improve from 0.21531\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.2212 - acc: 0.9127 - val_loss: 0.2335 - val_acc: 0.9089 - lr: 3.0000e-04\n",
      "Epoch 26/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2287 - acc: 0.9110\n",
      "Epoch 26: val_loss did not improve from 0.21531\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.2294 - acc: 0.9110 - val_loss: 0.2612 - val_acc: 0.8950 - lr: 3.0000e-04\n",
      "Epoch 27/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2023 - acc: 0.9202\n",
      "Epoch 27: val_loss did not improve from 0.21531\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.2023 - acc: 0.9201 - val_loss: 0.2341 - val_acc: 0.9138 - lr: 3.0000e-04\n",
      "Epoch 28/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.2157 - acc: 0.9169\n",
      "Epoch 28: val_loss did not improve from 0.21531\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.2178 - acc: 0.9162 - val_loss: 0.2459 - val_acc: 0.8983 - lr: 3.0000e-04\n",
      "Epoch 29/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1956 - acc: 0.9262\n",
      "Epoch 29: val_loss improved from 0.21531 to 0.18814, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_vgg16_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1950 - acc: 0.9264 - val_loss: 0.1881 - val_acc: 0.9268 - lr: 3.0000e-04\n",
      "Epoch 30/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1825 - acc: 0.9333\n",
      "Epoch 30: val_loss did not improve from 0.18814\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1817 - acc: 0.9337 - val_loss: 0.3180 - val_acc: 0.8926 - lr: 3.0000e-04\n",
      "Epoch 31/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2277 - acc: 0.9100\n",
      "Epoch 31: val_loss did not improve from 0.18814\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.2262 - acc: 0.9106 - val_loss: 0.2538 - val_acc: 0.9040 - lr: 3.0000e-04\n",
      "Epoch 32/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2055 - acc: 0.9206\n",
      "Epoch 32: val_loss did not improve from 0.18814\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.2051 - acc: 0.9204 - val_loss: 0.2201 - val_acc: 0.9194 - lr: 3.0000e-04\n",
      "Epoch 33/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1925 - acc: 0.9301\n",
      "Epoch 33: val_loss did not improve from 0.18814\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1948 - acc: 0.9291 - val_loss: 0.2313 - val_acc: 0.9048 - lr: 3.0000e-04\n",
      "Epoch 34/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1907 - acc: 0.9291\n",
      "Epoch 34: val_loss did not improve from 0.18814\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.1914 - acc: 0.9291 - val_loss: 0.3215 - val_acc: 0.8820 - lr: 3.0000e-04\n",
      "Epoch 35/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1819 - acc: 0.9333\n",
      "Epoch 35: val_loss did not improve from 0.18814\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.1832 - acc: 0.9326 - val_loss: 0.2054 - val_acc: 0.9251 - lr: 3.0000e-04\n",
      "Epoch 36/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1759 - acc: 0.9361\n",
      "Epoch 36: val_loss improved from 0.18814 to 0.18451, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_vgg16_weights.h5\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.1757 - acc: 0.9358 - val_loss: 0.1845 - val_acc: 0.9268 - lr: 3.0000e-04\n",
      "Epoch 37/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.3408 - acc: 0.8574\n",
      "Epoch 37: val_loss did not improve from 0.18451\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.3394 - acc: 0.8579 - val_loss: 0.2372 - val_acc: 0.8983 - lr: 3.0000e-04\n",
      "Epoch 38/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2190 - acc: 0.9125\n",
      "Epoch 38: val_loss did not improve from 0.18451\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.2183 - acc: 0.9127 - val_loss: 0.2243 - val_acc: 0.9056 - lr: 3.0000e-04\n",
      "Epoch 39/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1807 - acc: 0.9351\n",
      "Epoch 39: val_loss did not improve from 0.18451\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.1805 - acc: 0.9351 - val_loss: 0.2212 - val_acc: 0.9235 - lr: 3.0000e-04\n",
      "Epoch 40/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1677 - acc: 0.9400\n",
      "Epoch 40: val_loss improved from 0.18451 to 0.17756, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_vgg16_weights.h5\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.1691 - acc: 0.9389 - val_loss: 0.1776 - val_acc: 0.9284 - lr: 3.0000e-04\n",
      "Epoch 41/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2558 - acc: 0.8948\n",
      "Epoch 41: val_loss did not improve from 0.17756\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.2550 - acc: 0.8949 - val_loss: 0.2758 - val_acc: 0.8796 - lr: 3.0000e-04\n",
      "Epoch 42/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.1874 - acc: 0.9279\n",
      "Epoch 42: val_loss did not improve from 0.17756\n",
      "180/180 [==============================] - 4s 23ms/step - loss: 0.1886 - acc: 0.9274 - val_loss: 0.1968 - val_acc: 0.9219 - lr: 3.0000e-04\n",
      "Epoch 43/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.1704 - acc: 0.9421\n",
      "Epoch 43: val_loss did not improve from 0.17756\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.1702 - acc: 0.9421 - val_loss: 0.1907 - val_acc: 0.9317 - lr: 3.0000e-04\n",
      "Epoch 44/160\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.1616 - acc: 0.9361\n",
      "Epoch 44: val_loss did not improve from 0.17756\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1616 - acc: 0.9361 - val_loss: 0.2116 - val_acc: 0.9235 - lr: 3.0000e-04\n",
      "Epoch 45/160\n",
      "179/180 [============================>.] - ETA: 0s - loss: 0.1614 - acc: 0.9379\n",
      "Epoch 45: val_loss improved from 0.17756 to 0.17030, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_vgg16_weights.h5\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.1619 - acc: 0.9379 - val_loss: 0.1703 - val_acc: 0.9398 - lr: 3.0000e-04\n",
      "Epoch 46/160\n",
      "179/180 [============================>.] - ETA: 0s - loss: 0.1589 - acc: 0.9442\n",
      "Epoch 46: val_loss did not improve from 0.17030\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.1592 - acc: 0.9442 - val_loss: 0.2179 - val_acc: 0.9194 - lr: 3.0000e-04\n",
      "Epoch 47/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1690 - acc: 0.9428\n",
      "Epoch 47: val_loss improved from 0.17030 to 0.16980, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_vgg16_weights.h5\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.1683 - acc: 0.9431 - val_loss: 0.1698 - val_acc: 0.9300 - lr: 3.0000e-04\n",
      "Epoch 48/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1569 - acc: 0.9421\n",
      "Epoch 48: val_loss did not improve from 0.16980\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1564 - acc: 0.9424 - val_loss: 0.1883 - val_acc: 0.9357 - lr: 3.0000e-04\n",
      "Epoch 49/160\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.1568 - acc: 0.9424\n",
      "Epoch 49: val_loss improved from 0.16980 to 0.15605, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_vgg16_weights.h5\n",
      "180/180 [==============================] - 4s 24ms/step - loss: 0.1568 - acc: 0.9424 - val_loss: 0.1560 - val_acc: 0.9373 - lr: 3.0000e-04\n",
      "Epoch 50/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1438 - acc: 0.9435\n",
      "Epoch 50: val_loss did not improve from 0.15605\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1431 - acc: 0.9435 - val_loss: 0.1936 - val_acc: 0.9325 - lr: 3.0000e-04\n",
      "Epoch 51/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1393 - acc: 0.9485\n",
      "Epoch 51: val_loss did not improve from 0.15605\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1389 - acc: 0.9483 - val_loss: 0.4474 - val_acc: 0.8535 - lr: 3.0000e-04\n",
      "Epoch 52/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1550 - acc: 0.9425\n",
      "Epoch 52: val_loss did not improve from 0.15605\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.1542 - acc: 0.9428 - val_loss: 0.2247 - val_acc: 0.9276 - lr: 3.0000e-04\n",
      "Epoch 53/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1388 - acc: 0.9502\n",
      "Epoch 53: val_loss did not improve from 0.15605\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1387 - acc: 0.9497 - val_loss: 0.3118 - val_acc: 0.9268 - lr: 3.0000e-04\n",
      "Epoch 54/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1408 - acc: 0.9534\n",
      "Epoch 54: val_loss did not improve from 0.15605\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1413 - acc: 0.9525 - val_loss: 0.1932 - val_acc: 0.9292 - lr: 3.0000e-04\n",
      "Epoch 55/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1411 - acc: 0.9446\n",
      "Epoch 55: val_loss did not improve from 0.15605\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1398 - acc: 0.9452 - val_loss: 0.2119 - val_acc: 0.9268 - lr: 3.0000e-04\n",
      "Epoch 56/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1425 - acc: 0.9502\n",
      "Epoch 56: val_loss did not improve from 0.15605\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1413 - acc: 0.9508 - val_loss: 0.1732 - val_acc: 0.9390 - lr: 3.0000e-04\n",
      "Epoch 57/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.2077 - acc: 0.9220\n",
      "Epoch 57: val_loss did not improve from 0.15605\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.2067 - acc: 0.9218 - val_loss: 0.1684 - val_acc: 0.9349 - lr: 3.0000e-04\n",
      "Epoch 58/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1474 - acc: 0.9495\n",
      "Epoch 58: val_loss did not improve from 0.15605\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.1468 - acc: 0.9497 - val_loss: 0.1727 - val_acc: 0.9268 - lr: 3.0000e-04\n",
      "Epoch 59/160\n",
      "180/180 [==============================] - ETA: 0s - loss: 5.5626 - acc: 0.8988\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 0.00022500001068692654.\n",
      "\n",
      "Epoch 59: val_loss did not improve from 0.15605\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 5.5626 - acc: 0.8988 - val_loss: 0.2424 - val_acc: 0.9097 - lr: 3.0000e-04\n",
      "Epoch 60/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.2068 - acc: 0.9208\n",
      "Epoch 60: val_loss did not improve from 0.15605\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2060 - acc: 0.9208 - val_loss: 0.2086 - val_acc: 0.9243 - lr: 2.2500e-04\n",
      "Epoch 61/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.1650 - acc: 0.9397\n",
      "Epoch 61: val_loss did not improve from 0.15605\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1646 - acc: 0.9396 - val_loss: 0.2083 - val_acc: 0.9317 - lr: 2.2500e-04\n",
      "Epoch 62/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.1577 - acc: 0.9386\n",
      "Epoch 62: val_loss did not improve from 0.15605\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1562 - acc: 0.9396 - val_loss: 0.1822 - val_acc: 0.9341 - lr: 2.2500e-04\n",
      "Epoch 63/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1566 - acc: 0.9435\n",
      "Epoch 63: val_loss did not improve from 0.15605\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1567 - acc: 0.9435 - val_loss: 0.1902 - val_acc: 0.9276 - lr: 2.2500e-04\n",
      "Epoch 64/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.1580 - acc: 0.9407\n",
      "Epoch 64: val_loss did not improve from 0.15605\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1574 - acc: 0.9410 - val_loss: 0.1566 - val_acc: 0.9398 - lr: 2.2500e-04\n",
      "Epoch 65/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.1450 - acc: 0.9443\n",
      "Epoch 65: val_loss improved from 0.15605 to 0.14284, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_vgg16_weights.h5\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.1458 - acc: 0.9438 - val_loss: 0.1428 - val_acc: 0.9479 - lr: 2.2500e-04\n",
      "Epoch 66/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.1369 - acc: 0.9510\n",
      "Epoch 66: val_loss did not improve from 0.14284\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1364 - acc: 0.9511 - val_loss: 0.1503 - val_acc: 0.9365 - lr: 2.2500e-04\n",
      "Epoch 67/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1409 - acc: 0.9467\n",
      "Epoch 67: val_loss did not improve from 0.14284\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1399 - acc: 0.9473 - val_loss: 0.1571 - val_acc: 0.9463 - lr: 2.2500e-04\n",
      "Epoch 68/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1340 - acc: 0.9523\n",
      "Epoch 68: val_loss did not improve from 0.14284\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1330 - acc: 0.9529 - val_loss: 0.1829 - val_acc: 0.9284 - lr: 2.2500e-04\n",
      "Epoch 69/160\n",
      "179/180 [============================>.] - ETA: 0s - loss: 0.1354 - acc: 0.9516\n",
      "Epoch 69: val_loss did not improve from 0.14284\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1357 - acc: 0.9511 - val_loss: 0.1739 - val_acc: 0.9349 - lr: 2.2500e-04\n",
      "Epoch 70/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1357 - acc: 0.9513\n",
      "Epoch 70: val_loss did not improve from 0.14284\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1345 - acc: 0.9518 - val_loss: 0.1596 - val_acc: 0.9414 - lr: 2.2500e-04\n",
      "Epoch 71/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1236 - acc: 0.9545\n",
      "Epoch 71: val_loss did not improve from 0.14284\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1266 - acc: 0.9543 - val_loss: 0.1744 - val_acc: 0.9414 - lr: 2.2500e-04\n",
      "Epoch 72/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1295 - acc: 0.9495\n",
      "Epoch 72: val_loss did not improve from 0.14284\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1290 - acc: 0.9497 - val_loss: 0.1591 - val_acc: 0.9471 - lr: 2.2500e-04\n",
      "Epoch 73/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1279 - acc: 0.9492\n",
      "Epoch 73: val_loss did not improve from 0.14284\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1275 - acc: 0.9494 - val_loss: 0.1688 - val_acc: 0.9349 - lr: 2.2500e-04\n",
      "Epoch 74/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1311 - acc: 0.9516\n",
      "Epoch 74: val_loss did not improve from 0.14284\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1310 - acc: 0.9518 - val_loss: 0.2124 - val_acc: 0.9308 - lr: 2.2500e-04\n",
      "Epoch 75/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1459 - acc: 0.9481\n",
      "Epoch 75: ReduceLROnPlateau reducing learning rate to 0.0001687500080151949.\n",
      "\n",
      "Epoch 75: val_loss did not improve from 0.14284\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1450 - acc: 0.9483 - val_loss: 0.1540 - val_acc: 0.9471 - lr: 2.2500e-04\n",
      "Epoch 76/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1195 - acc: 0.9523\n",
      "Epoch 76: val_loss did not improve from 0.14284\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.1193 - acc: 0.9522 - val_loss: 0.1492 - val_acc: 0.9398 - lr: 1.6875e-04\n",
      "Epoch 77/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.1120 - acc: 0.9595\n",
      "Epoch 77: val_loss improved from 0.14284 to 0.13483, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_vgg16_weights.h5\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.1123 - acc: 0.9592 - val_loss: 0.1348 - val_acc: 0.9479 - lr: 1.6875e-04\n",
      "Epoch 78/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.1154 - acc: 0.9573\n",
      "Epoch 78: val_loss did not improve from 0.13483\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1150 - acc: 0.9571 - val_loss: 0.1507 - val_acc: 0.9390 - lr: 1.6875e-04\n",
      "Epoch 79/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1097 - acc: 0.9612\n",
      "Epoch 79: val_loss did not improve from 0.13483\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1089 - acc: 0.9616 - val_loss: 0.1513 - val_acc: 0.9414 - lr: 1.6875e-04\n",
      "Epoch 80/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.1020 - acc: 0.9631\n",
      "Epoch 80: val_loss did not improve from 0.13483\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1042 - acc: 0.9627 - val_loss: 0.1557 - val_acc: 0.9471 - lr: 1.6875e-04\n",
      "Epoch 81/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.1042 - acc: 0.9606\n",
      "Epoch 81: val_loss did not improve from 0.13483\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.1048 - acc: 0.9609 - val_loss: 0.1790 - val_acc: 0.9341 - lr: 1.6875e-04\n",
      "Epoch 82/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1147 - acc: 0.9569\n",
      "Epoch 82: val_loss did not improve from 0.13483\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1145 - acc: 0.9571 - val_loss: 0.1749 - val_acc: 0.9390 - lr: 1.6875e-04\n",
      "Epoch 83/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1010 - acc: 0.9636\n",
      "Epoch 83: val_loss did not improve from 0.13483\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1011 - acc: 0.9637 - val_loss: 0.1787 - val_acc: 0.9398 - lr: 1.6875e-04\n",
      "Epoch 84/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1178 - acc: 0.9612\n",
      "Epoch 84: val_loss did not improve from 0.13483\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1196 - acc: 0.9609 - val_loss: 0.2120 - val_acc: 0.9260 - lr: 1.6875e-04\n",
      "Epoch 85/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1040 - acc: 0.9601\n",
      "Epoch 85: val_loss did not improve from 0.13483\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1035 - acc: 0.9606 - val_loss: 0.1496 - val_acc: 0.9512 - lr: 1.6875e-04\n",
      "Epoch 86/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1127 - acc: 0.9562\n",
      "Epoch 86: val_loss did not improve from 0.13483\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.1134 - acc: 0.9560 - val_loss: 0.1831 - val_acc: 0.9414 - lr: 1.6875e-04\n",
      "Epoch 87/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1026 - acc: 0.9619\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 0.00012656250328291208.\n",
      "\n",
      "Epoch 87: val_loss did not improve from 0.13483\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1026 - acc: 0.9616 - val_loss: 0.1496 - val_acc: 0.9520 - lr: 1.6875e-04\n",
      "Epoch 88/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0982 - acc: 0.9598\n",
      "Epoch 88: val_loss did not improve from 0.13483\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.0978 - acc: 0.9599 - val_loss: 0.1706 - val_acc: 0.9504 - lr: 1.2656e-04\n",
      "Epoch 89/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.0948 - acc: 0.9624\n",
      "Epoch 89: val_loss did not improve from 0.13483\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.0948 - acc: 0.9623 - val_loss: 0.1629 - val_acc: 0.9373 - lr: 1.2656e-04\n",
      "Epoch 90/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.0899 - acc: 0.9666\n",
      "Epoch 90: val_loss did not improve from 0.13483\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.0891 - acc: 0.9668 - val_loss: 0.1483 - val_acc: 0.9487 - lr: 1.2656e-04\n",
      "Epoch 91/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.0971 - acc: 0.9606\n",
      "Epoch 91: val_loss did not improve from 0.13483\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.0975 - acc: 0.9606 - val_loss: 0.1556 - val_acc: 0.9487 - lr: 1.2656e-04\n",
      "Epoch 92/160\n",
      "179/180 [============================>.] - ETA: 0s - loss: 0.0951 - acc: 0.9649\n",
      "Epoch 92: val_loss did not improve from 0.13483\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.0954 - acc: 0.9644 - val_loss: 0.2090 - val_acc: 0.9325 - lr: 1.2656e-04\n",
      "Epoch 93/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.0910 - acc: 0.9641\n",
      "Epoch 93: val_loss did not improve from 0.13483\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.0916 - acc: 0.9640 - val_loss: 0.1776 - val_acc: 0.9487 - lr: 1.2656e-04\n",
      "Epoch 94/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.0881 - acc: 0.9641\n",
      "Epoch 94: val_loss did not improve from 0.13483\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.0872 - acc: 0.9644 - val_loss: 0.1565 - val_acc: 0.9544 - lr: 1.2656e-04\n",
      "Epoch 95/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0860 - acc: 0.9679\n",
      "Epoch 95: val_loss did not improve from 0.13483\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.0861 - acc: 0.9675 - val_loss: 0.1678 - val_acc: 0.9422 - lr: 1.2656e-04\n",
      "Epoch 96/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0884 - acc: 0.9668\n",
      "Epoch 96: val_loss did not improve from 0.13483\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.0887 - acc: 0.9668 - val_loss: 0.1719 - val_acc: 0.9398 - lr: 1.2656e-04\n",
      "Epoch 97/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0849 - acc: 0.9693\n",
      "Epoch 97: ReduceLROnPlateau reducing learning rate to 9.492187746218406e-05.\n",
      "\n",
      "Epoch 97: val_loss did not improve from 0.13483\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.0852 - acc: 0.9693 - val_loss: 0.1637 - val_acc: 0.9487 - lr: 1.2656e-04\n",
      "Epoch 97: early stopping\n",
      "Epoch 1/160\n",
      "179/180 [============================>.] - ETA: 0s - loss: 0.6828 - acc: 0.7624\n",
      "Epoch 1: val_loss improved from inf to 3.11308, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_mobilenet_weights.h5\n",
      "180/180 [==============================] - 8s 23ms/step - loss: 0.6811 - acc: 0.7634 - val_loss: 3.1131 - val_acc: 0.5899 - lr: 3.0000e-04\n",
      "Epoch 2/160\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.4312 - acc: 0.8283\n",
      "Epoch 2: val_loss improved from 3.11308 to 1.77118, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_mobilenet_weights.h5\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.4312 - acc: 0.8283 - val_loss: 1.7712 - val_acc: 0.5932 - lr: 3.0000e-04\n",
      "Epoch 3/160\n",
      "179/180 [============================>.] - ETA: 0s - loss: 0.3472 - acc: 0.8533\n",
      "Epoch 3: val_loss did not improve from 1.77118\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.3460 - acc: 0.8538 - val_loss: 1.8104 - val_acc: 0.6200 - lr: 3.0000e-04\n",
      "Epoch 4/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.3384 - acc: 0.8641\n",
      "Epoch 4: val_loss improved from 1.77118 to 0.29999, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_mobilenet_weights.h5\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.3392 - acc: 0.8635 - val_loss: 0.3000 - val_acc: 0.8820 - lr: 3.0000e-04\n",
      "Epoch 5/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.2850 - acc: 0.8889\n",
      "Epoch 5: val_loss improved from 0.29999 to 0.22888, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_mobilenet_weights.h5\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.2858 - acc: 0.8887 - val_loss: 0.2289 - val_acc: 0.9146 - lr: 3.0000e-04\n",
      "Epoch 6/160\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.2711 - acc: 0.8869\n",
      "Epoch 6: val_loss did not improve from 0.22888\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2711 - acc: 0.8869 - val_loss: 0.2328 - val_acc: 0.9089 - lr: 3.0000e-04\n",
      "Epoch 7/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2532 - acc: 0.8959\n",
      "Epoch 7: val_loss did not improve from 0.22888\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2535 - acc: 0.8956 - val_loss: 0.2316 - val_acc: 0.8999 - lr: 3.0000e-04\n",
      "Epoch 8/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2365 - acc: 0.9118\n",
      "Epoch 8: val_loss improved from 0.22888 to 0.20773, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_mobilenet_weights.h5\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.2363 - acc: 0.9120 - val_loss: 0.2077 - val_acc: 0.9154 - lr: 3.0000e-04\n",
      "Epoch 9/160\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.2357 - acc: 0.9082\n",
      "Epoch 9: val_loss did not improve from 0.20773\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2357 - acc: 0.9082 - val_loss: 0.2249 - val_acc: 0.9072 - lr: 3.0000e-04\n",
      "Epoch 10/160\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.2304 - acc: 0.9124\n",
      "Epoch 10: val_loss did not improve from 0.20773\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2304 - acc: 0.9124 - val_loss: 0.2865 - val_acc: 0.9097 - lr: 3.0000e-04\n",
      "Epoch 11/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.2135 - acc: 0.9176\n",
      "Epoch 11: val_loss improved from 0.20773 to 0.19645, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_mobilenet_weights.h5\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.2128 - acc: 0.9183 - val_loss: 0.1964 - val_acc: 0.9284 - lr: 3.0000e-04\n",
      "Epoch 12/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2029 - acc: 0.9216\n",
      "Epoch 12: val_loss did not improve from 0.19645\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2029 - acc: 0.9218 - val_loss: 0.2727 - val_acc: 0.8999 - lr: 3.0000e-04\n",
      "Epoch 13/160\n",
      "179/180 [============================>.] - ETA: 0s - loss: 0.1931 - acc: 0.9273\n",
      "Epoch 13: val_loss did not improve from 0.19645\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1947 - acc: 0.9267 - val_loss: 0.2029 - val_acc: 0.9260 - lr: 3.0000e-04\n",
      "Epoch 14/160\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.1819 - acc: 0.9281\n",
      "Epoch 14: val_loss did not improve from 0.19645\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1819 - acc: 0.9281 - val_loss: 0.4106 - val_acc: 0.8625 - lr: 3.0000e-04\n",
      "Epoch 15/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.1786 - acc: 0.9301\n",
      "Epoch 15: val_loss did not improve from 0.19645\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1789 - acc: 0.9298 - val_loss: 0.2711 - val_acc: 0.8942 - lr: 3.0000e-04\n",
      "Epoch 16/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1911 - acc: 0.9315\n",
      "Epoch 16: val_loss improved from 0.19645 to 0.18914, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_mobilenet_weights.h5\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.1923 - acc: 0.9305 - val_loss: 0.1891 - val_acc: 0.9235 - lr: 3.0000e-04\n",
      "Epoch 17/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.1780 - acc: 0.9311\n",
      "Epoch 17: val_loss did not improve from 0.18914\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1786 - acc: 0.9305 - val_loss: 0.3300 - val_acc: 0.8617 - lr: 3.0000e-04\n",
      "Epoch 18/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.1583 - acc: 0.9411\n",
      "Epoch 18: val_loss improved from 0.18914 to 0.18413, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_mobilenet_weights.h5\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.1593 - acc: 0.9410 - val_loss: 0.1841 - val_acc: 0.9186 - lr: 3.0000e-04\n",
      "Epoch 19/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.1503 - acc: 0.9439\n",
      "Epoch 19: val_loss did not improve from 0.18413\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1506 - acc: 0.9442 - val_loss: 0.1844 - val_acc: 0.9308 - lr: 3.0000e-04\n",
      "Epoch 20/160\n",
      "179/180 [============================>.] - ETA: 0s - loss: 0.1514 - acc: 0.9396\n",
      "Epoch 20: val_loss did not improve from 0.18413\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1509 - acc: 0.9400 - val_loss: 0.2038 - val_acc: 0.9235 - lr: 3.0000e-04\n",
      "Epoch 21/160\n",
      "179/180 [============================>.] - ETA: 0s - loss: 0.1445 - acc: 0.9481\n",
      "Epoch 21: val_loss improved from 0.18413 to 0.17986, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_mobilenet_weights.h5\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.1449 - acc: 0.9476 - val_loss: 0.1799 - val_acc: 0.9284 - lr: 3.0000e-04\n",
      "Epoch 22/160\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.1323 - acc: 0.9511\n",
      "Epoch 22: val_loss did not improve from 0.17986\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1323 - acc: 0.9511 - val_loss: 0.1927 - val_acc: 0.9251 - lr: 3.0000e-04\n",
      "Epoch 23/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1327 - acc: 0.9527\n",
      "Epoch 23: val_loss improved from 0.17986 to 0.16199, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_mobilenet_weights.h5\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.1318 - acc: 0.9529 - val_loss: 0.1620 - val_acc: 0.9447 - lr: 3.0000e-04\n",
      "Epoch 24/160\n",
      "179/180 [============================>.] - ETA: 0s - loss: 0.1417 - acc: 0.9466\n",
      "Epoch 24: val_loss improved from 0.16199 to 0.14673, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_mobilenet_weights.h5\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.1410 - acc: 0.9469 - val_loss: 0.1467 - val_acc: 0.9390 - lr: 3.0000e-04\n",
      "Epoch 25/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1380 - acc: 0.9545\n",
      "Epoch 25: val_loss did not improve from 0.14673\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1387 - acc: 0.9539 - val_loss: 0.1775 - val_acc: 0.9292 - lr: 3.0000e-04\n",
      "Epoch 26/160\n",
      "179/180 [============================>.] - ETA: 0s - loss: 0.1165 - acc: 0.9565\n",
      "Epoch 26: val_loss did not improve from 0.14673\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1160 - acc: 0.9567 - val_loss: 0.2020 - val_acc: 0.9308 - lr: 3.0000e-04\n",
      "Epoch 27/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1064 - acc: 0.9636\n",
      "Epoch 27: val_loss did not improve from 0.14673\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1060 - acc: 0.9637 - val_loss: 0.3550 - val_acc: 0.8926 - lr: 3.0000e-04\n",
      "Epoch 28/160\n",
      "179/180 [============================>.] - ETA: 0s - loss: 0.1220 - acc: 0.9551\n",
      "Epoch 28: val_loss did not improve from 0.14673\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1221 - acc: 0.9553 - val_loss: 0.2292 - val_acc: 0.9211 - lr: 3.0000e-04\n",
      "Epoch 29/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1089 - acc: 0.9587\n",
      "Epoch 29: val_loss did not improve from 0.14673\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1086 - acc: 0.9585 - val_loss: 0.2100 - val_acc: 0.9357 - lr: 3.0000e-04\n",
      "Epoch 30/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.0887 - acc: 0.9698\n",
      "Epoch 30: val_loss did not improve from 0.14673\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.0886 - acc: 0.9696 - val_loss: 0.2021 - val_acc: 0.9333 - lr: 3.0000e-04\n",
      "Epoch 31/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1074 - acc: 0.9615\n",
      "Epoch 31: val_loss did not improve from 0.14673\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1066 - acc: 0.9620 - val_loss: 0.1704 - val_acc: 0.9414 - lr: 3.0000e-04\n",
      "Epoch 32/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.1056 - acc: 0.9634\n",
      "Epoch 32: val_loss did not improve from 0.14673\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1060 - acc: 0.9627 - val_loss: 0.1640 - val_acc: 0.9382 - lr: 3.0000e-04\n",
      "Epoch 33/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0789 - acc: 0.9721\n",
      "Epoch 33: val_loss did not improve from 0.14673\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.0824 - acc: 0.9721 - val_loss: 0.2487 - val_acc: 0.9105 - lr: 3.0000e-04\n",
      "Epoch 34/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0850 - acc: 0.9675\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 0.00022500001068692654.\n",
      "\n",
      "Epoch 34: val_loss did not improve from 0.14673\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.0876 - acc: 0.9668 - val_loss: 0.2781 - val_acc: 0.9007 - lr: 3.0000e-04\n",
      "Epoch 35/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0739 - acc: 0.9753\n",
      "Epoch 35: val_loss did not improve from 0.14673\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.0732 - acc: 0.9756 - val_loss: 0.1516 - val_acc: 0.9512 - lr: 2.2500e-04\n",
      "Epoch 36/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.0677 - acc: 0.9759\n",
      "Epoch 36: val_loss did not improve from 0.14673\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.0669 - acc: 0.9763 - val_loss: 0.1717 - val_acc: 0.9439 - lr: 2.2500e-04\n",
      "Epoch 37/160\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.0553 - acc: 0.9791\n",
      "Epoch 37: val_loss did not improve from 0.14673\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.0553 - acc: 0.9791 - val_loss: 0.2390 - val_acc: 0.9341 - lr: 2.2500e-04\n",
      "Epoch 38/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0575 - acc: 0.9771\n",
      "Epoch 38: val_loss did not improve from 0.14673\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.0593 - acc: 0.9766 - val_loss: 0.1969 - val_acc: 0.9219 - lr: 2.2500e-04\n",
      "Epoch 39/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.0628 - acc: 0.9752\n",
      "Epoch 39: val_loss did not improve from 0.14673\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.0632 - acc: 0.9749 - val_loss: 0.2685 - val_acc: 0.9227 - lr: 2.2500e-04\n",
      "Epoch 40/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0435 - acc: 0.9859\n",
      "Epoch 40: val_loss did not improve from 0.14673\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.0437 - acc: 0.9857 - val_loss: 0.1555 - val_acc: 0.9544 - lr: 2.2500e-04\n",
      "Epoch 41/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0698 - acc: 0.9756\n",
      "Epoch 41: val_loss did not improve from 0.14673\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.0693 - acc: 0.9759 - val_loss: 0.1556 - val_acc: 0.9357 - lr: 2.2500e-04\n",
      "Epoch 42/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.0502 - acc: 0.9845\n",
      "Epoch 42: val_loss did not improve from 0.14673\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.0499 - acc: 0.9846 - val_loss: 0.1475 - val_acc: 0.9447 - lr: 2.2500e-04\n",
      "Epoch 43/160\n",
      "179/180 [============================>.] - ETA: 0s - loss: 0.0571 - acc: 0.9765\n",
      "Epoch 43: val_loss did not improve from 0.14673\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.0570 - acc: 0.9766 - val_loss: 0.1693 - val_acc: 0.9455 - lr: 2.2500e-04\n",
      "Epoch 44/160\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.0386 - acc: 0.9885\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 0.0001687500080151949.\n",
      "\n",
      "Epoch 44: val_loss did not improve from 0.14673\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.0386 - acc: 0.9885 - val_loss: 0.1718 - val_acc: 0.9520 - lr: 2.2500e-04\n",
      "Epoch 44: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/scripts/dl_utils.py:172: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  valores.append(float(df.iloc[3][-2]))\n",
      "/mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/scripts/dl_utils.py:176: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  valores_old.append(float(prev_df.iloc[3][-2]))\n",
      "/mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/scripts/dl_utils.py:172: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  valores.append(float(df.iloc[3][-2]))\n",
      "/mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/scripts/dl_utils.py:176: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  valores_old.append(float(prev_df.iloc[3][-2]))\n",
      "/mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/scripts/dl_utils.py:172: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  valores.append(float(df.iloc[3][-2]))\n",
      "/mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/scripts/dl_utils.py:176: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  valores_old.append(float(prev_df.iloc[3][-2]))\n",
      "/mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/scripts/dl_utils.py:172: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  valores.append(float(df.iloc[3][-2]))\n",
      "/mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/scripts/dl_utils.py:176: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  valores_old.append(float(prev_df.iloc[3][-2]))\n",
      "/home/raulpg/anaconda3/envs/tfm_tf/lib/python3.11/site-packages/keras/src/preprocessing/image.py:2093: UserWarning: Expected input to be images (as Numpy array) following the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3 or 4 channels on axis 3. However, it was passed an array with shape (2865, 48, 48, 12) (12 channels).\n",
      "  warnings.warn(\n",
      "/home/raulpg/anaconda3/envs/tfm_tf/lib/python3.11/site-packages/keras/src/preprocessing/image.py:766: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3, or 4 channels on axis 3. However, it was passed an array with shape (2865, 48, 48, 12) (12 channels).\n",
      "  warnings.warn(\n",
      "/home/raulpg/anaconda3/envs/tfm_tf/lib/python3.11/site-packages/keras/src/preprocessing/image.py:766: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3, or 4 channels on axis 3. However, it was passed an array with shape (1229, 48, 48, 12) (12 channels).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "Epoch 1/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.6799 - acc: 0.5690\n",
      "Epoch 1: val_loss improved from inf to 0.69850, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 5s 20ms/step - loss: 0.6782 - acc: 0.5717 - val_loss: 0.6985 - val_acc: 0.5956\n",
      "Epoch 2/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.5934 - acc: 0.6911\n",
      "Epoch 2: val_loss improved from 0.69850 to 0.61423, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.5928 - acc: 0.6925 - val_loss: 0.6142 - val_acc: 0.6395\n",
      "Epoch 3/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.5907 - acc: 0.7100\n",
      "Epoch 3: val_loss improved from 0.61423 to 0.56937, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.5895 - acc: 0.7110 - val_loss: 0.5694 - val_acc: 0.6802\n",
      "Epoch 4/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.5371 - acc: 0.7423\n",
      "Epoch 4: val_loss improved from 0.56937 to 0.52745, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.5386 - acc: 0.7428 - val_loss: 0.5274 - val_acc: 0.7347\n",
      "Epoch 5/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.5002 - acc: 0.7642\n",
      "Epoch 5: val_loss improved from 0.52745 to 0.48498, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.4996 - acc: 0.7651 - val_loss: 0.4850 - val_acc: 0.7697\n",
      "Epoch 6/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.5445 - acc: 0.7363\n",
      "Epoch 6: val_loss did not improve from 0.48498\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.5444 - acc: 0.7361 - val_loss: 0.6189 - val_acc: 0.6225\n",
      "Epoch 7/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.5027 - acc: 0.7575\n",
      "Epoch 7: val_loss did not improve from 0.48498\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.5024 - acc: 0.7585 - val_loss: 0.5023 - val_acc: 0.7559\n",
      "Epoch 8/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.4950 - acc: 0.7713\n",
      "Epoch 8: val_loss improved from 0.48498 to 0.47259, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.4943 - acc: 0.7714 - val_loss: 0.4726 - val_acc: 0.7608\n",
      "Epoch 9/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.4849 - acc: 0.7829\n",
      "Epoch 9: val_loss did not improve from 0.47259\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.4847 - acc: 0.7829 - val_loss: 0.5120 - val_acc: 0.7592\n",
      "Epoch 10/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.4597 - acc: 0.7910\n",
      "Epoch 10: val_loss improved from 0.47259 to 0.46885, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.4606 - acc: 0.7899 - val_loss: 0.4689 - val_acc: 0.7616\n",
      "Epoch 11/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.4298 - acc: 0.8009\n",
      "Epoch 11: val_loss improved from 0.46885 to 0.39116, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.4277 - acc: 0.8021 - val_loss: 0.3912 - val_acc: 0.8080\n",
      "Epoch 12/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.4236 - acc: 0.8108\n",
      "Epoch 12: val_loss did not improve from 0.39116\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.4215 - acc: 0.8115 - val_loss: 0.4636 - val_acc: 0.7852\n",
      "Epoch 13/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.4225 - acc: 0.8101\n",
      "Epoch 13: val_loss did not improve from 0.39116\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.4234 - acc: 0.8091 - val_loss: 0.4210 - val_acc: 0.7909\n",
      "Epoch 14/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.3948 - acc: 0.8150\n",
      "Epoch 14: val_loss improved from 0.39116 to 0.37119, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.3934 - acc: 0.8157 - val_loss: 0.3712 - val_acc: 0.8259\n",
      "Epoch 15/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.3879 - acc: 0.8306\n",
      "Epoch 15: val_loss did not improve from 0.37119\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.3870 - acc: 0.8318 - val_loss: 0.3803 - val_acc: 0.8332\n",
      "Epoch 16/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.3686 - acc: 0.8359\n",
      "Epoch 16: val_loss did not improve from 0.37119\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.3688 - acc: 0.8363 - val_loss: 0.3818 - val_acc: 0.8259\n",
      "Epoch 17/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.5958 - acc: 0.7144\n",
      "Epoch 17: val_loss did not improve from 0.37119\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.5956 - acc: 0.7152 - val_loss: 0.4577 - val_acc: 0.7779\n",
      "Epoch 18/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.4344 - acc: 0.7967\n",
      "Epoch 18: val_loss did not improve from 0.37119\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.4353 - acc: 0.7972 - val_loss: 0.3770 - val_acc: 0.8226\n",
      "Epoch 19/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.3759 - acc: 0.8299\n",
      "Epoch 19: val_loss improved from 0.37119 to 0.36706, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.3746 - acc: 0.8304 - val_loss: 0.3671 - val_acc: 0.8389\n",
      "Epoch 20/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.3588 - acc: 0.8502\n",
      "Epoch 20: val_loss did not improve from 0.36706\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.3580 - acc: 0.8496 - val_loss: 0.4048 - val_acc: 0.8112\n",
      "Epoch 21/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.3519 - acc: 0.8412\n",
      "Epoch 21: val_loss improved from 0.36706 to 0.33057, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.3511 - acc: 0.8415 - val_loss: 0.3306 - val_acc: 0.8381\n",
      "Epoch 22/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.3521 - acc: 0.8426\n",
      "Epoch 22: val_loss improved from 0.33057 to 0.32825, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.3527 - acc: 0.8408 - val_loss: 0.3282 - val_acc: 0.8446\n",
      "Epoch 23/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.3451 - acc: 0.8514\n",
      "Epoch 23: val_loss did not improve from 0.32825\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.3444 - acc: 0.8513 - val_loss: 0.3442 - val_acc: 0.8503\n",
      "Epoch 24/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.3169 - acc: 0.8683\n",
      "Epoch 24: val_loss did not improve from 0.32825\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.3205 - acc: 0.8677 - val_loss: 0.3333 - val_acc: 0.8576\n",
      "Epoch 25/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.3223 - acc: 0.8641\n",
      "Epoch 25: val_loss improved from 0.32825 to 0.31873, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.3233 - acc: 0.8646 - val_loss: 0.3187 - val_acc: 0.8625\n",
      "Epoch 26/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.3174 - acc: 0.8630\n",
      "Epoch 26: val_loss improved from 0.31873 to 0.31695, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.3164 - acc: 0.8635 - val_loss: 0.3169 - val_acc: 0.8617\n",
      "Epoch 27/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.3157 - acc: 0.8616\n",
      "Epoch 27: val_loss did not improve from 0.31695\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.3146 - acc: 0.8618 - val_loss: 0.3471 - val_acc: 0.8389\n",
      "Epoch 28/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2933 - acc: 0.8761\n",
      "Epoch 28: val_loss improved from 0.31695 to 0.28877, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2945 - acc: 0.8754 - val_loss: 0.2888 - val_acc: 0.8763\n",
      "Epoch 29/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.3056 - acc: 0.8779\n",
      "Epoch 29: val_loss did not improve from 0.28877\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.3045 - acc: 0.8782 - val_loss: 0.3341 - val_acc: 0.8544\n",
      "Epoch 30/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2921 - acc: 0.8733\n",
      "Epoch 30: val_loss did not improve from 0.28877\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.2929 - acc: 0.8729 - val_loss: 0.3007 - val_acc: 0.8706\n",
      "Epoch 31/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2904 - acc: 0.8765\n",
      "Epoch 31: val_loss improved from 0.28877 to 0.27563, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2902 - acc: 0.8768 - val_loss: 0.2756 - val_acc: 0.8877\n",
      "Epoch 32/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2980 - acc: 0.8726\n",
      "Epoch 32: val_loss did not improve from 0.27563\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.2966 - acc: 0.8733 - val_loss: 0.2765 - val_acc: 0.8820\n",
      "Epoch 33/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.3207 - acc: 0.8648\n",
      "Epoch 33: val_loss improved from 0.27563 to 0.27176, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.3204 - acc: 0.8653 - val_loss: 0.2718 - val_acc: 0.8885\n",
      "Epoch 34/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2759 - acc: 0.8895\n",
      "Epoch 34: val_loss did not improve from 0.27176\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.2764 - acc: 0.8887 - val_loss: 0.3103 - val_acc: 0.8666\n",
      "Epoch 35/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2761 - acc: 0.8955\n",
      "Epoch 35: val_loss did not improve from 0.27176\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.2751 - acc: 0.8956 - val_loss: 0.3968 - val_acc: 0.8332\n",
      "Epoch 36/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2739 - acc: 0.8842\n",
      "Epoch 36: val_loss improved from 0.27176 to 0.26817, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2732 - acc: 0.8841 - val_loss: 0.2682 - val_acc: 0.8934\n",
      "Epoch 37/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2662 - acc: 0.8878\n",
      "Epoch 37: val_loss improved from 0.26817 to 0.26152, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2662 - acc: 0.8883 - val_loss: 0.2615 - val_acc: 0.8812\n",
      "Epoch 38/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2570 - acc: 0.8983\n",
      "Epoch 38: val_loss did not improve from 0.26152\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.2575 - acc: 0.8984 - val_loss: 0.3672 - val_acc: 0.8592\n",
      "Epoch 39/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.2771 - acc: 0.8875\n",
      "Epoch 39: val_loss did not improve from 0.26152\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.2761 - acc: 0.8876 - val_loss: 0.2757 - val_acc: 0.8763\n",
      "Epoch 40/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2692 - acc: 0.8916\n",
      "Epoch 40: val_loss did not improve from 0.26152\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.2694 - acc: 0.8921 - val_loss: 0.2774 - val_acc: 0.8845\n",
      "Epoch 41/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2663 - acc: 0.8990\n",
      "Epoch 41: val_loss improved from 0.26152 to 0.25647, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2668 - acc: 0.8977 - val_loss: 0.2565 - val_acc: 0.8845\n",
      "Epoch 42/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.2453 - acc: 0.9013\n",
      "Epoch 42: val_loss improved from 0.25647 to 0.24854, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2452 - acc: 0.9012 - val_loss: 0.2485 - val_acc: 0.9040\n",
      "Epoch 43/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2506 - acc: 0.8998\n",
      "Epoch 43: val_loss improved from 0.24854 to 0.24297, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2524 - acc: 0.8998 - val_loss: 0.2430 - val_acc: 0.8934\n",
      "Epoch 44/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2398 - acc: 0.9086\n",
      "Epoch 44: val_loss did not improve from 0.24297\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.2387 - acc: 0.9089 - val_loss: 0.2438 - val_acc: 0.8991\n",
      "Epoch 45/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2304 - acc: 0.9103\n",
      "Epoch 45: val_loss did not improve from 0.24297\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.2309 - acc: 0.9103 - val_loss: 0.2501 - val_acc: 0.9056\n",
      "Epoch 46/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2451 - acc: 0.9075\n",
      "Epoch 46: val_loss did not improve from 0.24297\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.2438 - acc: 0.9079 - val_loss: 0.2458 - val_acc: 0.9015\n",
      "Epoch 47/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2293 - acc: 0.9089\n",
      "Epoch 47: val_loss did not improve from 0.24297\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.2313 - acc: 0.9082 - val_loss: 0.2711 - val_acc: 0.8926\n",
      "Epoch 48/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2555 - acc: 0.8983\n",
      "Epoch 48: val_loss did not improve from 0.24297\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.2548 - acc: 0.8984 - val_loss: 0.2499 - val_acc: 0.8967\n",
      "Epoch 49/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2313 - acc: 0.9086\n",
      "Epoch 49: val_loss did not improve from 0.24297\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.2302 - acc: 0.9092 - val_loss: 0.2531 - val_acc: 0.8885\n",
      "Epoch 50/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2299 - acc: 0.9065\n",
      "Epoch 50: val_loss improved from 0.24297 to 0.22257, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2297 - acc: 0.9068 - val_loss: 0.2226 - val_acc: 0.9015\n",
      "Epoch 51/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2343 - acc: 0.9114\n",
      "Epoch 51: val_loss did not improve from 0.22257\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.2342 - acc: 0.9113 - val_loss: 0.2511 - val_acc: 0.9007\n",
      "Epoch 52/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2263 - acc: 0.9142\n",
      "Epoch 52: val_loss improved from 0.22257 to 0.21687, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2256 - acc: 0.9145 - val_loss: 0.2169 - val_acc: 0.9186\n",
      "Epoch 53/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2085 - acc: 0.9195\n",
      "Epoch 53: val_loss did not improve from 0.21687\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.2081 - acc: 0.9194 - val_loss: 0.2864 - val_acc: 0.8828\n",
      "Epoch 54/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2271 - acc: 0.9110\n",
      "Epoch 54: val_loss did not improve from 0.21687\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.2273 - acc: 0.9110 - val_loss: 0.2340 - val_acc: 0.9072\n",
      "Epoch 55/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2212 - acc: 0.9068\n",
      "Epoch 55: val_loss did not improve from 0.21687\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.2231 - acc: 0.9061 - val_loss: 0.2369 - val_acc: 0.8950\n",
      "Epoch 56/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2142 - acc: 0.9174\n",
      "Epoch 56: val_loss did not improve from 0.21687\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.2145 - acc: 0.9169 - val_loss: 0.2270 - val_acc: 0.9064\n",
      "Epoch 57/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1957 - acc: 0.9283\n",
      "Epoch 57: val_loss did not improve from 0.21687\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1973 - acc: 0.9284 - val_loss: 0.2292 - val_acc: 0.8999\n",
      "Epoch 58/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2025 - acc: 0.9192\n",
      "Epoch 58: val_loss did not improve from 0.21687\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.2020 - acc: 0.9197 - val_loss: 0.2356 - val_acc: 0.8975\n",
      "Epoch 59/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1975 - acc: 0.9276\n",
      "Epoch 59: val_loss did not improve from 0.21687\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1968 - acc: 0.9277 - val_loss: 0.2248 - val_acc: 0.9015\n",
      "Epoch 60/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2099 - acc: 0.9202\n",
      "Epoch 60: val_loss did not improve from 0.21687\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.2098 - acc: 0.9204 - val_loss: 0.2388 - val_acc: 0.8991\n",
      "Epoch 61/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1997 - acc: 0.9188\n",
      "Epoch 61: val_loss did not improve from 0.21687\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.2006 - acc: 0.9190 - val_loss: 0.2193 - val_acc: 0.9178\n",
      "Epoch 62/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1936 - acc: 0.9259\n",
      "Epoch 62: val_loss improved from 0.21687 to 0.21413, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1937 - acc: 0.9253 - val_loss: 0.2141 - val_acc: 0.9154\n",
      "Epoch 63/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.1907 - acc: 0.9205\n",
      "Epoch 63: val_loss did not improve from 0.21413\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1909 - acc: 0.9197 - val_loss: 0.2458 - val_acc: 0.9015\n",
      "Epoch 64/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2003 - acc: 0.9220\n",
      "Epoch 64: val_loss did not improve from 0.21413\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1998 - acc: 0.9218 - val_loss: 0.2690 - val_acc: 0.8910\n",
      "Epoch 65/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1927 - acc: 0.9213\n",
      "Epoch 65: val_loss improved from 0.21413 to 0.20563, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1923 - acc: 0.9215 - val_loss: 0.2056 - val_acc: 0.9186\n",
      "Epoch 66/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1878 - acc: 0.9283\n",
      "Epoch 66: val_loss did not improve from 0.20563\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1891 - acc: 0.9284 - val_loss: 0.2285 - val_acc: 0.9032\n",
      "Epoch 67/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1980 - acc: 0.9255\n",
      "Epoch 67: val_loss did not improve from 0.20563\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1965 - acc: 0.9264 - val_loss: 0.2166 - val_acc: 0.9113\n",
      "Epoch 68/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1810 - acc: 0.9336\n",
      "Epoch 68: val_loss did not improve from 0.20563\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1798 - acc: 0.9340 - val_loss: 0.2531 - val_acc: 0.8983\n",
      "Epoch 69/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1814 - acc: 0.9301\n",
      "Epoch 69: val_loss improved from 0.20563 to 0.19681, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1847 - acc: 0.9291 - val_loss: 0.1968 - val_acc: 0.9227\n",
      "Epoch 70/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1804 - acc: 0.9283\n",
      "Epoch 70: val_loss improved from 0.19681 to 0.18850, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1798 - acc: 0.9284 - val_loss: 0.1885 - val_acc: 0.9203\n",
      "Epoch 71/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2547 - acc: 0.9241\n",
      "Epoch 71: val_loss did not improve from 0.18850\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.2541 - acc: 0.9246 - val_loss: 0.3302 - val_acc: 0.8682\n",
      "Epoch 72/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.2338 - acc: 0.9148\n",
      "Epoch 72: val_loss did not improve from 0.18850\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2359 - acc: 0.9131 - val_loss: 0.2538 - val_acc: 0.8893\n",
      "Epoch 73/160\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.1916 - acc: 0.9288\n",
      "Epoch 73: val_loss did not improve from 0.18850\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1916 - acc: 0.9288 - val_loss: 0.2124 - val_acc: 0.9162\n",
      "Epoch 74/160\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.1900 - acc: 0.9281\n",
      "Epoch 74: val_loss did not improve from 0.18850\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1900 - acc: 0.9281 - val_loss: 0.1935 - val_acc: 0.9235\n",
      "Epoch 75/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1741 - acc: 0.9351\n",
      "Epoch 75: val_loss did not improve from 0.18850\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1747 - acc: 0.9347 - val_loss: 0.2053 - val_acc: 0.9300\n",
      "Epoch 76/160\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.1719 - acc: 0.9330\n",
      "Epoch 76: val_loss did not improve from 0.18850\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1719 - acc: 0.9330 - val_loss: 0.2169 - val_acc: 0.9064\n",
      "Epoch 77/160\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.1654 - acc: 0.9368\n",
      "Epoch 77: val_loss improved from 0.18850 to 0.18123, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.1654 - acc: 0.9368 - val_loss: 0.1812 - val_acc: 0.9300\n",
      "Epoch 78/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.1628 - acc: 0.9354\n",
      "Epoch 78: val_loss did not improve from 0.18123\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1630 - acc: 0.9358 - val_loss: 0.2050 - val_acc: 0.9178\n",
      "Epoch 79/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.1630 - acc: 0.9368\n",
      "Epoch 79: val_loss did not improve from 0.18123\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1650 - acc: 0.9361 - val_loss: 0.2088 - val_acc: 0.9121\n",
      "Epoch 80/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.1554 - acc: 0.9386\n",
      "Epoch 80: val_loss did not improve from 0.18123\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1554 - acc: 0.9389 - val_loss: 0.2011 - val_acc: 0.9178\n",
      "Epoch 81/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1579 - acc: 0.9389\n",
      "Epoch 81: val_loss did not improve from 0.18123\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.1600 - acc: 0.9382 - val_loss: 0.2250 - val_acc: 0.9219\n",
      "Epoch 82/160\n",
      "179/180 [============================>.] - ETA: 0s - loss: 0.1614 - acc: 0.9375\n",
      "Epoch 82: val_loss did not improve from 0.18123\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.1612 - acc: 0.9379 - val_loss: 0.2259 - val_acc: 0.9056\n",
      "Epoch 83/160\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.1549 - acc: 0.9386\n",
      "Epoch 83: val_loss did not improve from 0.18123\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1549 - acc: 0.9386 - val_loss: 0.1936 - val_acc: 0.9251\n",
      "Epoch 84/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1623 - acc: 0.9365\n",
      "Epoch 84: val_loss did not improve from 0.18123\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1616 - acc: 0.9365 - val_loss: 0.1941 - val_acc: 0.9211\n",
      "Epoch 85/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1594 - acc: 0.9379\n",
      "Epoch 85: val_loss did not improve from 0.18123\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1592 - acc: 0.9379 - val_loss: 0.1922 - val_acc: 0.9251\n",
      "Epoch 86/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1518 - acc: 0.9396\n",
      "Epoch 86: val_loss did not improve from 0.18123\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1518 - acc: 0.9400 - val_loss: 0.2614 - val_acc: 0.9048\n",
      "Epoch 87/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1666 - acc: 0.9407\n",
      "Epoch 87: val_loss did not improve from 0.18123\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.1668 - acc: 0.9407 - val_loss: 0.2208 - val_acc: 0.9056\n",
      "Epoch 88/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1581 - acc: 0.9442\n",
      "Epoch 88: val_loss did not improve from 0.18123\n",
      "180/180 [==============================] - 4s 19ms/step - loss: 0.1581 - acc: 0.9442 - val_loss: 0.2136 - val_acc: 0.9170\n",
      "Epoch 89/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1525 - acc: 0.9428\n",
      "Epoch 89: val_loss improved from 0.18123 to 0.16569, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_alexnet_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1525 - acc: 0.9428 - val_loss: 0.1657 - val_acc: 0.9284\n",
      "Epoch 90/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1548 - acc: 0.9407\n",
      "Epoch 90: val_loss did not improve from 0.16569\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1561 - acc: 0.9403 - val_loss: 0.2238 - val_acc: 0.9089\n",
      "Epoch 91/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.1594 - acc: 0.9414\n",
      "Epoch 91: val_loss did not improve from 0.16569\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1612 - acc: 0.9403 - val_loss: 0.1772 - val_acc: 0.9406\n",
      "Epoch 92/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1547 - acc: 0.9400\n",
      "Epoch 92: val_loss did not improve from 0.16569\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1542 - acc: 0.9400 - val_loss: 0.2081 - val_acc: 0.9235\n",
      "Epoch 93/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1556 - acc: 0.9418\n",
      "Epoch 93: val_loss did not improve from 0.16569\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1564 - acc: 0.9417 - val_loss: 0.2361 - val_acc: 0.9105\n",
      "Epoch 94/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1548 - acc: 0.9411\n",
      "Epoch 94: val_loss did not improve from 0.16569\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1551 - acc: 0.9410 - val_loss: 0.2055 - val_acc: 0.9162\n",
      "Epoch 95/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1478 - acc: 0.9425\n",
      "Epoch 95: val_loss did not improve from 0.16569\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1467 - acc: 0.9428 - val_loss: 0.2301 - val_acc: 0.9121\n",
      "Epoch 96/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.1441 - acc: 0.9464\n",
      "Epoch 96: val_loss did not improve from 0.16569\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1430 - acc: 0.9469 - val_loss: 0.2011 - val_acc: 0.9162\n",
      "Epoch 97/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1566 - acc: 0.9379\n",
      "Epoch 97: val_loss did not improve from 0.16569\n",
      "180/180 [==============================] - 3s 19ms/step - loss: 0.1563 - acc: 0.9375 - val_loss: 0.2473 - val_acc: 0.8991\n",
      "Epoch 98/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.1535 - acc: 0.9404\n",
      "Epoch 98: val_loss did not improve from 0.16569\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1531 - acc: 0.9403 - val_loss: 0.2157 - val_acc: 0.9064\n",
      "Epoch 99/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.1415 - acc: 0.9446\n",
      "Epoch 99: val_loss did not improve from 0.16569\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.1414 - acc: 0.9449 - val_loss: 0.2184 - val_acc: 0.9146\n",
      "Epoch 100/160\n",
      "179/180 [============================>.] - ETA: 0s - loss: 0.1574 - acc: 0.9386\n",
      "Epoch 100: val_loss did not improve from 0.16569\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.1570 - acc: 0.9389 - val_loss: 0.1802 - val_acc: 0.9317\n",
      "Epoch 101/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.1374 - acc: 0.9446\n",
      "Epoch 101: val_loss did not improve from 0.16569\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.1368 - acc: 0.9449 - val_loss: 0.2362 - val_acc: 0.9089\n",
      "Epoch 102/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1269 - acc: 0.9485\n",
      "Epoch 102: val_loss did not improve from 0.16569\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.1282 - acc: 0.9483 - val_loss: 0.2384 - val_acc: 0.9154\n",
      "Epoch 103/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.1466 - acc: 0.9485\n",
      "Epoch 103: val_loss did not improve from 0.16569\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.1466 - acc: 0.9483 - val_loss: 0.2046 - val_acc: 0.9243\n",
      "Epoch 103: early stopping\n",
      "Epoch 1/160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-23 09:08:14.347343: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape insequential_1/dropout_2/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179/180 [============================>.] - ETA: 0s - loss: 0.6423 - acc: 0.6111\n",
      "Epoch 1: val_loss improved from inf to 0.55782, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 5s 20ms/step - loss: 0.6422 - acc: 0.6119 - val_loss: 0.5578 - val_acc: 0.7608\n",
      "Epoch 2/160\n",
      "179/180 [============================>.] - ETA: 0s - loss: 0.5149 - acc: 0.7645\n",
      "Epoch 2: val_loss improved from 0.55782 to 0.49383, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.5146 - acc: 0.7651 - val_loss: 0.4938 - val_acc: 0.7974\n",
      "Epoch 3/160\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.4864 - acc: 0.7735\n",
      "Epoch 3: val_loss did not improve from 0.49383\n",
      "180/180 [==============================] - 4s 22ms/step - loss: 0.4864 - acc: 0.7735 - val_loss: 0.5011 - val_acc: 0.7575\n",
      "Epoch 4/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.4350 - acc: 0.8016\n",
      "Epoch 4: val_loss improved from 0.49383 to 0.39604, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.4368 - acc: 0.8017 - val_loss: 0.3960 - val_acc: 0.8218\n",
      "Epoch 5/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.4311 - acc: 0.8119\n",
      "Epoch 5: val_loss improved from 0.39604 to 0.38522, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.4300 - acc: 0.8126 - val_loss: 0.3852 - val_acc: 0.8096\n",
      "Epoch 6/160\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.4187 - acc: 0.8182\n",
      "Epoch 6: val_loss did not improve from 0.38522\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.4187 - acc: 0.8182 - val_loss: 0.4412 - val_acc: 0.7941\n",
      "Epoch 7/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.3869 - acc: 0.8246\n",
      "Epoch 7: val_loss improved from 0.38522 to 0.35996, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.3854 - acc: 0.8251 - val_loss: 0.3600 - val_acc: 0.8218\n",
      "Epoch 8/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.3771 - acc: 0.8373\n",
      "Epoch 8: val_loss improved from 0.35996 to 0.35043, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.3763 - acc: 0.8380 - val_loss: 0.3504 - val_acc: 0.8470\n",
      "Epoch 9/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.3416 - acc: 0.8496\n",
      "Epoch 9: val_loss improved from 0.35043 to 0.34969, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.3433 - acc: 0.8485 - val_loss: 0.3497 - val_acc: 0.8470\n",
      "Epoch 10/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.3338 - acc: 0.8652\n",
      "Epoch 10: val_loss improved from 0.34969 to 0.31008, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.3338 - acc: 0.8642 - val_loss: 0.3101 - val_acc: 0.8739\n",
      "Epoch 11/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.3242 - acc: 0.8641\n",
      "Epoch 11: val_loss did not improve from 0.31008\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.3245 - acc: 0.8642 - val_loss: 0.3422 - val_acc: 0.8503\n",
      "Epoch 12/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.3097 - acc: 0.8690\n",
      "Epoch 12: val_loss did not improve from 0.31008\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.3077 - acc: 0.8705 - val_loss: 0.3403 - val_acc: 0.8495\n",
      "Epoch 13/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.3150 - acc: 0.8609\n",
      "Epoch 13: val_loss improved from 0.31008 to 0.29961, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.3137 - acc: 0.8614 - val_loss: 0.2996 - val_acc: 0.8674\n",
      "Epoch 14/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.3030 - acc: 0.8736\n",
      "Epoch 14: val_loss improved from 0.29961 to 0.28533, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.3018 - acc: 0.8736 - val_loss: 0.2853 - val_acc: 0.8739\n",
      "Epoch 15/160\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.2806 - acc: 0.8852\n",
      "Epoch 15: val_loss did not improve from 0.28533\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2806 - acc: 0.8852 - val_loss: 0.4124 - val_acc: 0.8169\n",
      "Epoch 16/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2804 - acc: 0.8870\n",
      "Epoch 16: val_loss improved from 0.28533 to 0.26332, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2803 - acc: 0.8873 - val_loss: 0.2633 - val_acc: 0.8845\n",
      "Epoch 17/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.2758 - acc: 0.8917\n",
      "Epoch 17: val_loss did not improve from 0.26332\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2758 - acc: 0.8921 - val_loss: 0.3239 - val_acc: 0.8771\n",
      "Epoch 18/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2756 - acc: 0.8846\n",
      "Epoch 18: val_loss did not improve from 0.26332\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2760 - acc: 0.8852 - val_loss: 0.3070 - val_acc: 0.8755\n",
      "Epoch 19/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.2683 - acc: 0.8978\n",
      "Epoch 19: val_loss did not improve from 0.26332\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.2667 - acc: 0.8981 - val_loss: 0.2828 - val_acc: 0.8910\n",
      "Epoch 20/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.2592 - acc: 0.8978\n",
      "Epoch 20: val_loss improved from 0.26332 to 0.24880, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 21ms/step - loss: 0.2589 - acc: 0.8977 - val_loss: 0.2488 - val_acc: 0.9040\n",
      "Epoch 21/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2484 - acc: 0.9040\n",
      "Epoch 21: val_loss did not improve from 0.24880\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2514 - acc: 0.9026 - val_loss: 0.2888 - val_acc: 0.8828\n",
      "Epoch 22/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2561 - acc: 0.8938\n",
      "Epoch 22: val_loss did not improve from 0.24880\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2556 - acc: 0.8942 - val_loss: 0.3292 - val_acc: 0.8812\n",
      "Epoch 23/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2620 - acc: 0.9022\n",
      "Epoch 23: val_loss did not improve from 0.24880\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2621 - acc: 0.9019 - val_loss: 0.3184 - val_acc: 0.8910\n",
      "Epoch 24/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.2583 - acc: 0.8971\n",
      "Epoch 24: val_loss improved from 0.24880 to 0.24622, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2578 - acc: 0.8977 - val_loss: 0.2462 - val_acc: 0.9105\n",
      "Epoch 25/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2345 - acc: 0.9110\n",
      "Epoch 25: val_loss improved from 0.24622 to 0.23365, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2357 - acc: 0.9106 - val_loss: 0.2336 - val_acc: 0.9040\n",
      "Epoch 26/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2371 - acc: 0.9103\n",
      "Epoch 26: val_loss improved from 0.23365 to 0.22958, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2367 - acc: 0.9106 - val_loss: 0.2296 - val_acc: 0.9097\n",
      "Epoch 27/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2600 - acc: 0.8980\n",
      "Epoch 27: val_loss did not improve from 0.22958\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2597 - acc: 0.8988 - val_loss: 0.2330 - val_acc: 0.9129\n",
      "Epoch 28/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2285 - acc: 0.9118\n",
      "Epoch 28: val_loss did not improve from 0.22958\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2314 - acc: 0.9106 - val_loss: 0.2335 - val_acc: 0.9097\n",
      "Epoch 29/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.2461 - acc: 0.9073\n",
      "Epoch 29: val_loss did not improve from 0.22958\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2479 - acc: 0.9072 - val_loss: 0.2362 - val_acc: 0.9097\n",
      "Epoch 30/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2162 - acc: 0.9121\n",
      "Epoch 30: val_loss did not improve from 0.22958\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2146 - acc: 0.9127 - val_loss: 0.2317 - val_acc: 0.9081\n",
      "Epoch 31/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.2236 - acc: 0.9223\n",
      "Epoch 31: val_loss did not improve from 0.22958\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2230 - acc: 0.9225 - val_loss: 0.2578 - val_acc: 0.8942\n",
      "Epoch 32/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2233 - acc: 0.9128\n",
      "Epoch 32: val_loss improved from 0.22958 to 0.19825, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2244 - acc: 0.9127 - val_loss: 0.1983 - val_acc: 0.9317\n",
      "Epoch 33/160\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.2236 - acc: 0.9152\n",
      "Epoch 33: val_loss did not improve from 0.19825\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2236 - acc: 0.9152 - val_loss: 0.2209 - val_acc: 0.9129\n",
      "Epoch 34/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2080 - acc: 0.9216\n",
      "Epoch 34: val_loss did not improve from 0.19825\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2070 - acc: 0.9218 - val_loss: 0.1987 - val_acc: 0.9251\n",
      "Epoch 35/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2187 - acc: 0.9209\n",
      "Epoch 35: val_loss did not improve from 0.19825\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2176 - acc: 0.9211 - val_loss: 0.2141 - val_acc: 0.9105\n",
      "Epoch 36/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2195 - acc: 0.9146\n",
      "Epoch 36: val_loss did not improve from 0.19825\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2190 - acc: 0.9152 - val_loss: 0.2220 - val_acc: 0.9154\n",
      "Epoch 37/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2057 - acc: 0.9269\n",
      "Epoch 37: val_loss improved from 0.19825 to 0.19698, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2080 - acc: 0.9257 - val_loss: 0.1970 - val_acc: 0.9317\n",
      "Epoch 38/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2002 - acc: 0.9234\n",
      "Epoch 38: val_loss improved from 0.19698 to 0.19516, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2011 - acc: 0.9229 - val_loss: 0.1952 - val_acc: 0.9292\n",
      "Epoch 39/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.2060 - acc: 0.9191\n",
      "Epoch 39: val_loss did not improve from 0.19516\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2050 - acc: 0.9197 - val_loss: 0.1959 - val_acc: 0.9317\n",
      "Epoch 40/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1991 - acc: 0.9216\n",
      "Epoch 40: val_loss did not improve from 0.19516\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1991 - acc: 0.9218 - val_loss: 0.2258 - val_acc: 0.9178\n",
      "Epoch 41/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.2038 - acc: 0.9187\n",
      "Epoch 41: val_loss improved from 0.19516 to 0.18860, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2037 - acc: 0.9187 - val_loss: 0.1886 - val_acc: 0.9284\n",
      "Epoch 42/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2010 - acc: 0.9259\n",
      "Epoch 42: val_loss improved from 0.18860 to 0.18559, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2013 - acc: 0.9250 - val_loss: 0.1856 - val_acc: 0.9308\n",
      "Epoch 43/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2011 - acc: 0.9245\n",
      "Epoch 43: val_loss did not improve from 0.18559\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2020 - acc: 0.9239 - val_loss: 0.1860 - val_acc: 0.9284\n",
      "Epoch 44/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1922 - acc: 0.9301\n",
      "Epoch 44: val_loss did not improve from 0.18559\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1950 - acc: 0.9288 - val_loss: 0.2534 - val_acc: 0.8950\n",
      "Epoch 45/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2019 - acc: 0.9273\n",
      "Epoch 45: val_loss did not improve from 0.18559\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2022 - acc: 0.9274 - val_loss: 0.2071 - val_acc: 0.9219\n",
      "Epoch 46/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2020 - acc: 0.9248\n",
      "Epoch 46: val_loss did not improve from 0.18559\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2023 - acc: 0.9253 - val_loss: 0.2047 - val_acc: 0.9325\n",
      "Epoch 47/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1934 - acc: 0.9255\n",
      "Epoch 47: val_loss did not improve from 0.18559\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1934 - acc: 0.9253 - val_loss: 0.2615 - val_acc: 0.9081\n",
      "Epoch 48/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1935 - acc: 0.9280\n",
      "Epoch 48: val_loss did not improve from 0.18559\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1926 - acc: 0.9281 - val_loss: 0.1999 - val_acc: 0.9211\n",
      "Epoch 49/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1935 - acc: 0.9259\n",
      "Epoch 49: val_loss did not improve from 0.18559\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1935 - acc: 0.9260 - val_loss: 0.2262 - val_acc: 0.9081\n",
      "Epoch 50/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2217 - acc: 0.9188\n",
      "Epoch 50: val_loss did not improve from 0.18559\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2218 - acc: 0.9180 - val_loss: 0.2097 - val_acc: 0.9129\n",
      "Epoch 51/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.1995 - acc: 0.9286\n",
      "Epoch 51: val_loss did not improve from 0.18559\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1994 - acc: 0.9284 - val_loss: 0.2290 - val_acc: 0.9129\n",
      "Epoch 52/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.2015 - acc: 0.9226\n",
      "Epoch 52: val_loss did not improve from 0.18559\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2004 - acc: 0.9229 - val_loss: 0.2255 - val_acc: 0.9154\n",
      "Epoch 53/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.1949 - acc: 0.9279\n",
      "Epoch 53: val_loss did not improve from 0.18559\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1943 - acc: 0.9277 - val_loss: 0.2184 - val_acc: 0.9194\n",
      "Epoch 54/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.2083 - acc: 0.9230\n",
      "Epoch 54: val_loss did not improve from 0.18559\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.2098 - acc: 0.9229 - val_loss: 0.1953 - val_acc: 0.9284\n",
      "Epoch 55/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.1968 - acc: 0.9276\n",
      "Epoch 55: val_loss did not improve from 0.18559\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1959 - acc: 0.9277 - val_loss: 0.2137 - val_acc: 0.9162\n",
      "Epoch 56/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1755 - acc: 0.9351\n",
      "Epoch 56: val_loss improved from 0.18559 to 0.17135, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1761 - acc: 0.9351 - val_loss: 0.1714 - val_acc: 0.9317\n",
      "Epoch 57/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.1914 - acc: 0.9301\n",
      "Epoch 57: val_loss did not improve from 0.17135\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1919 - acc: 0.9298 - val_loss: 0.1910 - val_acc: 0.9341\n",
      "Epoch 58/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.1895 - acc: 0.9262\n",
      "Epoch 58: val_loss did not improve from 0.17135\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1922 - acc: 0.9246 - val_loss: 0.2093 - val_acc: 0.9260\n",
      "Epoch 59/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1813 - acc: 0.9333\n",
      "Epoch 59: val_loss improved from 0.17135 to 0.16581, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1796 - acc: 0.9340 - val_loss: 0.1658 - val_acc: 0.9455\n",
      "Epoch 60/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1796 - acc: 0.9315\n",
      "Epoch 60: val_loss did not improve from 0.16581\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1808 - acc: 0.9309 - val_loss: 0.1880 - val_acc: 0.9276\n",
      "Epoch 61/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1574 - acc: 0.9418\n",
      "Epoch 61: val_loss did not improve from 0.16581\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1572 - acc: 0.9421 - val_loss: 0.1848 - val_acc: 0.9235\n",
      "Epoch 62/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.1756 - acc: 0.9311\n",
      "Epoch 62: val_loss did not improve from 0.16581\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1762 - acc: 0.9316 - val_loss: 0.2025 - val_acc: 0.9276\n",
      "Epoch 63/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1759 - acc: 0.9333\n",
      "Epoch 63: val_loss did not improve from 0.16581\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1776 - acc: 0.9330 - val_loss: 0.2024 - val_acc: 0.9203\n",
      "Epoch 64/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1739 - acc: 0.9351\n",
      "Epoch 64: val_loss did not improve from 0.16581\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1736 - acc: 0.9351 - val_loss: 0.1663 - val_acc: 0.9308\n",
      "Epoch 65/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1777 - acc: 0.9361\n",
      "Epoch 65: val_loss did not improve from 0.16581\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1778 - acc: 0.9358 - val_loss: 0.1995 - val_acc: 0.9235\n",
      "Epoch 66/160\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.1592 - acc: 0.9421\n",
      "Epoch 66: val_loss did not improve from 0.16581\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1592 - acc: 0.9421 - val_loss: 0.1969 - val_acc: 0.9284\n",
      "Epoch 67/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1704 - acc: 0.9365\n",
      "Epoch 67: val_loss did not improve from 0.16581\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1701 - acc: 0.9365 - val_loss: 0.1802 - val_acc: 0.9325\n",
      "Epoch 68/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1680 - acc: 0.9411\n",
      "Epoch 68: val_loss did not improve from 0.16581\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1678 - acc: 0.9410 - val_loss: 0.1843 - val_acc: 0.9251\n",
      "Epoch 69/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.1665 - acc: 0.9350\n",
      "Epoch 69: val_loss did not improve from 0.16581\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1665 - acc: 0.9347 - val_loss: 0.1933 - val_acc: 0.9235\n",
      "Epoch 70/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1669 - acc: 0.9421\n",
      "Epoch 70: val_loss improved from 0.16581 to 0.16138, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1662 - acc: 0.9421 - val_loss: 0.1614 - val_acc: 0.9414\n",
      "Epoch 71/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1625 - acc: 0.9442\n",
      "Epoch 71: val_loss did not improve from 0.16138\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1635 - acc: 0.9442 - val_loss: 0.1824 - val_acc: 0.9284\n",
      "Epoch 72/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1740 - acc: 0.9358\n",
      "Epoch 72: val_loss improved from 0.16138 to 0.16134, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1731 - acc: 0.9361 - val_loss: 0.1613 - val_acc: 0.9422\n",
      "Epoch 73/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1504 - acc: 0.9453\n",
      "Epoch 73: val_loss improved from 0.16134 to 0.14974, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1496 - acc: 0.9455 - val_loss: 0.1497 - val_acc: 0.9430\n",
      "Epoch 74/160\n",
      "180/180 [==============================] - ETA: 0s - loss: 0.1495 - acc: 0.9473\n",
      "Epoch 74: val_loss did not improve from 0.14974\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1495 - acc: 0.9473 - val_loss: 0.1829 - val_acc: 0.9243\n",
      "Epoch 75/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1490 - acc: 0.9435\n",
      "Epoch 75: val_loss improved from 0.14974 to 0.13982, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_scratch_modified_weights.h5\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1513 - acc: 0.9428 - val_loss: 0.1398 - val_acc: 0.9471\n",
      "Epoch 76/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1885 - acc: 0.9351\n",
      "Epoch 76: val_loss did not improve from 0.13982\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1881 - acc: 0.9354 - val_loss: 0.2688 - val_acc: 0.9113\n",
      "Epoch 77/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1578 - acc: 0.9418\n",
      "Epoch 77: val_loss did not improve from 0.13982\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1578 - acc: 0.9417 - val_loss: 0.1713 - val_acc: 0.9471\n",
      "Epoch 78/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.1529 - acc: 0.9450\n",
      "Epoch 78: val_loss did not improve from 0.13982\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1550 - acc: 0.9438 - val_loss: 0.1511 - val_acc: 0.9487\n",
      "Epoch 79/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.1499 - acc: 0.9468\n",
      "Epoch 79: val_loss did not improve from 0.13982\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1488 - acc: 0.9469 - val_loss: 0.1721 - val_acc: 0.9406\n",
      "Epoch 80/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1573 - acc: 0.9414\n",
      "Epoch 80: val_loss did not improve from 0.13982\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1582 - acc: 0.9410 - val_loss: 0.1418 - val_acc: 0.9487\n",
      "Epoch 81/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.1744 - acc: 0.9308\n",
      "Epoch 81: val_loss did not improve from 0.13982\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1749 - acc: 0.9302 - val_loss: 0.1816 - val_acc: 0.9325\n",
      "Epoch 82/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1461 - acc: 0.9513\n",
      "Epoch 82: val_loss did not improve from 0.13982\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1463 - acc: 0.9511 - val_loss: 0.1649 - val_acc: 0.9414\n",
      "Epoch 83/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.1634 - acc: 0.9411\n",
      "Epoch 83: val_loss did not improve from 0.13982\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1624 - acc: 0.9414 - val_loss: 0.1656 - val_acc: 0.9455\n",
      "Epoch 84/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1605 - acc: 0.9396\n",
      "Epoch 84: val_loss did not improve from 0.13982\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1611 - acc: 0.9393 - val_loss: 0.1744 - val_acc: 0.9390\n",
      "Epoch 85/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1452 - acc: 0.9495\n",
      "Epoch 85: val_loss did not improve from 0.13982\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1456 - acc: 0.9494 - val_loss: 0.1518 - val_acc: 0.9398\n",
      "Epoch 86/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1600 - acc: 0.9425\n",
      "Epoch 86: val_loss did not improve from 0.13982\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1592 - acc: 0.9431 - val_loss: 0.1624 - val_acc: 0.9455\n",
      "Epoch 87/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1416 - acc: 0.9478\n",
      "Epoch 87: val_loss did not improve from 0.13982\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1403 - acc: 0.9483 - val_loss: 0.1582 - val_acc: 0.9365\n",
      "Epoch 88/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.1487 - acc: 0.9506\n",
      "Epoch 88: val_loss did not improve from 0.13982\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1487 - acc: 0.9504 - val_loss: 0.2166 - val_acc: 0.9105\n",
      "Epoch 89/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.1386 - acc: 0.9507\n",
      "Epoch 89: val_loss did not improve from 0.13982\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.1375 - acc: 0.9511 - val_loss: 0.1448 - val_acc: 0.9536\n",
      "Epoch 89: early stopping\n",
      "Epoch 1/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.7031 - acc: 0.5249\n",
      "Epoch 1: val_loss improved from inf to 0.68250, saving model to /mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/notebooks/weigths/model_vgg16_weights.h5\n",
      "180/180 [==============================] - 6s 21ms/step - loss: 0.7028 - acc: 0.5253 - val_loss: 0.6825 - val_acc: 0.5899\n",
      "Epoch 2/160\n",
      "178/180 [============================>.] - ETA: 0s - loss: 0.7001 - acc: 0.5372\n",
      "Epoch 2: val_loss did not improve from 0.68250\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.7003 - acc: 0.5351 - val_loss: 0.7538 - val_acc: 0.4101\n",
      "Epoch 3/160\n",
      "177/180 [============================>.] - ETA: 0s - loss: 0.6518 - acc: 0.6329\n",
      "Epoch 3: val_loss did not improve from 0.68250\n",
      "180/180 [==============================] - 4s 20ms/step - loss: 0.6524 - acc: 0.6314 - val_loss: 0.8273 - val_acc: 0.4101\n",
      "Epoch 4/160\n",
      "  1/180 [..............................] - ETA: 6s - loss: 0.6431 - acc: 0.6250"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:85\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/tfm_tf/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/tfm_tf/lib/python3.11/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/envs/tfm_tf/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/tfm_tf/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/envs/tfm_tf/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/envs/tfm_tf/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tfm_tf/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/envs/tfm_tf/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/tfm_tf/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/tfm_tf/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
      "File \u001b[0;32m~/anaconda3/envs/tfm_tf/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for test in tests:\n",
    "\n",
    "    # Descripcion de esta prueba\n",
    "    desc_test = test[0]\n",
    "    hiperparametros = test[1]\n",
    "    \n",
    "    # Inicializamos para dar nombre a todos los outputs que se escriban\n",
    "    hora_exec = datetime.now().strftime('%Y-%m-%d_%H-%M')\n",
    "    \n",
    "    # Creamos el nombre del directorio para guardar los modelos finales\n",
    "    path_prueba_actual = f\"../notebooks/best_models/{desc_test}_{hora_exec}/\"\n",
    "    os.makedirs(path_prueba_actual, exist_ok=True)\n",
    "    \n",
    "    # Inicializamos las variables dónde almacenaremos los resultados de cada uno de los modelos generados\n",
    "    df_alexnet = pd.DataFrame()\n",
    "    df_scratch_modified = pd.DataFrame()\n",
    "    df_vgg = pd.DataFrame()\n",
    "    df_mobile_net = pd.DataFrame()\n",
    "    \n",
    "    #Eliminamos los csvs generados en ejecuciones anteriores\n",
    "    dl_utils.limpia_directorios(\"aux_path\")\n",
    "    \n",
    "    # Recorremos la lista de configuraciones distinta generada anteriormente\n",
    "    for id_hiperparams,hiperparams in enumerate(hiperparametros):\n",
    "        for semilla in range(0,2):  \n",
    "    \n",
    "            # Limpiamos la carpeta donde se guardan los modelos\n",
    "            dl_utils.limpia_directorios(\"weigths\")\n",
    "    \n",
    "            # Definimos hiperparámetros asociados a la ejecución actual\n",
    "            batch_size = hiperparams[\"batch_size\"]\n",
    "            epochs = hiperparams[\"epochs\"]\n",
    "         \n",
    "            # Dividimos el conjunto de imágenes en train y test\n",
    "            seed = np.random.randint(0, 2000,1)[0]\n",
    "            hiperparams[\"semilla\"] = seed\n",
    "            keras.utils.set_random_seed(int(seed))\n",
    "            x_train, x_test, y_train, y_test = train_test_split(x_norm, y, test_size=hiperparams[\"test_size\"], random_state=123)\n",
    "    \n",
    "            # Generamos los datagen de imágenes, empleamos las mismas imágenes en todos los modelos\n",
    "            datagen.fit(x_train)\n",
    "            train_generator = datagen.flow(x_train, y_train, batch_size=batch_size, shuffle=False)\n",
    "            test_generator = datagen.flow(x_test, y_test, batch_size=batch_size, shuffle=False)\n",
    "            \n",
    "            # Definimos y compilamos los modelos\n",
    "            alexnet = models.alexnet_model(input_shape)\n",
    "            scratch_modified_model = models.scratch_modified_model(input_shape)\n",
    "            vgg16 = models.vgg_16_model(input_shape)\n",
    "            mobile_net = models.mobilenet_model(input_shape)\n",
    "\n",
    "            # Modelo por defecto empleando los mismos parámetros que el original.\n",
    "            start_time = time.time()\n",
    "            alexnet_results = alexnet.fit(\n",
    "                train_generator,\n",
    "                batch_size=batch_size,\n",
    "                epochs=epochs,\n",
    "                validation_data=test_generator,\n",
    "                verbose=1,\n",
    "                shuffle=True,\n",
    "                callbacks=dl_utils.define_callbacks(\"model_alexnet_\",hiperparams),\n",
    "                class_weight=hiperparams[\"class_weight\"],\n",
    "            )\n",
    "            training_time_alexnet = time.time() - start_time\n",
    "    \n",
    "            # Modelo from scratch modificado, ampliación del modelo original\n",
    "            start_time = time.time()\n",
    "            scratch_modified_model_results = scratch_modified_model.fit(\n",
    "                train_generator,\n",
    "                batch_size=batch_size,\n",
    "                epochs=epochs,\n",
    "                validation_data=test_generator,\n",
    "                verbose=1,\n",
    "                shuffle=True,\n",
    "                callbacks=dl_utils.define_callbacks(\"model_scratch_modified_\",hiperparams),\n",
    "                class_weight=hiperparams[\"class_weight\"],\n",
    "            )\n",
    "            training_time_scratch_modified_model = time.time() - start_time\n",
    "    \n",
    "            # Fine-tunning con los pesos del modelo VGG16\n",
    "            start_time = time.time()\n",
    "            vgg16_results = vgg16.fit(\n",
    "                train_generator,\n",
    "                batch_size=batch_size,\n",
    "                epochs=epochs,\n",
    "                validation_data=test_generator,\n",
    "                verbose=1,\n",
    "                shuffle=True,\n",
    "                callbacks=dl_utils.define_callbacks(\"model_vgg16_\",hiperparams),\n",
    "                class_weight=hiperparams[\"class_weight\"],\n",
    "            )\n",
    "            training_time_vgg16 = time.time() - start_time\n",
    "    \n",
    "            # Fine-tunning con los pesos del modelo MobileNet\n",
    "            start_time = time.time()\n",
    "            mobile_net_results = mobile_net.fit(\n",
    "                train_generator,\n",
    "                batch_size=batch_size,\n",
    "                epochs=epochs,\n",
    "                validation_data=test_generator,\n",
    "                verbose=1,\n",
    "                shuffle=True,\n",
    "                callbacks=dl_utils.define_callbacks(\"model_mobilenet_\",hiperparams),\n",
    "                class_weight=hiperparams[\"class_weight\"],\n",
    "            )\n",
    "            training_time_mobile_net = time.time() - start_time\n",
    "        \n",
    "            # Evaluamos el modelo y lo comparamos con el mejor almacenado.  \n",
    "            hora_actual = datetime.now().strftime('%Y-%m-%d_%H-%M')\n",
    "            df_alexnet,           save_df_alexnet           = dl_utils.get_df_best_model(alexnet,test_partition_x,test_partition_y,f\"alexnet_{desc_test}_\",df_alexnet,hora_actual)\n",
    "            df_scratch_modified, save_df_scratch_modified = dl_utils.get_df_best_model(scratch_modified_model,test_partition_x,test_partition_y,f\"scratch_modified_model_{desc_test}_\",df_scratch_modified,hora_actual)\n",
    "            df_vgg,              save_df_vgg              = dl_utils.get_df_best_model(vgg16,test_partition_x,test_partition_y,f\"vgg16_{desc_test}_\",df_vgg,hora_actual)\n",
    "            df_mobile_net,       save_df_mobile_net       = dl_utils.get_df_best_model(mobile_net,test_partition_x,test_partition_y,f\"mobile_net_{desc_test}_\",df_mobile_net,hora_actual)\n",
    "        \n",
    "            # Si el modelo actual es mejor que el almacenado, guardamos su información.      \n",
    "            if save_df_alexnet:\n",
    "                best_alexnet_model = alexnet\n",
    "                best_alexnet_results = alexnet_results.history\n",
    "                best_alexnet_hiperparams = [hiperparams,\n",
    "                                            id_hiperparams+1,\n",
    "                                            f'resultados_evaluacion_alexnet_{desc_test}_{hora_actual}.csv',\n",
    "                                            training_time_alexnet,\n",
    "                                            len(alexnet_results.epoch)]\n",
    "\n",
    "            if save_df_scratch_modified:\n",
    "                best_scratch_modified_model = scratch_modified_model\n",
    "                best_scratch_modified_model_results = scratch_modified_model_results.history\n",
    "                best_scratch_modified_hiperparams = [hiperparams,\n",
    "                                                     id_hiperparams+1,\n",
    "                                                     f'resultados_evaluacion_scratch_modified_model_{desc_test}_{hora_actual}.csv',\n",
    "                                                     training_time_scratch_modified_model,\n",
    "                                                     len(scratch_modified_model_results.epoch)]\n",
    "        \n",
    "            if save_df_vgg:\n",
    "                best_vgg_model = vgg16\n",
    "                best_vgg_model_results = vgg16_results.history\n",
    "                best_vgg_hiperparams =[hiperparams,\n",
    "                                       id_hiperparams+1,\n",
    "                                       f'resultados_evaluacion_vgg16_{desc_test}_{hora_actual}.csv',\n",
    "                                       training_time_vgg16,\n",
    "                                       len(vgg16_results.epoch)]\n",
    "        \n",
    "            if save_df_mobile_net:\n",
    "                best_mobile_net_model = mobile_net\n",
    "                best_mobile_net_model_results = mobile_net_results.history\n",
    "                best_mobile_net_hiperparams = [hiperparams,\n",
    "                                               id_hiperparams+1,\n",
    "                                               f'resultados_evaluacion_mobile_net_{desc_test}_{hora_actual}.csv',\n",
    "                                               training_time_mobile_net,\n",
    "                                               len(mobile_net_results.epoch)]\n",
    "\n",
    "            # Limpiamos variables auxiliares\n",
    "            del alexnet\n",
    "            del scratch_modified_model\n",
    "            del vgg16\n",
    "            del mobile_net\n",
    "            del alexnet_results\n",
    "            del scratch_modified_model_results\n",
    "            del vgg16_results\n",
    "            del mobile_net_results\n",
    "            del train_generator\n",
    "            del test_generator\n",
    "            K.clear_session()\n",
    "            gc.collect()        \n",
    "    \n",
    "    # Guardamos el mejor modelo\n",
    "    dl_utils.save_models(best_alexnet_model,\n",
    "                         best_alexnet_results,\n",
    "                         best_alexnet_hiperparams,\n",
    "                         hora_exec,\n",
    "                         f'alexnet_{desc_test}',\n",
    "                         path_prueba_actual)\n",
    "    dl_utils.save_models(best_scratch_modified_model,\n",
    "                         best_scratch_modified_model_results,\n",
    "                         best_scratch_modified_hiperparams,\n",
    "                         hora_exec,\n",
    "                         f'scratch_modified_model_{desc_test}',\n",
    "                         path_prueba_actual)\n",
    "    dl_utils.save_models(best_vgg_model,\n",
    "                         best_vgg_model_results,\n",
    "                         best_vgg_hiperparams,\n",
    "                         hora_exec,\n",
    "                         f'vgg16_{desc_test}',\n",
    "                         path_prueba_actual)\n",
    "    dl_utils.save_models(best_mobile_net_model,\n",
    "                         best_mobile_net_model_results,\n",
    "                         best_mobile_net_hiperparams,\n",
    "                         hora_exec,\n",
    "                         f'mobile_net_{desc_test}',\n",
    "                         path_prueba_actual)\n",
    "    \n",
    "    # Movemos los archivos asociados a los resultados\n",
    "    dl_utils.obtener_tablas_resultado(path_prueba_actual,[best_alexnet_hiperparams[2],\n",
    "                                                         best_scratch_modified_hiperparams[2],\n",
    "                                                         best_vgg_hiperparams[2],\n",
    "                                                         best_mobile_net_hiperparams[2]])\n",
    "    # Limpiamos variables auxiliares\n",
    "    del best_alexnet_model\n",
    "    del best_alexnet_results\n",
    "    del best_alexnet_hiperparams\n",
    "    del best_scratch_modified_model\n",
    "    del best_scratch_modified_model_results\n",
    "    del best_scratch_modified_hiperparams\n",
    "    del best_vgg_model\n",
    "    del best_vgg_model_results\n",
    "    del best_vgg_hiperparams\n",
    "    del best_mobile_net_model\n",
    "    del best_mobile_net_model_results\n",
    "    del best_mobile_net_hiperparams\n",
    "    K.clear_session()\n",
    "    gc.collect() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "bec97cbb607180795486aa419a93884fe3d0b55501c3e5098d64200fe61c3ffb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
