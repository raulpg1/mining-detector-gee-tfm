{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Notebook for model training\n",
    "\n",
    "### Training Flow\n",
    "\n",
    "Load Training Data:\n",
    "- Load set of input data and label files\n",
    "- Prefilter positive set only to rule out heavily-masked patches\n",
    "- Create train/test set\n",
    "- Define augmentation parameters\n",
    "\n",
    "Train Model:\n",
    "- Define model architecture\n",
    "- Compile model\n",
    "- Train and evaluate model\n",
    "- Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-27 09:12:23.576329: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-27 09:12:23.597827: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-27 09:12:23.597849: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-27 09:12:23.598499: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-27 09:12:23.602165: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-27 09:12:24.118356: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "from datetime import datetime\n",
    "import time\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import io\n",
    "from contextlib import redirect_stdout\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, Conv2D\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "parent_dir = os.path.split(os.getcwd())[0]\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.insert(0, parent_dir)\n",
    "\n",
    "from scripts import dl_utils\n",
    "from scripts import viz_tools\n",
    "from scripts import models\n",
    "\n",
    "import gc\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# export TF_GPU_ALLOCATOR=cuda_malloc_async\n",
    "os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1204afbb6b941a196f6f1808cae6712",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4549 samples loaded\n",
      "1891 positive samples\n",
      "2658 negative samples\n"
     ]
    }
   ],
   "source": [
    "resolution = 48\n",
    "\n",
    "data_files = [\n",
    "    \"amazonas_2020_thresh_0.5_2_negatives_2019-01-01_2020-01-01_patch_arrays.pkl\",\n",
    "    \"amazonas_2020_thresh_0.8_sumbsample_3_positives_2019-01-01_2020-01-01_patch_arrays.pkl\",\n",
    "    \"MinesPos2018-2020Sentinel_points_2019-01-01_2020-01-01_patch_arrays.pkl\",\n",
    "    \"bolivar_2020_thresh_0.8_sumbsample_5_positives_2019-01-01_2020-01-01_patch_arrays.pkl\",\n",
    "    \"full_amazon_v9_negatives_2019-01-01_2020-01-01_patch_arrays.pkl\",\n",
    "    \"v2.4_amazon_positives_2019-01-01_2020-01-01_patch_arrays.pkl\",\n",
    "    \"v2.6_amazon_thresh_0.8_negatives_2019-01-01_2020-01-01_patch_arrays.pkl\",\n",
    "    \"v2.0_bolivar_negatives_2019-01-01_2020-01-01_patch_arrays.pkl\",\n",
    "    \"riverbank_negatives_2019-01-01_2020-01-01_patch_arrays.pkl\",\n",
    "    \"bolivar_2020_thresh_0.8_1_negatives_2019-01-01_2020-01-01_patch_arrays.pkl\",\n",
    "    \"v2.1.1_bolivar_negatives_2019-01-01_2020-01-01_patch_arrays.pkl\",\n",
    "    \"v2.1_bolivar_positives_2019-01-01_2020-01-01_patch_arrays.pkl\",\n",
    "    \"v2.4_amazonas_negatives_2019-01-01_2020-01-01_patch_arrays.pkl\",\n",
    "    \"v2.4_amazon_negatives_2019-01-01_2020-01-01_patch_arrays.pkl\",\n",
    "    \"v2.6_amazon_negatives_2019-01-01_2020-01-01_patch_arrays.pkl\",\n",
    "    \"v2.6_amazon_negatives_v2_2019-01-01_2020-01-01_patch_arrays.pkl\",\n",
    "    \"v3.1_2023_negatives_2023-01-01_2024-01-01_patch_arrays.pkl\",\n",
    "    \"amazon_all_48px_v3.1_2023_positives_0.999_2023-01-01_2024-01-01_patch_arrays.pkl\",\n",
    "    \"v3.2_2023_negatives_2023-01-01_2024-01-01_patch_arrays.pkl\",\n",
    "    \"v3.3_2023_positives_2023-01-01_2024-01-01_patch_arrays.pkl\",\n",
    "    \"v3.4_2023_negatives_2023-01-01_2024-01-01_patch_arrays.pkl\",\n",
    "    \"v3.5_2023_negatives_2023-01-01_2024-01-01_patch_arrays.pkl\",\n",
    "    \"v3.6_2023_positives_2023-01-01_2024-01-01_patch_arrays.pkl\"\n",
    "    \n",
    "    ]\n",
    "\n",
    "label_files = [\n",
    "    \"amazonas_2020_thresh_0.5_2_negatives_2019-01-01_2020-01-01_patch_array_labels.pkl\",\n",
    "    \"amazonas_2020_thresh_0.8_sumbsample_3_positives_2019-01-01_2020-01-01_patch_array_labels.pkl\",\n",
    "    \"MinesPos2018-2020Sentinel_points_2019-01-01_2020-01-01_patch_array_labels.pkl\",\n",
    "    \"bolivar_2020_thresh_0.8_sumbsample_5_positives_2019-01-01_2020-01-01_patch_array_labels.pkl\",\n",
    "    \"full_amazon_v9_negatives_2019-01-01_2020-01-01_patch_array_labels.pkl\",\n",
    "    \"v2.4_amazon_positives_2019-01-01_2020-01-01_patch_array_labels.pkl\",\n",
    "    \"v2.6_amazon_thresh_0.8_negatives_2019-01-01_2020-01-01_patch_array_labels.pkl\",\n",
    "    \"v2.0_bolivar_negatives_2019-01-01_2020-01-01_patch_array_labels.pkl\",\n",
    "    \"riverbank_negatives_2019-01-01_2020-01-01_patch_array_labels.pkl\",\n",
    "    \"bolivar_2020_thresh_0.8_1_negatives_2019-01-01_2020-01-01_patch_array_labels.pkl\",\n",
    "    \"v2.1.1_bolivar_negatives_2019-01-01_2020-01-01_patch_array_labels.pkl\",\n",
    "    \"v2.1_bolivar_positives_2019-01-01_2020-01-01_patch_array_labels.pkl\",\n",
    "    \"v2.4_amazonas_negatives_2019-01-01_2020-01-01_patch_array_labels.pkl\",\n",
    "    \"v2.4_amazon_negatives_2019-01-01_2020-01-01_patch_array_labels.pkl\",\n",
    "    \"v2.6_amazon_negatives_2019-01-01_2020-01-01_patch_array_labels.pkl\",\n",
    "    \"v2.6_amazon_negatives_v2_2019-01-01_2020-01-01_patch_array_labels.pkl\",\n",
    "    \"v3.1_2023_negatives_2023-01-01_2024-01-01_patch_array_labels.pkl\",\n",
    "    \"amazon_all_48px_v3.1_2023_positives_0.999_2023-01-01_2024-01-01_patch_array_labels.pkl\",\n",
    "    \"v3.2_2023_negatives_2023-01-01_2024-01-01_patch_array_labels.pkl\",\n",
    "    \"v3.3_2023_positives_2023-01-01_2024-01-01_patch_array_labels.pkl\",\n",
    "    \"v3.4_2023_negatives_2023-01-01_2024-01-01_patch_array_labels.pkl\",\n",
    "    \"v3.5_2023_negatives_2023-01-01_2024-01-01_patch_array_labels.pkl\",\n",
    "    \"v3.6_2023_positives_2023-01-01_2024-01-01_patch_array_labels.pkl\"\n",
    "    \n",
    "    \n",
    "]\n",
    "\n",
    "patches = []\n",
    "labels = []\n",
    "\n",
    "data_dir = os.path.join('..', 'data', 'training_data', f\"{resolution}_px\")\n",
    "\n",
    "for data, label in tqdm(zip(data_files, label_files), total=len(data_files)):\n",
    "    with open(os.path.join(data_dir, data), 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "        for elem in data:\n",
    "            #patch = dl_utils.pad_patch(elem, resolution)\n",
    "            patches.append(elem)\n",
    "    with open(os.path.join(data_dir, label), 'rb') as f:\n",
    "        label = pickle.load(f)\n",
    "        labels = np.concatenate((labels, label))\n",
    "\n",
    "patches = np.array(patches)\n",
    "negative_patches = patches[labels == 0]\n",
    "positive_patches = patches[labels == 1]\n",
    "\n",
    "print(len(patches), \"samples loaded\")\n",
    "print(sum(labels == 1), \"positive samples\")\n",
    "print(sum(labels == 0), \"negative samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 64\n",
    "indices = np.random.randint(0, len(patches), num_samples)\n",
    "# viz_tools.plot_image_grid(patches[indices], labels=[int(label) for label in labels[indices]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_black(data, mask_limit=0.1, return_rejects=False):\n",
    "    masked_fraction = np.array([np.sum(np.mean(patch, axis=-1) < 10) / np.size(np.mean(patch, axis=-1)) for patch in data])\n",
    "    filtered_data = data[masked_fraction < mask_limit]\n",
    "    print(f\"{len(filtered_data) / len(data) :.1%} of data below brightness limit\")\n",
    "    if return_rejects:\n",
    "        rejected_data = data[masked_fraction >= mask_limit]\n",
    "        return filtered_data, rejected_data\n",
    "    else:\n",
    "        return filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.9% of data below brightness limit\n"
     ]
    }
   ],
   "source": [
    "# Filter positive pixels that are masked beyond a threshold. Don't want to give positive examples of cloud-masked patches\n",
    "filtered_positives, positive_rejects = filter_black(positive_patches, mask_limit = 0.1, return_rejects=True)\n",
    "if len(positive_rejects) > 0:\n",
    "    num_samples = 16**2\n",
    "    if len(positive_rejects) < num_samples:\n",
    "        num_samples = len(positive_rejects)\n",
    "    indices = np.random.randint(0, len(positive_rejects), num_samples)\n",
    "    # viz_tools.plot_numpy_grid(positive_rejects[indices,:,:,3:0:-1] / 3000)\n",
    "    # plt.title(\"Positive Masked Rejects\")\n",
    "    # plt.show()\n",
    "\n",
    "num_samples = 25 ** 2\n",
    "indices = np.random.randint(0, len(filtered_positives), num_samples)\n",
    "# fig = viz_tools.plot_numpy_grid(filtered_positives[indices,:,:,3:0:-1] / 3000)\n",
    "# plt.title('Positive Filtered Samples')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0% of data below brightness limit\n"
     ]
    }
   ],
   "source": [
    "filtered_negatives, negative_rejects = filter_black(negative_patches, mask_limit = 0.6, return_rejects=True)\n",
    "if len(negative_rejects) > 0:\n",
    "    num_samples = 16**2\n",
    "    if len(positive_rejects) < num_samples:\n",
    "        num_samples = len(positive_rejects)\n",
    "    indices = np.random.randint(0, len(negative_rejects), num_samples)\n",
    "    # viz_tools.plot_numpy_grid(negative_rejects[indices,:,:,3:0:-1] / 3000)\n",
    "    # plt.title(\"Negative Mask Rejects\")\n",
    "    # plt.show()\n",
    "\n",
    "num_samples = 25 ** 2\n",
    "indices = np.random.randint(0, len(filtered_negatives), num_samples)\n",
    "# fig = viz_tools.plot_numpy_grid(filtered_negatives[indices,:,:,3:0:-1] / 3000)\n",
    "# plt.title('Negative Filtered Samples')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for RGBIR, x = normalize(np.copy(images[:,:,:,[1,2,3,8]]))\n",
    "x = np.concatenate((filtered_negatives, filtered_positives))\n",
    "y = np.concatenate((np.zeros(len(filtered_negatives)), np.ones(len(filtered_positives))))\n",
    "x, y = shuffle(x, y, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentation_parameters = {\n",
    "    'featurewise_center': False,\n",
    "    'rotation_range': 360,\n",
    "    'width_shift_range': [0.9, 1.1],\n",
    "    'height_shift_range': [0.9, 1.1],\n",
    "    'shear_range': 10,\n",
    "    'zoom_range': [0.9, 1.1],\n",
    "    'vertical_flip': True,\n",
    "    'horizontal_flip': True,\n",
    "    # Fill options: \"constant\", \"nearest\", \"reflect\" or \"wrap\"\n",
    "    'fill_mode': 'reflect'\n",
    "}\n",
    "\n",
    "datagen = ImageDataGenerator(**augmentation_parameters)\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(12,12), facecolor=(1,1,1), dpi=150)\n",
    "# aug_img, aug_labels = datagen.flow(x, y, batch_size=64).next()\n",
    "# viz_tools.plot_image_grid(aug_img, labels=[int(l) for l in aug_labels], norm=True);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_norm = np.clip(np.array(x.astype(\"float32\") / 10000), 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partimos el 10% del dataset total para test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = len(y)\n",
    "test_partition = int(dataset_size*0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de clases positivas en el dataset de training es de 1705, número de clases negativas 2389\n"
     ]
    }
   ],
   "source": [
    "num_positive_samples_train = sum(y[test_partition:]==1)\n",
    "num_negative_samples_train = sum(y[test_partition:]==0)\n",
    "\n",
    "print(f\"Número de clases positivas en el dataset de training es de {num_positive_samples_train}, número de clases negativas {num_negative_samples_train}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminamos estos samples del dataset de validacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_partition_x = x_norm[:test_partition]\n",
    "test_partition_y = y[:test_partition]\n",
    "\n",
    "x_norm = x_norm[test_partition:]\n",
    "y = y[test_partition:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Hiperparámetros ejecuciones originales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Preparación de hiperparámetros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Balanceo de clases para el entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "El número de valores para la clase no mina es de 0.8568438677270824 y para la clase mina 1.2005865102639297\n",
      "\n",
      "Ponemos peso a cada clase para tenerlo en cuenta en el entrenamiento {0: 0.8568438677270824, 1: 1.2005865102639297}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "import numpy as np\n",
    "\n",
    "# Suponiendo que 'y_train' es un array de las etiquetas de entrenamiento\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y),\n",
    "    y=y\n",
    ")\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "\n",
    "print(f\"\\nEl número de valores para la clase no mina es de {class_weight_dict[0]} y para la clase mina {class_weight_dict[1]}\")\n",
    "print(f\"\\nPonemos peso a cada clase para tenerlo en cuenta en el entrenamiento {class_weight_dict}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Clases no balanceadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a weighted loss\n",
    "class_weight = {0: 1, 1: 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diccionario con todos los hiperparámetros editables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Hiperparámetros para pruebas: early stopping = 7 y LR descendiente = 4 con test size del 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################################################\n",
    "########################################## CLASES BALANCEADAS ###########################################\n",
    "#########################################################################################################\n",
    "                                                                                                        #\n",
    "# reduce_lr en callbacks                                                                                #                            \n",
    "hiper_params_test1_20 = {\"class_weight\" : class_weight_dict, #\n",
    "                      \"batch_size\" : 32,                                                                #\n",
    "                      \"epochs\" : 160,                                                                   #\n",
    "                      \"define_callbacks\" : [\"reduce_lr\", \"early_stopping\"],         #\n",
    "                      \"patience_early_stopping\" : 7,                                                   #\n",
    "                      \"patience_reduce_lr\" : 4,                                                         #\n",
    "                      \"test_size\" : 0.2                                                                 #\n",
    "                     }                                                                                  #\n",
    "                                                                                                        #\n",
    "# SIN reduce_lr en callbacks                                                                            #\n",
    "hiper_params_test2_20 = {\"class_weight\" : class_weight_dict, #\n",
    "                      \"batch_size\" : 32,                                                                #\n",
    "                      \"epochs\" : 160,                                                                   #\n",
    "                      \"define_callbacks\" : [\"early_stopping\"],                      #\n",
    "                      \"patience_early_stopping\" : 7,                                                   #\n",
    "                      \"test_size\" : 0.2                                                                 #\n",
    "                     }                                                                                  #\n",
    "#########################################################################################################\n",
    "\n",
    "#########################################################################################################\n",
    "####################################### CLASES NO BALANCEADAS ###########################################\n",
    "#########################################################################################################\n",
    "                                                                                                        #\n",
    "# Reduce_lr en callbacks                                                                                #\n",
    "hiper_params_test3_20 = {\"class_weight\" : {0: 1, 1: 1},                                                 #\n",
    "                      \"batch_size\" : 32,                                                                #\n",
    "                      \"epochs\" : 160,                                                                   #\n",
    "                      \"define_callbacks\" : [\"reduce_lr\", \"early_stopping\"],         #\n",
    "                      \"patience_early_stopping\" : 7,                                                   #\n",
    "                      \"patience_reduce_lr\" : 4,                                                         #\n",
    "                      \"test_size\" : 0.2                                                                 #\n",
    "                     }                                                                                  #\n",
    "#SIN Reduce_lr en callbacks                                                                             #\n",
    "hiper_params_test4_20 = {\"class_weight\" : {0: 1, 1: 1},                                                 #\n",
    "                      \"batch_size\" : 32,                                                                #\n",
    "                      \"epochs\" : 160,                                                                   #\n",
    "                      \"define_callbacks\" : [\"early_stopping\"],                      #\n",
    "                      \"patience_early_stopping\" : 7,                                                   #\n",
    "                      \"test_size\" : 0.2                                                                 #\n",
    "                     }                                                                                  #\n",
    "#########################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Hiperparámetros para pruebas: early stopping = 7 y LR descendiente = 4 con test size del 30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################################################\n",
    "###################################### CLASES BALANCEADAS ###############################################\n",
    "#########################################################################################################\n",
    "                                                                                                        #\n",
    "# Reduce_lr en callbacks                                                                                #\n",
    "hiper_params_test1_30 = {\"class_weight\" : class_weight_dict, #\n",
    "                      \"batch_size\" : 16,                                                                #\n",
    "                      \"epochs\" : 160,                                                                   #\n",
    "                      \"define_callbacks\" : [\"reduce_lr\", \"early_stopping\"],         #\n",
    "                      \"patience_early_stopping\" : 7,                                                   #\n",
    "                      \"patience_reduce_lr\" : 4,                                                         #\n",
    "                      \"test_size\" : 0.3                                                                 #\n",
    "                     }                                                                                  #         \n",
    "                                                                                                        #\n",
    "# SIN reduce_lr en callbacks                                                                            #   \n",
    "hiper_params_test2_30 = {\"class_weight\" : class_weight_dict, #\n",
    "                      \"batch_size\" : 16,                                                                #\n",
    "                      \"epochs\" : 160,                                                                   #\n",
    "                      \"define_callbacks\" : [\"early_stopping\"],                      #\n",
    "                      \"patience_early_stopping\" : 7,                                                   #\n",
    "                      \"test_size\" : 0.3                                                                 #\n",
    "                     }                                                                                  #\n",
    "#########################################################################################################\n",
    "\n",
    "######################################################################################################\n",
    "###################################### CLASES NO BALANCEADAS #########################################\n",
    "######################################################################################################\n",
    "                                                                                                     #\n",
    "# Reduce_lr en callbacks                                                                             #  \n",
    "hiper_params_test3_30 = {\"class_weight\" : {0: 1, 1: 1},                                              #\n",
    "                      \"batch_size\" : 16,                                                             #\n",
    "                      \"epochs\" : 160,                                                                #\n",
    "                      \"define_callbacks\" : [\"reduce_lr\", \"early_stopping\"],      #\n",
    "                      \"patience_early_stopping\" : 7,                                                #\n",
    "                      \"patience_reduce_lr\" : 4,                                                      #\n",
    "                      \"test_size\" : 0.3                                                              #\n",
    "                     }                                                                               #\n",
    "                                                                                                     #\n",
    "# SIN reduce_lr en callbacks                                                                         #      \n",
    "hiper_params_test4_30 = {\"class_weight\" : {0: 1, 1: 1},                                              #\n",
    "                      \"batch_size\" : 16,                                                             #\n",
    "                      \"epochs\" : 160,                                                                #\n",
    "                      \"define_callbacks\" : [\"early_stopping\"],                   #\n",
    "                      \"patience_early_stopping\" : 7,                                                #\n",
    "                      \"test_size\" : 0.3                                                              #\n",
    "                     }                                                                               #\n",
    "######################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Hiperparámetros para pruebas: aumento patience en early stopping = 14 y LR descendiente = 8, split de 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################################################\n",
    "########################################## CLASES BALANCEADAS ###########################################\n",
    "#########################################################################################################\n",
    "                                                                                                        #\n",
    "# reduce_lr en callbacks                                                                                #                            \n",
    "hiper_params_test5_20 = {\"class_weight\" : class_weight_dict, #\n",
    "                      \"batch_size\" : 32,                                                                #\n",
    "                      \"epochs\" : 160,                                                                   #\n",
    "                      \"define_callbacks\" : [\"reduce_lr\", \"early_stopping\"],         #\n",
    "                      \"patience_early_stopping\" : 14,                                                   #\n",
    "                      \"patience_reduce_lr\" : 8,                                                        #\n",
    "                      \"test_size\" : 0.2                                                                 #\n",
    "                     }                                                                                  #\n",
    "                                                                                                        #\n",
    "# SIN reduce_lr en callbacks                                                                            #\n",
    "hiper_params_test6_20 = {\"class_weight\" : class_weight_dict, #\n",
    "                      \"batch_size\" : 32,                                                                #\n",
    "                      \"epochs\" : 160,                                                                   #\n",
    "                      \"define_callbacks\" : [\"early_stopping\"],                      #\n",
    "                      \"patience_early_stopping\" : 14,                                                   #\n",
    "                      \"test_size\" : 0.2                                                                 #\n",
    "                     }                                                                                  #\n",
    "#########################################################################################################\n",
    "\n",
    "#########################################################################################################\n",
    "####################################### CLASES NO BALANCEADAS ###########################################\n",
    "#########################################################################################################\n",
    "                                                                                                        #\n",
    "# Reduce_lr en callbacks                                                                                #\n",
    "hiper_params_test7_20 = {\"class_weight\" : {0: 1, 1: 1},                                                 #\n",
    "                      \"batch_size\" : 32,                                                                #\n",
    "                      \"epochs\" : 160,                                                                   #\n",
    "                      \"define_callbacks\" : [\"reduce_lr\", \"early_stopping\"],         #\n",
    "                      \"patience_early_stopping\" : 14,                                                   #\n",
    "                      \"patience_reduce_lr\" : 8,                                                        #\n",
    "                      \"test_size\" : 0.2                                                                 #\n",
    "                     }                                                                                  #\n",
    "#SIN Reduce_lr en callbacks                                                                             #\n",
    "hiper_params_test8_20 = {\"class_weight\" : {0: 1, 1: 1},                                                 #\n",
    "                      \"batch_size\" : 32,                                                                #\n",
    "                      \"epochs\" : 160,                                                                   #\n",
    "                      \"define_callbacks\" : [\"early_stopping\"],                      #\n",
    "                      \"patience_early_stopping\" : 14,                                                   #\n",
    "                      \"test_size\" : 0.2                                                                 #\n",
    "                     }                                                                                  #\n",
    "#########################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Hiperparámetros para pruebas: aumento patience en early stopping = 14 y LR descendiente = 8, split de 30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################################################\n",
    "###################################### CLASES BALANCEADAS ###############################################\n",
    "#########################################################################################################\n",
    "                                                                                                        #\n",
    "# Reduce_lr en callbacks                                                                                #\n",
    "hiper_params_test5_30 = {\"class_weight\" : class_weight_dict, #\n",
    "                      \"batch_size\" : 16,                                                                #\n",
    "                      \"epochs\" : 160,                                                                   #\n",
    "                      \"define_callbacks\" : [\"reduce_lr\", \"early_stopping\"],         #\n",
    "                      \"patience_early_stopping\" : 14,                                                   #\n",
    "                      \"patience_reduce_lr\" : 8,                                                        #\n",
    "                      \"test_size\" : 0.3                                                                 #\n",
    "                     }                                                                                  #         \n",
    "                                                                                                        #\n",
    "# SIN reduce_lr en callbacks                                                                            #   \n",
    "hiper_params_test6_30 = {\"class_weight\" : class_weight_dict, #\n",
    "                      \"batch_size\" : 16,                                                                #\n",
    "                      \"epochs\" : 160,                                                                   #\n",
    "                      \"define_callbacks\" : [\"early_stopping\"],                      #\n",
    "                      \"patience_early_stopping\" : 14,                                                   #\n",
    "                      \"test_size\" : 0.3                                                                 #\n",
    "                     }                                                                                  #\n",
    "#########################################################################################################\n",
    "\n",
    "######################################################################################################\n",
    "###################################### CLASES NO BALANCEADAS #########################################\n",
    "######################################################################################################\n",
    "                                                                                                     #\n",
    "# Reduce_lr en callbacks                                                                             #  \n",
    "hiper_params_test7_30 = {\"class_weight\" : {0: 1, 1: 1},                                              #\n",
    "                      \"batch_size\" : 16,                                                             #\n",
    "                      \"epochs\" : 160,                                                                #\n",
    "                      \"define_callbacks\" : [\"reduce_lr\", \"early_stopping\"],      #\n",
    "                      \"patience_early_stopping\" : 14,                                                #\n",
    "                      \"patience_reduce_lr\" : 8,                                                     #\n",
    "                      \"test_size\" : 0.3                                                              #\n",
    "                     }                                                                               #\n",
    "                                                                                                     #\n",
    "# SIN reduce_lr en callbacks                                                                         #      \n",
    "hiper_params_test8_30 = {\"class_weight\" : {0: 1, 1: 1},                                              #\n",
    "                      \"batch_size\" : 16,                                                             #\n",
    "                      \"epochs\" : 160,                                                                #\n",
    "                      \"define_callbacks\" : [\"early_stopping\"],                   #\n",
    "                      \"patience_early_stopping\" : 14,                                                #\n",
    "                      \"test_size\" : 0.3                                                              #\n",
    "                     }                                                                               #\n",
    "######################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Hiperparámetros para pruebas: aumento patience en early stopping = 20 y LR descendiente = 10, split de 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################################################\n",
    "########################################## CLASES BALANCEADAS ###########################################\n",
    "#########################################################################################################\n",
    "                                                                                                        #\n",
    "# reduce_lr en callbacks                                                                                #                            \n",
    "hiper_params_test9_20 = {\"class_weight\" : class_weight_dict, #\n",
    "                      \"batch_size\" : 32,                                                                #\n",
    "                      \"epochs\" : 160,                                                                   #\n",
    "                      \"define_callbacks\" : [\"reduce_lr\", \"early_stopping\"],         #\n",
    "                      \"patience_early_stopping\" : 20,                                                   #\n",
    "                      \"patience_reduce_lr\" : 10,                                                        #\n",
    "                      \"test_size\" : 0.2                                                                 #\n",
    "                     }                                                                                  #\n",
    "                                                                                                        #\n",
    "# SIN reduce_lr en callbacks                                                                            #\n",
    "hiper_params_test10_20 = {\"class_weight\" : class_weight_dict, #\n",
    "                      \"batch_size\" : 32,                                                                #\n",
    "                      \"epochs\" : 160,                                                                   #\n",
    "                      \"define_callbacks\" : [\"early_stopping\"],                      #\n",
    "                      \"patience_early_stopping\" : 20,                                                   #\n",
    "                      \"test_size\" : 0.2                                                                 #\n",
    "                     }                                                                                  #\n",
    "#########################################################################################################\n",
    "\n",
    "#########################################################################################################\n",
    "####################################### CLASES NO BALANCEADAS ###########################################\n",
    "#########################################################################################################\n",
    "                                                                                                        #\n",
    "# Reduce_lr en callbacks                                                                                #\n",
    "hiper_params_test11_20 = {\"class_weight\" : {0: 1, 1: 1},                                                 #\n",
    "                      \"batch_size\" : 32,                                                                #\n",
    "                      \"epochs\" : 160,                                                                   #\n",
    "                      \"define_callbacks\" : [\"reduce_lr\", \"early_stopping\"],         #\n",
    "                      \"patience_early_stopping\" : 20,                                                   #\n",
    "                      \"patience_reduce_lr\" : 10,                                                        #\n",
    "                      \"test_size\" : 0.2                                                                 #\n",
    "                     }                                                                                  #\n",
    "#SIN Reduce_lr en callbacks                                                                             #\n",
    "hiper_params_test12_20 = {\"class_weight\" : {0: 1, 1: 1},                                                 #\n",
    "                      \"batch_size\" : 32,                                                                #\n",
    "                      \"epochs\" : 160,                                                                   #\n",
    "                      \"define_callbacks\" : [\"early_stopping\"],                      #\n",
    "                      \"patience_early_stopping\" : 14,                                                   #\n",
    "                      \"test_size\" : 0.2                                                                 #\n",
    "                     }                                                                                  #\n",
    "#########################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Hiperparámetros para pruebas: aumento patience en early stopping = 20 y LR descendiente = 10, split de 30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################################################################################\n",
    "###################################### CLASES BALANCEADAS ###############################################\n",
    "#########################################################################################################\n",
    "                                                                                                        #\n",
    "# Reduce_lr en callbacks                                                                                #\n",
    "hiper_params_test9_30 = {\"class_weight\" : class_weight_dict, #\n",
    "                      \"batch_size\" : 16,                                                                #\n",
    "                      \"epochs\" : 160,                                                                   #\n",
    "                      \"define_callbacks\" : [\"reduce_lr\", \"early_stopping\"],         #\n",
    "                      \"patience_early_stopping\" : 20,                                                   #\n",
    "                      \"patience_reduce_lr\" : 10,                                                        #\n",
    "                      \"test_size\" : 0.3                                                                 #\n",
    "                     }                                                                                  #         \n",
    "                                                                                                        #\n",
    "# SIN reduce_lr en callbacks                                                                            #   \n",
    "hiper_params_test10_30 = {\"class_weight\" : class_weight_dict, #\n",
    "                      \"batch_size\" : 16,                                                                #\n",
    "                      \"epochs\" : 160,                                                                   #\n",
    "                      \"define_callbacks\" : [\"early_stopping\"],                      #\n",
    "                      \"patience_early_stopping\" : 14,                                                   #\n",
    "                      \"test_size\" : 0.3                                                                 #\n",
    "                     }                                                                                  #\n",
    "#########################################################################################################\n",
    "\n",
    "######################################################################################################\n",
    "###################################### CLASES NO BALANCEADAS #########################################\n",
    "######################################################################################################\n",
    "                                                                                                     #\n",
    "# Reduce_lr en callbacks                                                                             #  \n",
    "hiper_params_test11_30 = {\"class_weight\" : {0: 1, 1: 1},                                              #\n",
    "                      \"batch_size\" : 16,                                                             #\n",
    "                      \"epochs\" : 160,                                                                #\n",
    "                      \"define_callbacks\" : [\"reduce_lr\", \"early_stopping\"],      #\n",
    "                      \"patience_early_stopping\" : 20,                                                #\n",
    "                      \"patience_reduce_lr\" : 10,                                                     #\n",
    "                      \"test_size\" : 0.3                                                              #\n",
    "                     }                                                                               #\n",
    "                                                                                                     #\n",
    "# SIN reduce_lr en callbacks                                                                         #      \n",
    "hiper_params_test12_30 = {\"class_weight\" : {0: 1, 1: 1},                                              #\n",
    "                      \"batch_size\" : 16,                                                             #\n",
    "                      \"epochs\" : 160,                                                                #\n",
    "                      \"define_callbacks\" : [\"early_stopping\"],                   #\n",
    "                      \"patience_early_stopping\" : 20,                                                #\n",
    "                      \"test_size\" : 0.3                                                              #\n",
    "                     }                                                                               #\n",
    "######################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generamos una lista con todos los hiperparámetros definidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiperparametros_20 = [hiper_params_test1_20, hiper_params_test2_20, hiper_params_test3_20, hiper_params_test4_20]\n",
    "hiperparametros_30 = [hiper_params_test1_30, hiper_params_test2_30, hiper_params_test3_30, hiper_params_test4_30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiperparametros_20_modified = [hiper_params_test5_20, hiper_params_test6_20, hiper_params_test7_20, hiper_params_test8_20]\n",
    "hiperparametros_30_modified = [hiper_params_test5_30, hiper_params_test6_30, hiper_params_test7_30, hiper_params_test8_30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiperparametros_20_max_patience = [hiper_params_test9_20, hiper_params_test10_20, hiper_params_test11_20, hiper_params_test12_20]\n",
    "hiperparametros_30_max_patience = [hiper_params_test9_30, hiper_params_test10_30, hiper_params_test11_30, hiper_params_test12_30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento de las diferentes arquitecturas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de modelos construidos = 6 pruebas * 4 hiperparámetros/prueba * 2 semillas distintas * 4 arquitecturas distintas = 192 modelos construidos. 48 modelos por cada arquitectura.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total de modelos construidos = 6 pruebas * 4 hiperparámetros/prueba * 2 semillas distintas * 4 arquitecturas distintas = {6*4*2*4} modelos construidos. 48 modelos por cada arquitectura.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tests = [\n",
    "    # [\"split_20\",hiperparametros_20],\n",
    "    # [\"split_30\",hiperparametros_30],\n",
    "    # [\"split_20_increase_patience\",hiperparametros_20_modified],\n",
    "    # [\"split_30_increase_patience\",hiperparametros_30_modified],\n",
    "    # [\"split_20_max_patience\",hiperparametros_20_max_patience],\n",
    "    [\"split_30_max_patience\",hiperparametros_30_max_patience]\n",
    "]\n",
    "\n",
    "input_shape = (48,48,12)\n",
    "\n",
    "modelos = [\n",
    "    # \"alexnet\",\n",
    "    # \"scratch\",\n",
    "    \"vgg\",\n",
    "    # \"mobilenet\"\n",
    "]\n",
    "\n",
    "first_top_model_layer = \"Flatten\"\n",
    "# first_top_model_layer = \"GlobalMaxPooling\"\n",
    "# first_top_model_layer = \"GlobalAveragePooling\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raulpg/anaconda3/envs/tfm_tf/lib/python3.11/site-packages/keras/src/legacy/preprocessing/image.py:1495: UserWarning: Expected input to be images (as Numpy array) following the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3 or 4 channels on axis 3. However, it was passed an array with shape (2865, 48, 48, 12) (12 channels).\n",
      "  warnings.warn(\n",
      "/home/raulpg/anaconda3/envs/tfm_tf/lib/python3.11/site-packages/keras/src/legacy/preprocessing/image.py:619: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3, or 4 channels on axis 3. However, it was passed an array with shape (2865, 48, 48, 12) (12 channels).\n",
      "  warnings.warn(\n",
      "/home/raulpg/anaconda3/envs/tfm_tf/lib/python3.11/site-packages/keras/src/legacy/preprocessing/image.py:619: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3, or 4 channels on axis 3. However, it was passed an array with shape (1229, 48, 48, 12) (12 channels).\n",
      "  warnings.warn(\n",
      "2024-09-27 09:12:29.109418: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-09-27 09:12:29.124847: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-09-27 09:12:29.124885: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-09-27 09:12:29.127331: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-09-27 09:12:29.127366: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-09-27 09:12:29.127382: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-09-27 09:12:29.212821: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-09-27 09:12:29.212866: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-09-27 09:12:29.212870: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-09-27 09:12:29.212882: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:236] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-09-27 09:12:29.213004: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-09-27 09:12:29.213027: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5381 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Ti, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2024-09-27 09:12:29.329121: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raulpg/anaconda3/envs/tfm_tf/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n",
      "2024-09-27 09:12:31.547397: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f33f4006e30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-09-27 09:12:31.547425: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4060 Ti, Compute Capability 8.9\n",
      "2024-09-27 09:12:31.575627: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-09-27 09:12:31.801402: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 13/180\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - acc: 0.4952 - loss: 0.7062"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1727421155.963929   66957 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "W0000 00:00:1727421155.975864   66957 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 45ms/step - acc: 0.5749 - loss: 0.6634 - val_acc: 0.7323 - val_loss: 0.5438 - learning_rate: 3.0000e-04\n",
      "Epoch 2/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.7789 - loss: 0.4829 - val_acc: 0.8226 - val_loss: 0.4243 - learning_rate: 3.0000e-04\n",
      "Epoch 3/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.8256 - loss: 0.4152 - val_acc: 0.8657 - val_loss: 0.3202 - learning_rate: 3.0000e-04\n",
      "Epoch 4/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.8473 - loss: 0.3726 - val_acc: 0.8714 - val_loss: 0.2841 - learning_rate: 3.0000e-04\n",
      "Epoch 5/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.7582 - loss: 0.4817 - val_acc: 0.8503 - val_loss: 0.3488 - learning_rate: 3.0000e-04\n",
      "Epoch 6/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.8630 - loss: 0.3278 - val_acc: 0.8771 - val_loss: 0.3012 - learning_rate: 3.0000e-04\n",
      "Epoch 7/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.8687 - loss: 0.3305 - val_acc: 0.8812 - val_loss: 0.2847 - learning_rate: 3.0000e-04\n",
      "Epoch 8/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.8887 - loss: 0.2744 - val_acc: 0.8698 - val_loss: 0.3107 - learning_rate: 3.0000e-04\n",
      "Epoch 9/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.8838 - loss: 0.2891 - val_acc: 0.8869 - val_loss: 0.2771 - learning_rate: 3.0000e-04\n",
      "Epoch 10/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.8874 - loss: 0.2815 - val_acc: 0.9015 - val_loss: 0.2411 - learning_rate: 3.0000e-04\n",
      "Epoch 11/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.8991 - loss: 0.2448 - val_acc: 0.8885 - val_loss: 0.2817 - learning_rate: 3.0000e-04\n",
      "Epoch 12/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9161 - loss: 0.2163 - val_acc: 0.9162 - val_loss: 0.2296 - learning_rate: 3.0000e-04\n",
      "Epoch 13/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9200 - loss: 0.2176 - val_acc: 0.9162 - val_loss: 0.2155 - learning_rate: 3.0000e-04\n",
      "Epoch 14/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9312 - loss: 0.2057 - val_acc: 0.8723 - val_loss: 0.3301 - learning_rate: 3.0000e-04\n",
      "Epoch 15/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9158 - loss: 0.2244 - val_acc: 0.9243 - val_loss: 0.2031 - learning_rate: 3.0000e-04\n",
      "Epoch 16/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9337 - loss: 0.1992 - val_acc: 0.9105 - val_loss: 0.2168 - learning_rate: 3.0000e-04\n",
      "Epoch 17/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9162 - loss: 0.2214 - val_acc: 0.9227 - val_loss: 0.1907 - learning_rate: 3.0000e-04\n",
      "Epoch 18/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9257 - loss: 0.1930 - val_acc: 0.9162 - val_loss: 0.2502 - learning_rate: 3.0000e-04\n",
      "Epoch 19/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9228 - loss: 0.2106 - val_acc: 0.9146 - val_loss: 0.2170 - learning_rate: 3.0000e-04\n",
      "Epoch 20/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9276 - loss: 0.2016 - val_acc: 0.9300 - val_loss: 0.1730 - learning_rate: 3.0000e-04\n",
      "Epoch 21/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9418 - loss: 0.1562 - val_acc: 0.9227 - val_loss: 0.1878 - learning_rate: 3.0000e-04\n",
      "Epoch 22/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9330 - loss: 0.1888 - val_acc: 0.8893 - val_loss: 0.2501 - learning_rate: 3.0000e-04\n",
      "Epoch 23/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9172 - loss: 0.2219 - val_acc: 0.9186 - val_loss: 0.2056 - learning_rate: 3.0000e-04\n",
      "Epoch 24/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - acc: 0.9375 - loss: 0.1689 - val_acc: 0.9300 - val_loss: 0.1906 - learning_rate: 3.0000e-04\n",
      "Epoch 25/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9364 - loss: 0.1628 - val_acc: 0.9146 - val_loss: 0.2142 - learning_rate: 3.0000e-04\n",
      "Epoch 26/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - acc: 0.9396 - loss: 0.1635 - val_acc: 0.9227 - val_loss: 0.1920 - learning_rate: 3.0000e-04\n",
      "Epoch 27/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - acc: 0.9388 - loss: 0.1735 - val_acc: 0.9349 - val_loss: 0.1694 - learning_rate: 3.0000e-04\n",
      "Epoch 28/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - acc: 0.9445 - loss: 0.1510 - val_acc: 0.9390 - val_loss: 0.1568 - learning_rate: 3.0000e-04\n",
      "Epoch 29/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - acc: 0.9610 - loss: 0.1275 - val_acc: 0.9325 - val_loss: 0.1560 - learning_rate: 3.0000e-04\n",
      "Epoch 30/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - acc: 0.9455 - loss: 0.1461 - val_acc: 0.9284 - val_loss: 0.2027 - learning_rate: 3.0000e-04\n",
      "Epoch 31/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9491 - loss: 0.1364 - val_acc: 0.9081 - val_loss: 0.2285 - learning_rate: 3.0000e-04\n",
      "Epoch 32/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9504 - loss: 0.1314 - val_acc: 0.9300 - val_loss: 0.1949 - learning_rate: 3.0000e-04\n",
      "Epoch 33/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9469 - loss: 0.1400 - val_acc: 0.9170 - val_loss: 0.2047 - learning_rate: 3.0000e-04\n",
      "Epoch 34/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9447 - loss: 0.1465 - val_acc: 0.9390 - val_loss: 0.1659 - learning_rate: 3.0000e-04\n",
      "Epoch 35/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9546 - loss: 0.1235 - val_acc: 0.9308 - val_loss: 0.2324 - learning_rate: 3.0000e-04\n",
      "Epoch 36/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9469 - loss: 0.1466 - val_acc: 0.9365 - val_loss: 0.1682 - learning_rate: 3.0000e-04\n",
      "Epoch 37/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9593 - loss: 0.1195 - val_acc: 0.9365 - val_loss: 0.1798 - learning_rate: 3.0000e-04\n",
      "Epoch 38/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9467 - loss: 0.1332 - val_acc: 0.9357 - val_loss: 0.1767 - learning_rate: 3.0000e-04\n",
      "Epoch 39/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9543 - loss: 0.1325 - val_acc: 0.9357 - val_loss: 0.1505 - learning_rate: 3.0000e-04\n",
      "Epoch 40/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9506 - loss: 0.1365 - val_acc: 0.9203 - val_loss: 0.2213 - learning_rate: 3.0000e-04\n",
      "Epoch 41/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9487 - loss: 0.1474 - val_acc: 0.9154 - val_loss: 0.1966 - learning_rate: 3.0000e-04\n",
      "Epoch 42/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9487 - loss: 0.1309 - val_acc: 0.9406 - val_loss: 0.1679 - learning_rate: 3.0000e-04\n",
      "Epoch 43/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9543 - loss: 0.1315 - val_acc: 0.9422 - val_loss: 0.1629 - learning_rate: 3.0000e-04\n",
      "Epoch 44/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9608 - loss: 0.1035 - val_acc: 0.9284 - val_loss: 0.1764 - learning_rate: 3.0000e-04\n",
      "Epoch 45/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9519 - loss: 0.1204 - val_acc: 0.9422 - val_loss: 0.1373 - learning_rate: 3.0000e-04\n",
      "Epoch 46/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9688 - loss: 0.0936 - val_acc: 0.9422 - val_loss: 0.1836 - learning_rate: 3.0000e-04\n",
      "Epoch 47/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9463 - loss: 0.1554 - val_acc: 0.9414 - val_loss: 0.1726 - learning_rate: 3.0000e-04\n",
      "Epoch 48/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9444 - loss: 0.1387 - val_acc: 0.9333 - val_loss: 0.1692 - learning_rate: 3.0000e-04\n",
      "Epoch 49/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9453 - loss: 0.1454 - val_acc: 0.9260 - val_loss: 0.1780 - learning_rate: 3.0000e-04\n",
      "Epoch 50/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9632 - loss: 0.1016 - val_acc: 0.9463 - val_loss: 0.1696 - learning_rate: 3.0000e-04\n",
      "Epoch 51/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9544 - loss: 0.1197 - val_acc: 0.9512 - val_loss: 0.1267 - learning_rate: 3.0000e-04\n",
      "Epoch 52/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9572 - loss: 0.1053 - val_acc: 0.9333 - val_loss: 0.1676 - learning_rate: 3.0000e-04\n",
      "Epoch 53/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9650 - loss: 0.0926 - val_acc: 0.9325 - val_loss: 0.1651 - learning_rate: 3.0000e-04\n",
      "Epoch 54/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9586 - loss: 0.1153 - val_acc: 0.9447 - val_loss: 0.1384 - learning_rate: 3.0000e-04\n",
      "Epoch 55/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9713 - loss: 0.0847 - val_acc: 0.9447 - val_loss: 0.1513 - learning_rate: 3.0000e-04\n",
      "Epoch 56/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9592 - loss: 0.1162 - val_acc: 0.9243 - val_loss: 0.1986 - learning_rate: 3.0000e-04\n",
      "Epoch 57/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9448 - loss: 0.1415 - val_acc: 0.9365 - val_loss: 0.1681 - learning_rate: 3.0000e-04\n",
      "Epoch 58/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9646 - loss: 0.1116 - val_acc: 0.9325 - val_loss: 0.1839 - learning_rate: 3.0000e-04\n",
      "Epoch 59/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9568 - loss: 0.1265 - val_acc: 0.9325 - val_loss: 0.1815 - learning_rate: 3.0000e-04\n",
      "Epoch 60/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9617 - loss: 0.1091 - val_acc: 0.9382 - val_loss: 0.1737 - learning_rate: 3.0000e-04\n",
      "Epoch 61/160\n",
      "\u001b[1m179/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - acc: 0.9707 - loss: 0.0877\n",
      "Epoch 61: ReduceLROnPlateau reducing learning rate to 0.00022500001068692654.\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9707 - loss: 0.0878 - val_acc: 0.9317 - val_loss: 0.1783 - learning_rate: 3.0000e-04\n",
      "Epoch 62/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9737 - loss: 0.0846 - val_acc: 0.9382 - val_loss: 0.1495 - learning_rate: 2.2500e-04\n",
      "Epoch 63/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9755 - loss: 0.0721 - val_acc: 0.9512 - val_loss: 0.1635 - learning_rate: 2.2500e-04\n",
      "Epoch 64/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9707 - loss: 0.0750 - val_acc: 0.9471 - val_loss: 0.1356 - learning_rate: 2.2500e-04\n",
      "Epoch 65/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9679 - loss: 0.0860 - val_acc: 0.9430 - val_loss: 0.1579 - learning_rate: 2.2500e-04\n",
      "Epoch 66/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9726 - loss: 0.0756 - val_acc: 0.9414 - val_loss: 0.1788 - learning_rate: 2.2500e-04\n",
      "Epoch 67/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9727 - loss: 0.0841 - val_acc: 0.9235 - val_loss: 0.1886 - learning_rate: 2.2500e-04\n",
      "Epoch 68/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9710 - loss: 0.0884 - val_acc: 0.9414 - val_loss: 0.1582 - learning_rate: 2.2500e-04\n",
      "Epoch 69/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9721 - loss: 0.0850 - val_acc: 0.9520 - val_loss: 0.1362 - learning_rate: 2.2500e-04\n",
      "Epoch 70/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9645 - loss: 0.0785 - val_acc: 0.9536 - val_loss: 0.1441 - learning_rate: 2.2500e-04\n",
      "Epoch 71/160\n",
      "\u001b[1m179/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - acc: 0.9761 - loss: 0.0632\n",
      "Epoch 71: ReduceLROnPlateau reducing learning rate to 0.0001687500080151949.\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9761 - loss: 0.0633 - val_acc: 0.9479 - val_loss: 0.1273 - learning_rate: 2.2500e-04\n",
      "Epoch 71: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raulpg/anaconda3/envs/tfm_tf/lib/python3.11/site-packages/keras/src/legacy/preprocessing/image.py:1495: UserWarning: Expected input to be images (as Numpy array) following the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3 or 4 channels on axis 3. However, it was passed an array with shape (2865, 48, 48, 12) (12 channels).\n",
      "  warnings.warn(\n",
      "/home/raulpg/anaconda3/envs/tfm_tf/lib/python3.11/site-packages/keras/src/legacy/preprocessing/image.py:619: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3, or 4 channels on axis 3. However, it was passed an array with shape (2865, 48, 48, 12) (12 channels).\n",
      "  warnings.warn(\n",
      "/home/raulpg/anaconda3/envs/tfm_tf/lib/python3.11/site-packages/keras/src/legacy/preprocessing/image.py:619: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3, or 4 channels on axis 3. However, it was passed an array with shape (1229, 48, 48, 12) (12 channels).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raulpg/anaconda3/envs/tfm_tf/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  5/180\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 37ms/step - acc: 0.4065 - loss: 0.7997"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1727421420.209599   66955 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - acc: 0.5235 - loss: 0.7018 - val_acc: 0.7274 - val_loss: 0.5351 - learning_rate: 3.0000e-04\n",
      "Epoch 2/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.7320 - loss: 0.5341 - val_acc: 0.7819 - val_loss: 0.4663 - learning_rate: 3.0000e-04\n",
      "Epoch 3/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.7853 - loss: 0.4510 - val_acc: 0.8063 - val_loss: 0.3944 - learning_rate: 3.0000e-04\n",
      "Epoch 4/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.8254 - loss: 0.3951 - val_acc: 0.8226 - val_loss: 0.3753 - learning_rate: 3.0000e-04\n",
      "Epoch 5/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.8489 - loss: 0.3721 - val_acc: 0.8186 - val_loss: 0.3883 - learning_rate: 3.0000e-04\n",
      "Epoch 6/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.8395 - loss: 0.3679 - val_acc: 0.8454 - val_loss: 0.3428 - learning_rate: 3.0000e-04\n",
      "Epoch 7/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.8622 - loss: 0.3399 - val_acc: 0.8552 - val_loss: 0.3012 - learning_rate: 3.0000e-04\n",
      "Epoch 8/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.8715 - loss: 0.3038 - val_acc: 0.8568 - val_loss: 0.3575 - learning_rate: 3.0000e-04\n",
      "Epoch 9/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.8690 - loss: 0.3192 - val_acc: 0.8324 - val_loss: 0.3364 - learning_rate: 3.0000e-04\n",
      "Epoch 10/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.8757 - loss: 0.2949 - val_acc: 0.8755 - val_loss: 0.2863 - learning_rate: 3.0000e-04\n",
      "Epoch 11/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.8754 - loss: 0.2901 - val_acc: 0.8698 - val_loss: 0.3166 - learning_rate: 3.0000e-04\n",
      "Epoch 12/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.8939 - loss: 0.2645 - val_acc: 0.8771 - val_loss: 0.2616 - learning_rate: 3.0000e-04\n",
      "Epoch 13/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.8941 - loss: 0.2623 - val_acc: 0.8934 - val_loss: 0.2497 - learning_rate: 3.0000e-04\n",
      "Epoch 14/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9029 - loss: 0.2491 - val_acc: 0.8592 - val_loss: 0.3280 - learning_rate: 3.0000e-04\n",
      "Epoch 15/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.8810 - loss: 0.2754 - val_acc: 0.9032 - val_loss: 0.2272 - learning_rate: 3.0000e-04\n",
      "Epoch 16/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.8920 - loss: 0.2578 - val_acc: 0.8861 - val_loss: 0.2521 - learning_rate: 3.0000e-04\n",
      "Epoch 17/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9121 - loss: 0.2359 - val_acc: 0.8983 - val_loss: 0.2414 - learning_rate: 3.0000e-04\n",
      "Epoch 18/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - acc: 0.9045 - loss: 0.2360 - val_acc: 0.9178 - val_loss: 0.2216 - learning_rate: 3.0000e-04\n",
      "Epoch 19/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - acc: 0.9246 - loss: 0.2061 - val_acc: 0.8853 - val_loss: 0.2618 - learning_rate: 3.0000e-04\n",
      "Epoch 20/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9193 - loss: 0.2026 - val_acc: 0.8950 - val_loss: 0.2545 - learning_rate: 3.0000e-04\n",
      "Epoch 21/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - acc: 0.9180 - loss: 0.2048 - val_acc: 0.9081 - val_loss: 0.2315 - learning_rate: 3.0000e-04\n",
      "Epoch 22/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9071 - loss: 0.2463 - val_acc: 0.8218 - val_loss: 0.3683 - learning_rate: 3.0000e-04\n",
      "Epoch 23/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - acc: 0.8512 - loss: 0.3431 - val_acc: 0.8853 - val_loss: 0.2760 - learning_rate: 3.0000e-04\n",
      "Epoch 24/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.8890 - loss: 0.2767 - val_acc: 0.8910 - val_loss: 0.2599 - learning_rate: 3.0000e-04\n",
      "Epoch 25/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9060 - loss: 0.2303 - val_acc: 0.9040 - val_loss: 0.2390 - learning_rate: 3.0000e-04\n",
      "Epoch 26/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9161 - loss: 0.2060 - val_acc: 0.9064 - val_loss: 0.2176 - learning_rate: 3.0000e-04\n",
      "Epoch 27/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9221 - loss: 0.2081 - val_acc: 0.9146 - val_loss: 0.2205 - learning_rate: 3.0000e-04\n",
      "Epoch 28/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9149 - loss: 0.2156 - val_acc: 0.8495 - val_loss: 0.3138 - learning_rate: 3.0000e-04\n",
      "Epoch 29/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9183 - loss: 0.2063 - val_acc: 0.9097 - val_loss: 0.2230 - learning_rate: 3.0000e-04\n",
      "Epoch 30/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9228 - loss: 0.2003 - val_acc: 0.9121 - val_loss: 0.2408 - learning_rate: 3.0000e-04\n",
      "Epoch 31/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9126 - loss: 0.2362 - val_acc: 0.9146 - val_loss: 0.2104 - learning_rate: 3.0000e-04\n",
      "Epoch 32/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9317 - loss: 0.1834 - val_acc: 0.9097 - val_loss: 0.2193 - learning_rate: 3.0000e-04\n",
      "Epoch 33/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9291 - loss: 0.1803 - val_acc: 0.9268 - val_loss: 0.1886 - learning_rate: 3.0000e-04\n",
      "Epoch 34/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9390 - loss: 0.1630 - val_acc: 0.9357 - val_loss: 0.1785 - learning_rate: 3.0000e-04\n",
      "Epoch 35/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9402 - loss: 0.1596 - val_acc: 0.9211 - val_loss: 0.1923 - learning_rate: 3.0000e-04\n",
      "Epoch 36/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9128 - loss: 0.2461 - val_acc: 0.9138 - val_loss: 0.2042 - learning_rate: 3.0000e-04\n",
      "Epoch 37/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9256 - loss: 0.1983 - val_acc: 0.9170 - val_loss: 0.2373 - learning_rate: 3.0000e-04\n",
      "Epoch 38/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9273 - loss: 0.1849 - val_acc: 0.9349 - val_loss: 0.1763 - learning_rate: 3.0000e-04\n",
      "Epoch 39/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9166 - loss: 0.2325 - val_acc: 0.9154 - val_loss: 0.2038 - learning_rate: 3.0000e-04\n",
      "Epoch 40/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9292 - loss: 0.1974 - val_acc: 0.9186 - val_loss: 0.2040 - learning_rate: 3.0000e-04\n",
      "Epoch 41/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9465 - loss: 0.1608 - val_acc: 0.9268 - val_loss: 0.1829 - learning_rate: 3.0000e-04\n",
      "Epoch 42/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9484 - loss: 0.1416 - val_acc: 0.9251 - val_loss: 0.1852 - learning_rate: 3.0000e-04\n",
      "Epoch 43/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9380 - loss: 0.1689 - val_acc: 0.9162 - val_loss: 0.2226 - learning_rate: 3.0000e-04\n",
      "Epoch 44/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9184 - loss: 0.2126 - val_acc: 0.9178 - val_loss: 0.2033 - learning_rate: 3.0000e-04\n",
      "Epoch 45/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9280 - loss: 0.1782 - val_acc: 0.8959 - val_loss: 0.2570 - learning_rate: 3.0000e-04\n",
      "Epoch 46/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9391 - loss: 0.1708 - val_acc: 0.9105 - val_loss: 0.2161 - learning_rate: 3.0000e-04\n",
      "Epoch 47/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9436 - loss: 0.1548 - val_acc: 0.9064 - val_loss: 0.2463 - learning_rate: 3.0000e-04\n",
      "Epoch 48/160\n",
      "\u001b[1m176/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - acc: 0.9453 - loss: 0.1551\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 0.00022500001068692654.\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9453 - loss: 0.1549 - val_acc: 0.9308 - val_loss: 0.1931 - learning_rate: 3.0000e-04\n",
      "Epoch 49/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9343 - loss: 0.1567 - val_acc: 0.9406 - val_loss: 0.1741 - learning_rate: 2.2500e-04\n",
      "Epoch 50/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9521 - loss: 0.1311 - val_acc: 0.9243 - val_loss: 0.1902 - learning_rate: 2.2500e-04\n",
      "Epoch 51/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9394 - loss: 0.1428 - val_acc: 0.9373 - val_loss: 0.1715 - learning_rate: 2.2500e-04\n",
      "Epoch 52/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9454 - loss: 0.1336 - val_acc: 0.9390 - val_loss: 0.1685 - learning_rate: 2.2500e-04\n",
      "Epoch 53/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9387 - loss: 0.1424 - val_acc: 0.9333 - val_loss: 0.1914 - learning_rate: 2.2500e-04\n",
      "Epoch 54/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9443 - loss: 0.1436 - val_acc: 0.9373 - val_loss: 0.1675 - learning_rate: 2.2500e-04\n",
      "Epoch 55/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9547 - loss: 0.1244 - val_acc: 0.9430 - val_loss: 0.1596 - learning_rate: 2.2500e-04\n",
      "Epoch 56/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9504 - loss: 0.1161 - val_acc: 0.9276 - val_loss: 0.1792 - learning_rate: 2.2500e-04\n",
      "Epoch 57/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9474 - loss: 0.1324 - val_acc: 0.9447 - val_loss: 0.1716 - learning_rate: 2.2500e-04\n",
      "Epoch 58/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9558 - loss: 0.1187 - val_acc: 0.9325 - val_loss: 0.1893 - learning_rate: 2.2500e-04\n",
      "Epoch 59/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9605 - loss: 0.1024 - val_acc: 0.9471 - val_loss: 0.1758 - learning_rate: 2.2500e-04\n",
      "Epoch 60/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9576 - loss: 0.1128 - val_acc: 0.9414 - val_loss: 0.1510 - learning_rate: 2.2500e-04\n",
      "Epoch 61/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9595 - loss: 0.1004 - val_acc: 0.9186 - val_loss: 0.2248 - learning_rate: 2.2500e-04\n",
      "Epoch 62/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9507 - loss: 0.1213 - val_acc: 0.9512 - val_loss: 0.1688 - learning_rate: 2.2500e-04\n",
      "Epoch 63/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9578 - loss: 0.1079 - val_acc: 0.9398 - val_loss: 0.1921 - learning_rate: 2.2500e-04\n",
      "Epoch 64/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9445 - loss: 0.1471 - val_acc: 0.9382 - val_loss: 0.1717 - learning_rate: 2.2500e-04\n",
      "Epoch 65/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9517 - loss: 0.1285 - val_acc: 0.9398 - val_loss: 0.1751 - learning_rate: 2.2500e-04\n",
      "Epoch 66/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9571 - loss: 0.1123 - val_acc: 0.9414 - val_loss: 0.1734 - learning_rate: 2.2500e-04\n",
      "Epoch 67/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9562 - loss: 0.1127 - val_acc: 0.9398 - val_loss: 0.1701 - learning_rate: 2.2500e-04\n",
      "Epoch 68/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9628 - loss: 0.1004 - val_acc: 0.9211 - val_loss: 0.2153 - learning_rate: 2.2500e-04\n",
      "Epoch 69/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9579 - loss: 0.1114 - val_acc: 0.9455 - val_loss: 0.1533 - learning_rate: 2.2500e-04\n",
      "Epoch 70/160\n",
      "\u001b[1m179/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - acc: 0.9579 - loss: 0.1021\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 0.0001687500080151949.\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9579 - loss: 0.1021 - val_acc: 0.9349 - val_loss: 0.2168 - learning_rate: 2.2500e-04\n",
      "Epoch 71/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9587 - loss: 0.1101 - val_acc: 0.9479 - val_loss: 0.1890 - learning_rate: 1.6875e-04\n",
      "Epoch 72/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9686 - loss: 0.0779 - val_acc: 0.9422 - val_loss: 0.1498 - learning_rate: 1.6875e-04\n",
      "Epoch 73/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9706 - loss: 0.0855 - val_acc: 0.9382 - val_loss: 0.2136 - learning_rate: 1.6875e-04\n",
      "Epoch 74/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9555 - loss: 0.1059 - val_acc: 0.9260 - val_loss: 0.2060 - learning_rate: 1.6875e-04\n",
      "Epoch 75/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9691 - loss: 0.0901 - val_acc: 0.9455 - val_loss: 0.1829 - learning_rate: 1.6875e-04\n",
      "Epoch 76/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9659 - loss: 0.0882 - val_acc: 0.9504 - val_loss: 0.1824 - learning_rate: 1.6875e-04\n",
      "Epoch 77/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9611 - loss: 0.0972 - val_acc: 0.9422 - val_loss: 0.1556 - learning_rate: 1.6875e-04\n",
      "Epoch 78/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9786 - loss: 0.0695 - val_acc: 0.9414 - val_loss: 0.1953 - learning_rate: 1.6875e-04\n",
      "Epoch 79/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9688 - loss: 0.0850 - val_acc: 0.9512 - val_loss: 0.1357 - learning_rate: 1.6875e-04\n",
      "Epoch 80/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9717 - loss: 0.0813 - val_acc: 0.9496 - val_loss: 0.1733 - learning_rate: 1.6875e-04\n",
      "Epoch 81/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9714 - loss: 0.0713 - val_acc: 0.9496 - val_loss: 0.1653 - learning_rate: 1.6875e-04\n",
      "Epoch 82/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9714 - loss: 0.0788 - val_acc: 0.9455 - val_loss: 0.1603 - learning_rate: 1.6875e-04\n",
      "Epoch 83/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9734 - loss: 0.0778 - val_acc: 0.9455 - val_loss: 0.1591 - learning_rate: 1.6875e-04\n",
      "Epoch 84/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9737 - loss: 0.0721 - val_acc: 0.9520 - val_loss: 0.1501 - learning_rate: 1.6875e-04\n",
      "Epoch 85/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9697 - loss: 0.0698 - val_acc: 0.9406 - val_loss: 0.1489 - learning_rate: 1.6875e-04\n",
      "Epoch 86/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9578 - loss: 0.1034 - val_acc: 0.9414 - val_loss: 0.1983 - learning_rate: 1.6875e-04\n",
      "Epoch 87/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9588 - loss: 0.1156 - val_acc: 0.9536 - val_loss: 0.1514 - learning_rate: 1.6875e-04\n",
      "Epoch 88/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9677 - loss: 0.0880 - val_acc: 0.9447 - val_loss: 0.1683 - learning_rate: 1.6875e-04\n",
      "Epoch 89/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - acc: 0.9787 - loss: 0.0648\n",
      "Epoch 89: ReduceLROnPlateau reducing learning rate to 0.00012656250328291208.\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - acc: 0.9786 - loss: 0.0649 - val_acc: 0.9536 - val_loss: 0.1408 - learning_rate: 1.6875e-04\n",
      "Epoch 90/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9743 - loss: 0.0712 - val_acc: 0.9528 - val_loss: 0.1670 - learning_rate: 1.2656e-04\n",
      "Epoch 91/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9762 - loss: 0.0610 - val_acc: 0.9317 - val_loss: 0.2165 - learning_rate: 1.2656e-04\n",
      "Epoch 92/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9788 - loss: 0.0688 - val_acc: 0.9601 - val_loss: 0.1536 - learning_rate: 1.2656e-04\n",
      "Epoch 93/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9755 - loss: 0.0633 - val_acc: 0.9609 - val_loss: 0.1534 - learning_rate: 1.2656e-04\n",
      "Epoch 94/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9746 - loss: 0.0656 - val_acc: 0.9658 - val_loss: 0.1632 - learning_rate: 1.2656e-04\n",
      "Epoch 95/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9756 - loss: 0.0631 - val_acc: 0.9544 - val_loss: 0.1682 - learning_rate: 1.2656e-04\n",
      "Epoch 96/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9733 - loss: 0.0652 - val_acc: 0.9512 - val_loss: 0.1642 - learning_rate: 1.2656e-04\n",
      "Epoch 97/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9778 - loss: 0.0687 - val_acc: 0.9528 - val_loss: 0.1700 - learning_rate: 1.2656e-04\n",
      "Epoch 98/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9765 - loss: 0.0613 - val_acc: 0.9593 - val_loss: 0.1841 - learning_rate: 1.2656e-04\n",
      "Epoch 99/160\n",
      "\u001b[1m179/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - acc: 0.9799 - loss: 0.0541\n",
      "Epoch 99: ReduceLROnPlateau reducing learning rate to 9.492187746218406e-05.\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9798 - loss: 0.0541 - val_acc: 0.9528 - val_loss: 0.1762 - learning_rate: 1.2656e-04\n",
      "Epoch 99: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/scripts/dl_utils.py:172: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  valores.append(float(df.iloc[3][-2]))\n",
      "/mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/scripts/dl_utils.py:176: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  valores_old.append(float(prev_df.iloc[3][-2]))\n",
      "/home/raulpg/anaconda3/envs/tfm_tf/lib/python3.11/site-packages/keras/src/legacy/preprocessing/image.py:1495: UserWarning: Expected input to be images (as Numpy array) following the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3 or 4 channels on axis 3. However, it was passed an array with shape (2865, 48, 48, 12) (12 channels).\n",
      "  warnings.warn(\n",
      "/home/raulpg/anaconda3/envs/tfm_tf/lib/python3.11/site-packages/keras/src/legacy/preprocessing/image.py:619: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3, or 4 channels on axis 3. However, it was passed an array with shape (2865, 48, 48, 12) (12 channels).\n",
      "  warnings.warn(\n",
      "/home/raulpg/anaconda3/envs/tfm_tf/lib/python3.11/site-packages/keras/src/legacy/preprocessing/image.py:619: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3, or 4 channels on axis 3. However, it was passed an array with shape (1229, 48, 48, 12) (12 channels).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raulpg/anaconda3/envs/tfm_tf/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  2/180\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m17s\u001b[0m 96ms/step - acc: 0.3281 - loss: 0.8099"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1727421778.929641   66956 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - acc: 0.5797 - loss: 0.6729 - val_acc: 0.7225 - val_loss: 0.5465\n",
      "Epoch 2/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.7751 - loss: 0.4918 - val_acc: 0.7803 - val_loss: 0.4709\n",
      "Epoch 3/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.8247 - loss: 0.4221 - val_acc: 0.7608 - val_loss: 0.5058\n",
      "Epoch 4/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.8240 - loss: 0.3969 - val_acc: 0.8600 - val_loss: 0.3635\n",
      "Epoch 5/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.8301 - loss: 0.3840 - val_acc: 0.7648 - val_loss: 0.5177\n",
      "Epoch 6/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.8278 - loss: 0.3713 - val_acc: 0.8584 - val_loss: 0.3227\n",
      "Epoch 7/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.8717 - loss: 0.3098 - val_acc: 0.8226 - val_loss: 0.3786\n",
      "Epoch 8/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.8762 - loss: 0.2902 - val_acc: 0.8641 - val_loss: 0.3316\n",
      "Epoch 9/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.8883 - loss: 0.2786 - val_acc: 0.8926 - val_loss: 0.2492\n",
      "Epoch 10/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.8907 - loss: 0.2533 - val_acc: 0.8592 - val_loss: 0.3339\n",
      "Epoch 11/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.8941 - loss: 0.2710 - val_acc: 0.8779 - val_loss: 0.3091\n",
      "Epoch 12/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.8745 - loss: 0.3165 - val_acc: 0.8967 - val_loss: 0.2452\n",
      "Epoch 13/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9059 - loss: 0.2394 - val_acc: 0.8950 - val_loss: 0.2691\n",
      "Epoch 14/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.8986 - loss: 0.2601 - val_acc: 0.9097 - val_loss: 0.2291\n",
      "Epoch 15/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9090 - loss: 0.2536 - val_acc: 0.8902 - val_loss: 0.2587\n",
      "Epoch 16/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9180 - loss: 0.2173 - val_acc: 0.9129 - val_loss: 0.2049\n",
      "Epoch 17/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9149 - loss: 0.2193 - val_acc: 0.9333 - val_loss: 0.1884\n",
      "Epoch 18/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9375 - loss: 0.1790 - val_acc: 0.9138 - val_loss: 0.2038\n",
      "Epoch 19/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9166 - loss: 0.2197 - val_acc: 0.9178 - val_loss: 0.2113\n",
      "Epoch 20/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9264 - loss: 0.2007 - val_acc: 0.8975 - val_loss: 0.2565\n",
      "Epoch 21/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9216 - loss: 0.2034 - val_acc: 0.9235 - val_loss: 0.1901\n",
      "Epoch 22/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9314 - loss: 0.1809 - val_acc: 0.9235 - val_loss: 0.1901\n",
      "Epoch 23/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9230 - loss: 0.1873 - val_acc: 0.9089 - val_loss: 0.2461\n",
      "Epoch 24/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9376 - loss: 0.1781 - val_acc: 0.9260 - val_loss: 0.1919\n",
      "Epoch 25/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9332 - loss: 0.1723 - val_acc: 0.9194 - val_loss: 0.2565\n",
      "Epoch 26/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9385 - loss: 0.1755 - val_acc: 0.8999 - val_loss: 0.2377\n",
      "Epoch 27/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9246 - loss: 0.1865 - val_acc: 0.9203 - val_loss: 0.2474\n",
      "Epoch 28/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9319 - loss: 0.1824 - val_acc: 0.9349 - val_loss: 0.1977\n",
      "Epoch 29/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9386 - loss: 0.1625 - val_acc: 0.9251 - val_loss: 0.1815\n",
      "Epoch 30/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9442 - loss: 0.1511 - val_acc: 0.9284 - val_loss: 0.1852\n",
      "Epoch 31/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9401 - loss: 0.1508 - val_acc: 0.9292 - val_loss: 0.1824\n",
      "Epoch 32/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9273 - loss: 0.1833 - val_acc: 0.9373 - val_loss: 0.1638\n",
      "Epoch 33/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9484 - loss: 0.1514 - val_acc: 0.9194 - val_loss: 0.1780\n",
      "Epoch 34/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9501 - loss: 0.1474 - val_acc: 0.9341 - val_loss: 0.1873\n",
      "Epoch 35/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9529 - loss: 0.1272 - val_acc: 0.9471 - val_loss: 0.1591\n",
      "Epoch 36/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9388 - loss: 0.1533 - val_acc: 0.9317 - val_loss: 0.1776\n",
      "Epoch 37/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9446 - loss: 0.1491 - val_acc: 0.9455 - val_loss: 0.1547\n",
      "Epoch 38/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9456 - loss: 0.1532 - val_acc: 0.9260 - val_loss: 0.1671\n",
      "Epoch 39/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9449 - loss: 0.1302 - val_acc: 0.9398 - val_loss: 0.1575\n",
      "Epoch 40/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9345 - loss: 0.1735 - val_acc: 0.9414 - val_loss: 0.1735\n",
      "Epoch 41/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9333 - loss: 0.1805 - val_acc: 0.9382 - val_loss: 0.1921\n",
      "Epoch 42/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9508 - loss: 0.1365 - val_acc: 0.9113 - val_loss: 0.2289\n",
      "Epoch 43/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9417 - loss: 0.1508 - val_acc: 0.9422 - val_loss: 0.1793\n",
      "Epoch 44/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9536 - loss: 0.1293 - val_acc: 0.9406 - val_loss: 0.1565\n",
      "Epoch 45/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9560 - loss: 0.1273 - val_acc: 0.8723 - val_loss: 0.3046\n",
      "Epoch 46/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9263 - loss: 0.1878 - val_acc: 0.9357 - val_loss: 0.1825\n",
      "Epoch 47/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9576 - loss: 0.1151 - val_acc: 0.9422 - val_loss: 0.1525\n",
      "Epoch 48/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9477 - loss: 0.1312 - val_acc: 0.9447 - val_loss: 0.1830\n",
      "Epoch 49/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9571 - loss: 0.1252 - val_acc: 0.9308 - val_loss: 0.1537\n",
      "Epoch 50/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9524 - loss: 0.1161 - val_acc: 0.9308 - val_loss: 0.2267\n",
      "Epoch 51/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - acc: 0.9533 - loss: 0.1379 - val_acc: 0.9512 - val_loss: 0.1354\n",
      "Epoch 52/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9567 - loss: 0.1162 - val_acc: 0.9398 - val_loss: 0.1753\n",
      "Epoch 53/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9575 - loss: 0.1205 - val_acc: 0.9341 - val_loss: 0.1658\n",
      "Epoch 54/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - acc: 0.9616 - loss: 0.1048 - val_acc: 0.9463 - val_loss: 0.1580\n",
      "Epoch 55/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9599 - loss: 0.1107 - val_acc: 0.9496 - val_loss: 0.1664\n",
      "Epoch 56/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9546 - loss: 0.1592 - val_acc: 0.8983 - val_loss: 0.2414\n",
      "Epoch 57/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9145 - loss: 0.2185 - val_acc: 0.9211 - val_loss: 0.2384\n",
      "Epoch 58/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9408 - loss: 0.1477 - val_acc: 0.9390 - val_loss: 0.1816\n",
      "Epoch 59/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - acc: 0.9393 - loss: 0.1537 - val_acc: 0.9382 - val_loss: 0.1802\n",
      "Epoch 60/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9541 - loss: 0.1290 - val_acc: 0.9496 - val_loss: 0.1380\n",
      "Epoch 61/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9589 - loss: 0.1029 - val_acc: 0.9447 - val_loss: 0.1578\n",
      "Epoch 62/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9561 - loss: 0.1062 - val_acc: 0.9406 - val_loss: 0.1760\n",
      "Epoch 63/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9527 - loss: 0.1151 - val_acc: 0.9471 - val_loss: 0.1415\n",
      "Epoch 64/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9549 - loss: 0.1131 - val_acc: 0.9487 - val_loss: 0.1420\n",
      "Epoch 65/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9457 - loss: 0.1227 - val_acc: 0.9471 - val_loss: 0.1424\n",
      "Epoch 65: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/scripts/dl_utils.py:172: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  valores.append(float(df.iloc[3][-2]))\n",
      "/mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/scripts/dl_utils.py:176: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  valores_old.append(float(prev_df.iloc[3][-2]))\n",
      "/home/raulpg/anaconda3/envs/tfm_tf/lib/python3.11/site-packages/keras/src/legacy/preprocessing/image.py:1495: UserWarning: Expected input to be images (as Numpy array) following the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3 or 4 channels on axis 3. However, it was passed an array with shape (2865, 48, 48, 12) (12 channels).\n",
      "  warnings.warn(\n",
      "/home/raulpg/anaconda3/envs/tfm_tf/lib/python3.11/site-packages/keras/src/legacy/preprocessing/image.py:619: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3, or 4 channels on axis 3. However, it was passed an array with shape (2865, 48, 48, 12) (12 channels).\n",
      "  warnings.warn(\n",
      "/home/raulpg/anaconda3/envs/tfm_tf/lib/python3.11/site-packages/keras/src/legacy/preprocessing/image.py:619: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3, or 4 channels on axis 3. However, it was passed an array with shape (1229, 48, 48, 12) (12 channels).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raulpg/anaconda3/envs/tfm_tf/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  1/180\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:28\u001b[0m 3s/step - acc: 0.2500 - loss: 0.7272"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1727422019.925090   66958 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - acc: 0.4955 - loss: 0.7116 - val_acc: 0.4101 - val_loss: 0.6966\n",
      "Epoch 2/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 20ms/step - acc: 0.4244 - loss: 0.6950 - val_acc: 0.4101 - val_loss: 0.6938\n",
      "Epoch 3/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.5106 - loss: 0.6915 - val_acc: 0.4101 - val_loss: 0.6939\n",
      "Epoch 4/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.4416 - loss: 0.6985 - val_acc: 0.5899 - val_loss: 0.6923\n",
      "Epoch 5/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.5649 - loss: 0.6952 - val_acc: 0.5899 - val_loss: 0.6931\n",
      "Epoch 6/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.5038 - loss: 0.6950 - val_acc: 0.4101 - val_loss: 0.6934\n",
      "Epoch 7/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.4564 - loss: 0.6951 - val_acc: 0.4101 - val_loss: 0.6934\n",
      "Epoch 8/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.4641 - loss: 0.6933 - val_acc: 0.5899 - val_loss: 0.6927\n",
      "Epoch 9/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.5308 - loss: 0.6929 - val_acc: 0.5899 - val_loss: 0.6930\n",
      "Epoch 10/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.5271 - loss: 0.6924 - val_acc: 0.4101 - val_loss: 0.6936\n",
      "Epoch 11/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.4689 - loss: 0.6929 - val_acc: 0.4101 - val_loss: 0.6939\n",
      "Epoch 12/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.5201 - loss: 0.6893 - val_acc: 0.4101 - val_loss: 0.6936\n",
      "Epoch 13/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.4245 - loss: 0.6950 - val_acc: 0.4101 - val_loss: 0.6935\n",
      "Epoch 14/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.5036 - loss: 0.6911 - val_acc: 0.4101 - val_loss: 0.6935\n",
      "Epoch 15/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.4324 - loss: 0.6965 - val_acc: 0.4101 - val_loss: 0.6932\n",
      "Epoch 16/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.4495 - loss: 0.6936 - val_acc: 0.4101 - val_loss: 0.6936\n",
      "Epoch 17/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.4865 - loss: 0.6932 - val_acc: 0.4101 - val_loss: 0.6933\n",
      "Epoch 18/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.4531 - loss: 0.6956 - val_acc: 0.4101 - val_loss: 0.6937\n",
      "Epoch 18: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raulpg/anaconda3/envs/tfm_tf/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/raulpg/anaconda3/envs/tfm_tf/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/raulpg/anaconda3/envs/tfm_tf/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/scripts/dl_utils.py:172: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  valores.append(float(df.iloc[3][-2]))\n",
      "/mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/scripts/dl_utils.py:176: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  valores_old.append(float(prev_df.iloc[3][-2]))\n",
      "/home/raulpg/anaconda3/envs/tfm_tf/lib/python3.11/site-packages/keras/src/legacy/preprocessing/image.py:1495: UserWarning: Expected input to be images (as Numpy array) following the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3 or 4 channels on axis 3. However, it was passed an array with shape (2865, 48, 48, 12) (12 channels).\n",
      "  warnings.warn(\n",
      "/home/raulpg/anaconda3/envs/tfm_tf/lib/python3.11/site-packages/keras/src/legacy/preprocessing/image.py:619: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3, or 4 channels on axis 3. However, it was passed an array with shape (2865, 48, 48, 12) (12 channels).\n",
      "  warnings.warn(\n",
      "/home/raulpg/anaconda3/envs/tfm_tf/lib/python3.11/site-packages/keras/src/legacy/preprocessing/image.py:619: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3, or 4 channels on axis 3. However, it was passed an array with shape (1229, 48, 48, 12) (12 channels).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raulpg/anaconda3/envs/tfm_tf/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  5/180\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m6s\u001b[0m 39ms/step - acc: 0.3881 - loss: 0.7791"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1727422093.579431   66956 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 28ms/step - acc: 0.5496 - loss: 0.6926 - val_acc: 0.6989 - val_loss: 0.5913 - learning_rate: 3.0000e-04\n",
      "Epoch 2/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.7410 - loss: 0.5421 - val_acc: 0.7624 - val_loss: 0.4885 - learning_rate: 3.0000e-04\n",
      "Epoch 3/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.7890 - loss: 0.4546 - val_acc: 0.7876 - val_loss: 0.4547 - learning_rate: 3.0000e-04\n",
      "Epoch 4/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.8120 - loss: 0.3992 - val_acc: 0.8324 - val_loss: 0.3824 - learning_rate: 3.0000e-04\n",
      "Epoch 5/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.8302 - loss: 0.4092 - val_acc: 0.8397 - val_loss: 0.3533 - learning_rate: 3.0000e-04\n",
      "Epoch 6/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.8469 - loss: 0.3446 - val_acc: 0.8641 - val_loss: 0.2983 - learning_rate: 3.0000e-04\n",
      "Epoch 7/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.8600 - loss: 0.3375 - val_acc: 0.7933 - val_loss: 0.4221 - learning_rate: 3.0000e-04\n",
      "Epoch 8/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.8522 - loss: 0.3342 - val_acc: 0.8657 - val_loss: 0.2994 - learning_rate: 3.0000e-04\n",
      "Epoch 9/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.8666 - loss: 0.3075 - val_acc: 0.8861 - val_loss: 0.2599 - learning_rate: 3.0000e-04\n",
      "Epoch 10/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.8880 - loss: 0.2670 - val_acc: 0.8462 - val_loss: 0.3472 - learning_rate: 3.0000e-04\n",
      "Epoch 11/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.8702 - loss: 0.3057 - val_acc: 0.8845 - val_loss: 0.2661 - learning_rate: 3.0000e-04\n",
      "Epoch 12/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9028 - loss: 0.2494 - val_acc: 0.8910 - val_loss: 0.2679 - learning_rate: 3.0000e-04\n",
      "Epoch 13/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9074 - loss: 0.2316 - val_acc: 0.8975 - val_loss: 0.2403 - learning_rate: 3.0000e-04\n",
      "Epoch 14/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9084 - loss: 0.2334 - val_acc: 0.8609 - val_loss: 0.2890 - learning_rate: 3.0000e-04\n",
      "Epoch 15/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9017 - loss: 0.2376 - val_acc: 0.8918 - val_loss: 0.2405 - learning_rate: 3.0000e-04\n",
      "Epoch 16/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - acc: 0.9148 - loss: 0.2300 - val_acc: 0.9032 - val_loss: 0.2302 - learning_rate: 3.0000e-04\n",
      "Epoch 17/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.8981 - loss: 0.2318 - val_acc: 0.8950 - val_loss: 0.2578 - learning_rate: 3.0000e-04\n",
      "Epoch 18/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9040 - loss: 0.2303 - val_acc: 0.9105 - val_loss: 0.2252 - learning_rate: 3.0000e-04\n",
      "Epoch 19/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9266 - loss: 0.1988 - val_acc: 0.9138 - val_loss: 0.2050 - learning_rate: 3.0000e-04\n",
      "Epoch 20/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9035 - loss: 0.2660 - val_acc: 0.8853 - val_loss: 0.2899 - learning_rate: 3.0000e-04\n",
      "Epoch 21/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9160 - loss: 0.2170 - val_acc: 0.9186 - val_loss: 0.2008 - learning_rate: 3.0000e-04\n",
      "Epoch 22/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9213 - loss: 0.2104 - val_acc: 0.9121 - val_loss: 0.2351 - learning_rate: 3.0000e-04\n",
      "Epoch 23/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9301 - loss: 0.1794 - val_acc: 0.9081 - val_loss: 0.2283 - learning_rate: 3.0000e-04\n",
      "Epoch 24/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9241 - loss: 0.1722 - val_acc: 0.9129 - val_loss: 0.2024 - learning_rate: 3.0000e-04\n",
      "Epoch 25/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9335 - loss: 0.1867 - val_acc: 0.9268 - val_loss: 0.1885 - learning_rate: 3.0000e-04\n",
      "Epoch 26/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9321 - loss: 0.1726 - val_acc: 0.9056 - val_loss: 0.2267 - learning_rate: 3.0000e-04\n",
      "Epoch 27/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9279 - loss: 0.1846 - val_acc: 0.9194 - val_loss: 0.1793 - learning_rate: 3.0000e-04\n",
      "Epoch 28/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9331 - loss: 0.1717 - val_acc: 0.9105 - val_loss: 0.2039 - learning_rate: 3.0000e-04\n",
      "Epoch 29/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9292 - loss: 0.1750 - val_acc: 0.8690 - val_loss: 0.3029 - learning_rate: 3.0000e-04\n",
      "Epoch 30/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9126 - loss: 0.2139 - val_acc: 0.9154 - val_loss: 0.2425 - learning_rate: 3.0000e-04\n",
      "Epoch 31/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9425 - loss: 0.1471 - val_acc: 0.9251 - val_loss: 0.1830 - learning_rate: 3.0000e-04\n",
      "Epoch 32/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9397 - loss: 0.1586 - val_acc: 0.9284 - val_loss: 0.1702 - learning_rate: 3.0000e-04\n",
      "Epoch 33/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9395 - loss: 0.1603 - val_acc: 0.9170 - val_loss: 0.2057 - learning_rate: 3.0000e-04\n",
      "Epoch 34/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9447 - loss: 0.1453 - val_acc: 0.9276 - val_loss: 0.1841 - learning_rate: 3.0000e-04\n",
      "Epoch 35/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9180 - loss: 0.2046 - val_acc: 0.9178 - val_loss: 0.2133 - learning_rate: 3.0000e-04\n",
      "Epoch 36/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9325 - loss: 0.1761 - val_acc: 0.9211 - val_loss: 0.1869 - learning_rate: 3.0000e-04\n",
      "Epoch 37/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9413 - loss: 0.1586 - val_acc: 0.9292 - val_loss: 0.1865 - learning_rate: 3.0000e-04\n",
      "Epoch 38/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9468 - loss: 0.1318 - val_acc: 0.8877 - val_loss: 0.2564 - learning_rate: 3.0000e-04\n",
      "Epoch 39/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9416 - loss: 0.1442 - val_acc: 0.9333 - val_loss: 0.1838 - learning_rate: 3.0000e-04\n",
      "Epoch 40/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9453 - loss: 0.1476 - val_acc: 0.9276 - val_loss: 0.1853 - learning_rate: 3.0000e-04\n",
      "Epoch 41/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9478 - loss: 0.1343 - val_acc: 0.8682 - val_loss: 0.3986 - learning_rate: 3.0000e-04\n",
      "Epoch 42/160\n",
      "\u001b[1m175/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - acc: 0.9371 - loss: 0.1631\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.00022500001068692654.\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9374 - loss: 0.1624 - val_acc: 0.9341 - val_loss: 0.1827 - learning_rate: 3.0000e-04\n",
      "Epoch 43/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9577 - loss: 0.1165 - val_acc: 0.9194 - val_loss: 0.1857 - learning_rate: 2.2500e-04\n",
      "Epoch 44/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9485 - loss: 0.1355 - val_acc: 0.9455 - val_loss: 0.1579 - learning_rate: 2.2500e-04\n",
      "Epoch 45/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9448 - loss: 0.1314 - val_acc: 0.9455 - val_loss: 0.1610 - learning_rate: 2.2500e-04\n",
      "Epoch 46/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9473 - loss: 0.1359 - val_acc: 0.9406 - val_loss: 0.1749 - learning_rate: 2.2500e-04\n",
      "Epoch 47/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9551 - loss: 0.1196 - val_acc: 0.9284 - val_loss: 0.1863 - learning_rate: 2.2500e-04\n",
      "Epoch 48/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9541 - loss: 0.1232 - val_acc: 0.9325 - val_loss: 0.1813 - learning_rate: 2.2500e-04\n",
      "Epoch 49/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9510 - loss: 0.1150 - val_acc: 0.9317 - val_loss: 0.1815 - learning_rate: 2.2500e-04\n",
      "Epoch 50/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9550 - loss: 0.1082 - val_acc: 0.9268 - val_loss: 0.1823 - learning_rate: 2.2500e-04\n",
      "Epoch 51/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9386 - loss: 0.1468 - val_acc: 0.9414 - val_loss: 0.1614 - learning_rate: 2.2500e-04\n",
      "Epoch 52/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9595 - loss: 0.1231 - val_acc: 0.9097 - val_loss: 0.2222 - learning_rate: 2.2500e-04\n",
      "Epoch 53/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9419 - loss: 0.1374 - val_acc: 0.9414 - val_loss: 0.1516 - learning_rate: 2.2500e-04\n",
      "Epoch 54/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9569 - loss: 0.1156 - val_acc: 0.9373 - val_loss: 0.1534 - learning_rate: 2.2500e-04\n",
      "Epoch 55/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9542 - loss: 0.1125 - val_acc: 0.9422 - val_loss: 0.1659 - learning_rate: 2.2500e-04\n",
      "Epoch 56/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9581 - loss: 0.1049 - val_acc: 0.9455 - val_loss: 0.1592 - learning_rate: 2.2500e-04\n",
      "Epoch 57/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9532 - loss: 0.1170 - val_acc: 0.9382 - val_loss: 0.1834 - learning_rate: 2.2500e-04\n",
      "Epoch 58/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9540 - loss: 0.1083 - val_acc: 0.9276 - val_loss: 0.2157 - learning_rate: 2.2500e-04\n",
      "Epoch 59/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9593 - loss: 0.1161 - val_acc: 0.9422 - val_loss: 0.1567 - learning_rate: 2.2500e-04\n",
      "Epoch 60/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9672 - loss: 0.0924 - val_acc: 0.9479 - val_loss: 0.1718 - learning_rate: 2.2500e-04\n",
      "Epoch 61/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9663 - loss: 0.0922 - val_acc: 0.9463 - val_loss: 0.1380 - learning_rate: 2.2500e-04\n",
      "Epoch 62/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9671 - loss: 0.0870 - val_acc: 0.9406 - val_loss: 0.1523 - learning_rate: 2.2500e-04\n",
      "Epoch 63/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9608 - loss: 0.0988 - val_acc: 0.9422 - val_loss: 0.1556 - learning_rate: 2.2500e-04\n",
      "Epoch 64/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9654 - loss: 0.0946 - val_acc: 0.9528 - val_loss: 0.1578 - learning_rate: 2.2500e-04\n",
      "Epoch 65/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9603 - loss: 0.1023 - val_acc: 0.9479 - val_loss: 0.2227 - learning_rate: 2.2500e-04\n",
      "Epoch 66/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9638 - loss: 0.0955 - val_acc: 0.9373 - val_loss: 0.1742 - learning_rate: 2.2500e-04\n",
      "Epoch 67/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9681 - loss: 0.0985 - val_acc: 0.9504 - val_loss: 0.1348 - learning_rate: 2.2500e-04\n",
      "Epoch 68/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - acc: 0.9696 - loss: 0.0901 - val_acc: 0.9430 - val_loss: 0.1706 - learning_rate: 2.2500e-04\n",
      "Epoch 69/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - acc: 0.9638 - loss: 0.0959 - val_acc: 0.9325 - val_loss: 0.2158 - learning_rate: 2.2500e-04\n",
      "Epoch 70/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9648 - loss: 0.0848 - val_acc: 0.9406 - val_loss: 0.1816 - learning_rate: 2.2500e-04\n",
      "Epoch 71/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9555 - loss: 0.1158 - val_acc: 0.9406 - val_loss: 0.1530 - learning_rate: 2.2500e-04\n",
      "Epoch 72/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9674 - loss: 0.0890 - val_acc: 0.9463 - val_loss: 0.1553 - learning_rate: 2.2500e-04\n",
      "Epoch 73/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9685 - loss: 0.0765 - val_acc: 0.9113 - val_loss: 0.2565 - learning_rate: 2.2500e-04\n",
      "Epoch 74/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9531 - loss: 0.1154 - val_acc: 0.9496 - val_loss: 0.1506 - learning_rate: 2.2500e-04\n",
      "Epoch 75/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9644 - loss: 0.0939 - val_acc: 0.9235 - val_loss: 0.1925 - learning_rate: 2.2500e-04\n",
      "Epoch 76/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9454 - loss: 0.1401 - val_acc: 0.9373 - val_loss: 0.1808 - learning_rate: 2.2500e-04\n",
      "Epoch 77/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - acc: 0.9595 - loss: 0.1073\n",
      "Epoch 77: ReduceLROnPlateau reducing learning rate to 0.0001687500080151949.\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9595 - loss: 0.1072 - val_acc: 0.9317 - val_loss: 0.1931 - learning_rate: 2.2500e-04\n",
      "Epoch 78/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9703 - loss: 0.0830 - val_acc: 0.9463 - val_loss: 0.1486 - learning_rate: 1.6875e-04\n",
      "Epoch 79/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9681 - loss: 0.0892 - val_acc: 0.9463 - val_loss: 0.1702 - learning_rate: 1.6875e-04\n",
      "Epoch 80/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9725 - loss: 0.0656 - val_acc: 0.9487 - val_loss: 0.1366 - learning_rate: 1.6875e-04\n",
      "Epoch 81/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9754 - loss: 0.0762 - val_acc: 0.9406 - val_loss: 0.1406 - learning_rate: 1.6875e-04\n",
      "Epoch 82/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9750 - loss: 0.0666 - val_acc: 0.9585 - val_loss: 0.1239 - learning_rate: 1.6875e-04\n",
      "Epoch 83/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9738 - loss: 0.0637 - val_acc: 0.9341 - val_loss: 0.2009 - learning_rate: 1.6875e-04\n",
      "Epoch 84/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9556 - loss: 0.1056 - val_acc: 0.9552 - val_loss: 0.1439 - learning_rate: 1.6875e-04\n",
      "Epoch 85/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9743 - loss: 0.0691 - val_acc: 0.9569 - val_loss: 0.1298 - learning_rate: 1.6875e-04\n",
      "Epoch 86/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9759 - loss: 0.0556 - val_acc: 0.9479 - val_loss: 0.1675 - learning_rate: 1.6875e-04\n",
      "Epoch 87/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9789 - loss: 0.0618 - val_acc: 0.9414 - val_loss: 0.2184 - learning_rate: 1.6875e-04\n",
      "Epoch 88/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9744 - loss: 0.0772 - val_acc: 0.9520 - val_loss: 0.1654 - learning_rate: 1.6875e-04\n",
      "Epoch 89/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9751 - loss: 0.0726 - val_acc: 0.9496 - val_loss: 0.1346 - learning_rate: 1.6875e-04\n",
      "Epoch 90/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9786 - loss: 0.0568 - val_acc: 0.9471 - val_loss: 0.1681 - learning_rate: 1.6875e-04\n",
      "Epoch 91/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9719 - loss: 0.0853 - val_acc: 0.9561 - val_loss: 0.1478 - learning_rate: 1.6875e-04\n",
      "Epoch 92/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - acc: 0.9773 - loss: 0.0521\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 0.00012656250328291208.\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9773 - loss: 0.0521 - val_acc: 0.9487 - val_loss: 0.1820 - learning_rate: 1.6875e-04\n",
      "Epoch 93/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9799 - loss: 0.0562 - val_acc: 0.9414 - val_loss: 0.2017 - learning_rate: 1.2656e-04\n",
      "Epoch 94/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9762 - loss: 0.0672 - val_acc: 0.9528 - val_loss: 0.1358 - learning_rate: 1.2656e-04\n",
      "Epoch 95/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9818 - loss: 0.0458 - val_acc: 0.9479 - val_loss: 0.1738 - learning_rate: 1.2656e-04\n",
      "Epoch 96/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9837 - loss: 0.0461 - val_acc: 0.9569 - val_loss: 0.1670 - learning_rate: 1.2656e-04\n",
      "Epoch 97/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9865 - loss: 0.0392 - val_acc: 0.9569 - val_loss: 0.1763 - learning_rate: 1.2656e-04\n",
      "Epoch 98/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9830 - loss: 0.0397 - val_acc: 0.9455 - val_loss: 0.1763 - learning_rate: 1.2656e-04\n",
      "Epoch 99/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9868 - loss: 0.0400 - val_acc: 0.9471 - val_loss: 0.1612 - learning_rate: 1.2656e-04\n",
      "Epoch 100/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9797 - loss: 0.0578 - val_acc: 0.9552 - val_loss: 0.1341 - learning_rate: 1.2656e-04\n",
      "Epoch 101/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9895 - loss: 0.0284 - val_acc: 0.9536 - val_loss: 0.1654 - learning_rate: 1.2656e-04\n",
      "Epoch 102/160\n",
      "\u001b[1m178/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - acc: 0.9843 - loss: 0.0451\n",
      "Epoch 102: ReduceLROnPlateau reducing learning rate to 9.492187746218406e-05.\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9843 - loss: 0.0452 - val_acc: 0.9544 - val_loss: 0.1662 - learning_rate: 1.2656e-04\n",
      "Epoch 102: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/scripts/dl_utils.py:172: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  valores.append(float(df.iloc[3][-2]))\n",
      "/mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/scripts/dl_utils.py:176: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  valores_old.append(float(prev_df.iloc[3][-2]))\n",
      "/home/raulpg/anaconda3/envs/tfm_tf/lib/python3.11/site-packages/keras/src/legacy/preprocessing/image.py:1495: UserWarning: Expected input to be images (as Numpy array) following the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3 or 4 channels on axis 3. However, it was passed an array with shape (2865, 48, 48, 12) (12 channels).\n",
      "  warnings.warn(\n",
      "/home/raulpg/anaconda3/envs/tfm_tf/lib/python3.11/site-packages/keras/src/legacy/preprocessing/image.py:619: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3, or 4 channels on axis 3. However, it was passed an array with shape (2865, 48, 48, 12) (12 channels).\n",
      "  warnings.warn(\n",
      "/home/raulpg/anaconda3/envs/tfm_tf/lib/python3.11/site-packages/keras/src/legacy/preprocessing/image.py:619: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3, or 4 channels on axis 3. However, it was passed an array with shape (1229, 48, 48, 12) (12 channels).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raulpg/anaconda3/envs/tfm_tf/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  1/180\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:35\u001b[0m 3s/step - acc: 0.6875 - loss: 0.6222"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1727422462.230387   66958 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - acc: 0.5726 - loss: 0.6869 - val_acc: 0.7404 - val_loss: 0.5415 - learning_rate: 3.0000e-04\n",
      "Epoch 2/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.7359 - loss: 0.5469 - val_acc: 0.7087 - val_loss: 0.5836 - learning_rate: 3.0000e-04\n",
      "Epoch 3/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.7509 - loss: 0.5068 - val_acc: 0.8129 - val_loss: 0.4049 - learning_rate: 3.0000e-04\n",
      "Epoch 4/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.7927 - loss: 0.4541 - val_acc: 0.8055 - val_loss: 0.3988 - learning_rate: 3.0000e-04\n",
      "Epoch 5/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.8538 - loss: 0.3545 - val_acc: 0.8267 - val_loss: 0.3879 - learning_rate: 3.0000e-04\n",
      "Epoch 6/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.8623 - loss: 0.3152 - val_acc: 0.8666 - val_loss: 0.3254 - learning_rate: 3.0000e-04\n",
      "Epoch 7/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.8560 - loss: 0.3124 - val_acc: 0.8666 - val_loss: 0.3157 - learning_rate: 3.0000e-04\n",
      "Epoch 8/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.8776 - loss: 0.2869 - val_acc: 0.8820 - val_loss: 0.2515 - learning_rate: 3.0000e-04\n",
      "Epoch 9/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.8971 - loss: 0.2604 - val_acc: 0.8633 - val_loss: 0.2991 - learning_rate: 3.0000e-04\n",
      "Epoch 10/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.8956 - loss: 0.2551 - val_acc: 0.9129 - val_loss: 0.2304 - learning_rate: 3.0000e-04\n",
      "Epoch 11/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9047 - loss: 0.2399 - val_acc: 0.9056 - val_loss: 0.2506 - learning_rate: 3.0000e-04\n",
      "Epoch 12/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9138 - loss: 0.2161 - val_acc: 0.8983 - val_loss: 0.2426 - learning_rate: 3.0000e-04\n",
      "Epoch 13/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9031 - loss: 0.2403 - val_acc: 0.9089 - val_loss: 0.2140 - learning_rate: 3.0000e-04\n",
      "Epoch 14/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9293 - loss: 0.1886 - val_acc: 0.8478 - val_loss: 0.3387 - learning_rate: 3.0000e-04\n",
      "Epoch 15/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9274 - loss: 0.1933 - val_acc: 0.9235 - val_loss: 0.2077 - learning_rate: 3.0000e-04\n",
      "Epoch 16/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9281 - loss: 0.1953 - val_acc: 0.9146 - val_loss: 0.2184 - learning_rate: 3.0000e-04\n",
      "Epoch 17/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9349 - loss: 0.1698 - val_acc: 0.9154 - val_loss: 0.1971 - learning_rate: 3.0000e-04\n",
      "Epoch 18/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9282 - loss: 0.1778 - val_acc: 0.8861 - val_loss: 0.2723 - learning_rate: 3.0000e-04\n",
      "Epoch 19/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9353 - loss: 0.1784 - val_acc: 0.9268 - val_loss: 0.1781 - learning_rate: 3.0000e-04\n",
      "Epoch 20/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9245 - loss: 0.2054 - val_acc: 0.9138 - val_loss: 0.2090 - learning_rate: 3.0000e-04\n",
      "Epoch 21/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9299 - loss: 0.1775 - val_acc: 0.9105 - val_loss: 0.2252 - learning_rate: 3.0000e-04\n",
      "Epoch 22/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9304 - loss: 0.1814 - val_acc: 0.9162 - val_loss: 0.2012 - learning_rate: 3.0000e-04\n",
      "Epoch 23/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9388 - loss: 0.1751 - val_acc: 0.9268 - val_loss: 0.1887 - learning_rate: 3.0000e-04\n",
      "Epoch 24/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9480 - loss: 0.1409 - val_acc: 0.9186 - val_loss: 0.2188 - learning_rate: 3.0000e-04\n",
      "Epoch 25/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9461 - loss: 0.1649 - val_acc: 0.9341 - val_loss: 0.1744 - learning_rate: 3.0000e-04\n",
      "Epoch 26/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9487 - loss: 0.1410 - val_acc: 0.9268 - val_loss: 0.1880 - learning_rate: 3.0000e-04\n",
      "Epoch 27/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9419 - loss: 0.1482 - val_acc: 0.9276 - val_loss: 0.1817 - learning_rate: 3.0000e-04\n",
      "Epoch 28/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9418 - loss: 0.1485 - val_acc: 0.9390 - val_loss: 0.1716 - learning_rate: 3.0000e-04\n",
      "Epoch 29/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9508 - loss: 0.1403 - val_acc: 0.9211 - val_loss: 0.1932 - learning_rate: 3.0000e-04\n",
      "Epoch 30/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - acc: 0.9434 - loss: 0.1497 - val_acc: 0.9422 - val_loss: 0.1521 - learning_rate: 3.0000e-04\n",
      "Epoch 31/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9526 - loss: 0.1283 - val_acc: 0.9333 - val_loss: 0.1823 - learning_rate: 3.0000e-04\n",
      "Epoch 32/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9516 - loss: 0.1359 - val_acc: 0.9382 - val_loss: 0.1667 - learning_rate: 3.0000e-04\n",
      "Epoch 33/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9449 - loss: 0.1394 - val_acc: 0.9365 - val_loss: 0.1830 - learning_rate: 3.0000e-04\n",
      "Epoch 34/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9527 - loss: 0.1353 - val_acc: 0.9382 - val_loss: 0.1546 - learning_rate: 3.0000e-04\n",
      "Epoch 35/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9515 - loss: 0.1366 - val_acc: 0.9398 - val_loss: 0.1578 - learning_rate: 3.0000e-04\n",
      "Epoch 36/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9455 - loss: 0.1328 - val_acc: 0.9373 - val_loss: 0.1676 - learning_rate: 3.0000e-04\n",
      "Epoch 37/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9462 - loss: 0.1435 - val_acc: 0.9341 - val_loss: 0.1689 - learning_rate: 3.0000e-04\n",
      "Epoch 38/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9587 - loss: 0.1058 - val_acc: 0.9455 - val_loss: 0.1497 - learning_rate: 3.0000e-04\n",
      "Epoch 39/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9623 - loss: 0.1175 - val_acc: 0.9398 - val_loss: 0.1569 - learning_rate: 3.0000e-04\n",
      "Epoch 40/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9522 - loss: 0.1300 - val_acc: 0.9373 - val_loss: 0.1479 - learning_rate: 3.0000e-04\n",
      "Epoch 41/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9621 - loss: 0.1011 - val_acc: 0.9325 - val_loss: 0.1865 - learning_rate: 3.0000e-04\n",
      "Epoch 42/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9577 - loss: 0.1228 - val_acc: 0.9341 - val_loss: 0.1770 - learning_rate: 3.0000e-04\n",
      "Epoch 43/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9611 - loss: 0.1047 - val_acc: 0.9284 - val_loss: 0.2022 - learning_rate: 3.0000e-04\n",
      "Epoch 44/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9568 - loss: 0.1184 - val_acc: 0.9382 - val_loss: 0.1871 - learning_rate: 3.0000e-04\n",
      "Epoch 45/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9444 - loss: 0.1393 - val_acc: 0.9064 - val_loss: 0.2425 - learning_rate: 3.0000e-04\n",
      "Epoch 46/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9387 - loss: 0.1607 - val_acc: 0.9089 - val_loss: 0.2288 - learning_rate: 3.0000e-04\n",
      "Epoch 47/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9514 - loss: 0.1337 - val_acc: 0.9463 - val_loss: 0.1639 - learning_rate: 3.0000e-04\n",
      "Epoch 48/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9586 - loss: 0.1089 - val_acc: 0.9398 - val_loss: 0.1746 - learning_rate: 3.0000e-04\n",
      "Epoch 49/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9586 - loss: 0.1147 - val_acc: 0.9341 - val_loss: 0.2005 - learning_rate: 3.0000e-04\n",
      "Epoch 50/160\n",
      "\u001b[1m176/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - acc: 0.9528 - loss: 0.1127\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 0.00022500001068692654.\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9529 - loss: 0.1128 - val_acc: 0.9317 - val_loss: 0.1776 - learning_rate: 3.0000e-04\n",
      "Epoch 51/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9570 - loss: 0.1077 - val_acc: 0.9528 - val_loss: 0.1628 - learning_rate: 2.2500e-04\n",
      "Epoch 52/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9606 - loss: 0.0976 - val_acc: 0.9341 - val_loss: 0.1946 - learning_rate: 2.2500e-04\n",
      "Epoch 53/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9667 - loss: 0.0881 - val_acc: 0.9422 - val_loss: 0.1451 - learning_rate: 2.2500e-04\n",
      "Epoch 54/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9678 - loss: 0.0871 - val_acc: 0.9341 - val_loss: 0.1706 - learning_rate: 2.2500e-04\n",
      "Epoch 55/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9631 - loss: 0.0906 - val_acc: 0.9520 - val_loss: 0.1462 - learning_rate: 2.2500e-04\n",
      "Epoch 56/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9736 - loss: 0.0764 - val_acc: 0.9447 - val_loss: 0.1558 - learning_rate: 2.2500e-04\n",
      "Epoch 57/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9633 - loss: 0.0865 - val_acc: 0.9422 - val_loss: 0.1767 - learning_rate: 2.2500e-04\n",
      "Epoch 58/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9755 - loss: 0.0648 - val_acc: 0.9276 - val_loss: 0.2053 - learning_rate: 2.2500e-04\n",
      "Epoch 59/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9723 - loss: 0.0780 - val_acc: 0.9300 - val_loss: 0.2328 - learning_rate: 2.2500e-04\n",
      "Epoch 60/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9551 - loss: 0.1019 - val_acc: 0.9243 - val_loss: 0.2538 - learning_rate: 2.2500e-04\n",
      "Epoch 61/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9565 - loss: 0.1046 - val_acc: 0.9479 - val_loss: 0.1618 - learning_rate: 2.2500e-04\n",
      "Epoch 62/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9715 - loss: 0.0730 - val_acc: 0.9528 - val_loss: 0.1560 - learning_rate: 2.2500e-04\n",
      "Epoch 63/160\n",
      "\u001b[1m178/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - acc: 0.9685 - loss: 0.0869\n",
      "Epoch 63: ReduceLROnPlateau reducing learning rate to 0.0001687500080151949.\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9685 - loss: 0.0869 - val_acc: 0.9032 - val_loss: 0.2720 - learning_rate: 2.2500e-04\n",
      "Epoch 64/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9445 - loss: 0.1306 - val_acc: 0.9552 - val_loss: 0.1459 - learning_rate: 1.6875e-04\n",
      "Epoch 65/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9794 - loss: 0.0586 - val_acc: 0.9601 - val_loss: 0.1237 - learning_rate: 1.6875e-04\n",
      "Epoch 66/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - acc: 0.9785 - loss: 0.0619 - val_acc: 0.9341 - val_loss: 0.1795 - learning_rate: 1.6875e-04\n",
      "Epoch 67/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9685 - loss: 0.0812 - val_acc: 0.9577 - val_loss: 0.1209 - learning_rate: 1.6875e-04\n",
      "Epoch 68/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9734 - loss: 0.0648 - val_acc: 0.9504 - val_loss: 0.1563 - learning_rate: 1.6875e-04\n",
      "Epoch 69/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9785 - loss: 0.0573 - val_acc: 0.9333 - val_loss: 0.1893 - learning_rate: 1.6875e-04\n",
      "Epoch 70/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9780 - loss: 0.0578 - val_acc: 0.9544 - val_loss: 0.1384 - learning_rate: 1.6875e-04\n",
      "Epoch 71/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9853 - loss: 0.0441 - val_acc: 0.9390 - val_loss: 0.1908 - learning_rate: 1.6875e-04\n",
      "Epoch 72/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9701 - loss: 0.0699 - val_acc: 0.9577 - val_loss: 0.1289 - learning_rate: 1.6875e-04\n",
      "Epoch 73/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9735 - loss: 0.0756 - val_acc: 0.9447 - val_loss: 0.2009 - learning_rate: 1.6875e-04\n",
      "Epoch 74/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9792 - loss: 0.0698 - val_acc: 0.9609 - val_loss: 0.1326 - learning_rate: 1.6875e-04\n",
      "Epoch 75/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9836 - loss: 0.0507 - val_acc: 0.9512 - val_loss: 0.1347 - learning_rate: 1.6875e-04\n",
      "Epoch 76/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9784 - loss: 0.0561 - val_acc: 0.9512 - val_loss: 0.1406 - learning_rate: 1.6875e-04\n",
      "Epoch 77/160\n",
      "\u001b[1m176/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - acc: 0.9867 - loss: 0.0476\n",
      "Epoch 77: ReduceLROnPlateau reducing learning rate to 0.00012656250328291208.\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9866 - loss: 0.0478 - val_acc: 0.9544 - val_loss: 0.1411 - learning_rate: 1.6875e-04\n",
      "Epoch 78/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9805 - loss: 0.0538 - val_acc: 0.9561 - val_loss: 0.1597 - learning_rate: 1.2656e-04\n",
      "Epoch 79/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9862 - loss: 0.0400 - val_acc: 0.9569 - val_loss: 0.1326 - learning_rate: 1.2656e-04\n",
      "Epoch 80/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9855 - loss: 0.0402 - val_acc: 0.9520 - val_loss: 0.1552 - learning_rate: 1.2656e-04\n",
      "Epoch 81/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9827 - loss: 0.0456 - val_acc: 0.9585 - val_loss: 0.1365 - learning_rate: 1.2656e-04\n",
      "Epoch 82/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9843 - loss: 0.0427 - val_acc: 0.9479 - val_loss: 0.1613 - learning_rate: 1.2656e-04\n",
      "Epoch 83/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9793 - loss: 0.0503 - val_acc: 0.9601 - val_loss: 0.1379 - learning_rate: 1.2656e-04\n",
      "Epoch 84/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9869 - loss: 0.0325 - val_acc: 0.9512 - val_loss: 0.1704 - learning_rate: 1.2656e-04\n",
      "Epoch 85/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9840 - loss: 0.0460 - val_acc: 0.9512 - val_loss: 0.1805 - learning_rate: 1.2656e-04\n",
      "Epoch 86/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9873 - loss: 0.0316 - val_acc: 0.9512 - val_loss: 0.1760 - learning_rate: 1.2656e-04\n",
      "Epoch 87/160\n",
      "\u001b[1m175/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - acc: 0.9900 - loss: 0.0314\n",
      "Epoch 87: ReduceLROnPlateau reducing learning rate to 9.492187746218406e-05.\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9898 - loss: 0.0317 - val_acc: 0.9536 - val_loss: 0.1949 - learning_rate: 1.2656e-04\n",
      "Epoch 87: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/scripts/dl_utils.py:172: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  valores.append(float(df.iloc[3][-2]))\n",
      "/mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/scripts/dl_utils.py:176: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  valores_old.append(float(prev_df.iloc[3][-2]))\n",
      "/home/raulpg/anaconda3/envs/tfm_tf/lib/python3.11/site-packages/keras/src/legacy/preprocessing/image.py:1495: UserWarning: Expected input to be images (as Numpy array) following the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3 or 4 channels on axis 3. However, it was passed an array with shape (2865, 48, 48, 12) (12 channels).\n",
      "  warnings.warn(\n",
      "/home/raulpg/anaconda3/envs/tfm_tf/lib/python3.11/site-packages/keras/src/legacy/preprocessing/image.py:619: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3, or 4 channels on axis 3. However, it was passed an array with shape (2865, 48, 48, 12) (12 channels).\n",
      "  warnings.warn(\n",
      "/home/raulpg/anaconda3/envs/tfm_tf/lib/python3.11/site-packages/keras/src/legacy/preprocessing/image.py:619: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3, or 4 channels on axis 3. However, it was passed an array with shape (1229, 48, 48, 12) (12 channels).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raulpg/anaconda3/envs/tfm_tf/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  1/180\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:31\u001b[0m 3s/step - acc: 0.5000 - loss: 0.7290"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1727422775.301685   66957 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - acc: 0.5629 - loss: 0.6893 - val_acc: 0.7388 - val_loss: 0.5312\n",
      "Epoch 2/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.7616 - loss: 0.5201 - val_acc: 0.7290 - val_loss: 0.5089\n",
      "Epoch 3/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.7927 - loss: 0.4504 - val_acc: 0.8218 - val_loss: 0.3877\n",
      "Epoch 4/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.8408 - loss: 0.3685 - val_acc: 0.8633 - val_loss: 0.3680\n",
      "Epoch 5/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.8542 - loss: 0.3415 - val_acc: 0.8454 - val_loss: 0.4471\n",
      "Epoch 6/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.8439 - loss: 0.3720 - val_acc: 0.8560 - val_loss: 0.3088\n",
      "Epoch 7/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.8742 - loss: 0.3111 - val_acc: 0.8788 - val_loss: 0.2980\n",
      "Epoch 8/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.8748 - loss: 0.2984 - val_acc: 0.8804 - val_loss: 0.2932\n",
      "Epoch 9/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.8869 - loss: 0.2601 - val_acc: 0.8796 - val_loss: 0.2565\n",
      "Epoch 10/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.8939 - loss: 0.2467 - val_acc: 0.8804 - val_loss: 0.2836\n",
      "Epoch 11/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 20ms/step - acc: 0.9087 - loss: 0.2407 - val_acc: 0.8910 - val_loss: 0.2773\n",
      "Epoch 12/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9093 - loss: 0.2436 - val_acc: 0.8991 - val_loss: 0.2304\n",
      "Epoch 13/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9160 - loss: 0.2221 - val_acc: 0.9064 - val_loss: 0.2240\n",
      "Epoch 14/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9120 - loss: 0.2163 - val_acc: 0.9129 - val_loss: 0.2230\n",
      "Epoch 15/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9120 - loss: 0.2178 - val_acc: 0.9105 - val_loss: 0.2104\n",
      "Epoch 16/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9026 - loss: 0.2349 - val_acc: 0.9186 - val_loss: 0.2095\n",
      "Epoch 17/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9311 - loss: 0.1838 - val_acc: 0.9129 - val_loss: 0.2119\n",
      "Epoch 18/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9254 - loss: 0.2023 - val_acc: 0.9113 - val_loss: 0.2214\n",
      "Epoch 19/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9156 - loss: 0.2065 - val_acc: 0.8918 - val_loss: 0.2665\n",
      "Epoch 20/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9225 - loss: 0.1931 - val_acc: 0.9268 - val_loss: 0.1815\n",
      "Epoch 21/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9311 - loss: 0.1830 - val_acc: 0.9072 - val_loss: 0.2225\n",
      "Epoch 22/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9223 - loss: 0.1886 - val_acc: 0.9219 - val_loss: 0.2031\n",
      "Epoch 23/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9388 - loss: 0.1624 - val_acc: 0.9113 - val_loss: 0.2068\n",
      "Epoch 24/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9281 - loss: 0.1770 - val_acc: 0.9349 - val_loss: 0.1764\n",
      "Epoch 25/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9422 - loss: 0.1561 - val_acc: 0.9203 - val_loss: 0.1981\n",
      "Epoch 26/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9409 - loss: 0.1542 - val_acc: 0.9268 - val_loss: 0.1943\n",
      "Epoch 27/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9398 - loss: 0.1744 - val_acc: 0.9235 - val_loss: 0.1989\n",
      "Epoch 28/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9291 - loss: 0.1901 - val_acc: 0.9064 - val_loss: 0.2423\n",
      "Epoch 29/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 19ms/step - acc: 0.9362 - loss: 0.1721 - val_acc: 0.9227 - val_loss: 0.1975\n",
      "Epoch 30/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9365 - loss: 0.1570 - val_acc: 0.9154 - val_loss: 0.2819\n",
      "Epoch 31/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9476 - loss: 0.1427 - val_acc: 0.9341 - val_loss: 0.1986\n",
      "Epoch 32/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9417 - loss: 0.1485 - val_acc: 0.9015 - val_loss: 0.2283\n",
      "Epoch 33/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9464 - loss: 0.1465 - val_acc: 0.9227 - val_loss: 0.1957\n",
      "Epoch 34/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9548 - loss: 0.1280 - val_acc: 0.9300 - val_loss: 0.1854\n",
      "Epoch 35/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9384 - loss: 0.1520 - val_acc: 0.9300 - val_loss: 0.1743\n",
      "Epoch 36/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9455 - loss: 0.1555 - val_acc: 0.9341 - val_loss: 0.1648\n",
      "Epoch 37/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9522 - loss: 0.1304 - val_acc: 0.9235 - val_loss: 0.2015\n",
      "Epoch 38/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9393 - loss: 0.1548 - val_acc: 0.9455 - val_loss: 0.1581\n",
      "Epoch 39/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9482 - loss: 0.1403 - val_acc: 0.9325 - val_loss: 0.1607\n",
      "Epoch 40/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9534 - loss: 0.1356 - val_acc: 0.9471 - val_loss: 0.1557\n",
      "Epoch 41/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9533 - loss: 0.1190 - val_acc: 0.9300 - val_loss: 0.2048\n",
      "Epoch 42/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - acc: 0.9495 - loss: 0.1471 - val_acc: 0.9300 - val_loss: 0.2412\n",
      "Epoch 43/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - acc: 0.9199 - loss: 0.1940 - val_acc: 0.8177 - val_loss: 0.4230\n",
      "Epoch 44/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - acc: 0.9059 - loss: 0.2495 - val_acc: 0.9089 - val_loss: 0.2135\n",
      "Epoch 45/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - acc: 0.9224 - loss: 0.1935 - val_acc: 0.9072 - val_loss: 0.2044\n",
      "Epoch 46/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9436 - loss: 0.1524 - val_acc: 0.9349 - val_loss: 0.1707\n",
      "Epoch 47/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - acc: 0.9377 - loss: 0.1578 - val_acc: 0.9325 - val_loss: 0.1739\n",
      "Epoch 48/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9524 - loss: 0.1287 - val_acc: 0.9349 - val_loss: 0.1504\n",
      "Epoch 49/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9467 - loss: 0.1352 - val_acc: 0.9373 - val_loss: 0.1735\n",
      "Epoch 50/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9580 - loss: 0.1098 - val_acc: 0.9129 - val_loss: 0.2245\n",
      "Epoch 51/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9429 - loss: 0.1462 - val_acc: 0.9382 - val_loss: 0.1452\n",
      "Epoch 52/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9578 - loss: 0.1126 - val_acc: 0.9333 - val_loss: 0.1858\n",
      "Epoch 53/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9287 - loss: 0.1957 - val_acc: 0.9357 - val_loss: 0.1494\n",
      "Epoch 54/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9638 - loss: 0.1103 - val_acc: 0.9276 - val_loss: 0.2195\n",
      "Epoch 55/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9532 - loss: 0.1235 - val_acc: 0.9487 - val_loss: 0.1486\n",
      "Epoch 56/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9608 - loss: 0.0947 - val_acc: 0.9422 - val_loss: 0.1716\n",
      "Epoch 57/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9659 - loss: 0.1052 - val_acc: 0.9300 - val_loss: 0.1830\n",
      "Epoch 58/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9536 - loss: 0.1141 - val_acc: 0.9447 - val_loss: 0.1661\n",
      "Epoch 59/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9680 - loss: 0.0883 - val_acc: 0.9349 - val_loss: 0.2172\n",
      "Epoch 60/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9684 - loss: 0.0917 - val_acc: 0.9422 - val_loss: 0.1758\n",
      "Epoch 61/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9481 - loss: 0.1400 - val_acc: 0.9447 - val_loss: 0.1561\n",
      "Epoch 62/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9599 - loss: 0.1183 - val_acc: 0.9447 - val_loss: 0.1763\n",
      "Epoch 63/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9634 - loss: 0.1017 - val_acc: 0.9357 - val_loss: 0.1977\n",
      "Epoch 64/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9610 - loss: 0.1007 - val_acc: 0.9496 - val_loss: 0.1388\n",
      "Epoch 65/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9616 - loss: 0.0947 - val_acc: 0.9333 - val_loss: 0.1670\n",
      "Epoch 66/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9585 - loss: 0.1025 - val_acc: 0.9430 - val_loss: 0.1685\n",
      "Epoch 67/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9572 - loss: 0.1020 - val_acc: 0.8666 - val_loss: 0.3478\n",
      "Epoch 68/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9275 - loss: 0.2157 - val_acc: 0.9349 - val_loss: 0.1729\n",
      "Epoch 69/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9551 - loss: 0.1174 - val_acc: 0.9308 - val_loss: 0.1718\n",
      "Epoch 70/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9633 - loss: 0.0984 - val_acc: 0.9447 - val_loss: 0.1663\n",
      "Epoch 71/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9550 - loss: 0.1179 - val_acc: 0.9333 - val_loss: 0.1915\n",
      "Epoch 72/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9602 - loss: 0.1109 - val_acc: 0.9528 - val_loss: 0.1422\n",
      "Epoch 73/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9733 - loss: 0.0789 - val_acc: 0.9398 - val_loss: 0.1438\n",
      "Epoch 74/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9719 - loss: 0.0817 - val_acc: 0.9414 - val_loss: 0.1595\n",
      "Epoch 75/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - acc: 0.9714 - loss: 0.0828 - val_acc: 0.9504 - val_loss: 0.1525\n",
      "Epoch 76/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - acc: 0.9586 - loss: 0.1095 - val_acc: 0.9341 - val_loss: 0.1888\n",
      "Epoch 77/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9704 - loss: 0.0756 - val_acc: 0.9382 - val_loss: 0.1935\n",
      "Epoch 78/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - acc: 0.9652 - loss: 0.0932 - val_acc: 0.9349 - val_loss: 0.1984\n",
      "Epoch 79/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - acc: 0.9727 - loss: 0.0821 - val_acc: 0.9577 - val_loss: 0.1420\n",
      "Epoch 80/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9666 - loss: 0.0797 - val_acc: 0.9325 - val_loss: 0.1634\n",
      "Epoch 81/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9616 - loss: 0.0904 - val_acc: 0.9536 - val_loss: 0.1429\n",
      "Epoch 82/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9695 - loss: 0.0863 - val_acc: 0.9479 - val_loss: 0.1509\n",
      "Epoch 83/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9635 - loss: 0.1067 - val_acc: 0.9414 - val_loss: 0.1561\n",
      "Epoch 84/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9721 - loss: 0.0735 - val_acc: 0.9504 - val_loss: 0.1527\n",
      "Epoch 84: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/scripts/dl_utils.py:172: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  valores.append(float(df.iloc[3][-2]))\n",
      "/mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/scripts/dl_utils.py:176: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  valores_old.append(float(prev_df.iloc[3][-2]))\n",
      "/home/raulpg/anaconda3/envs/tfm_tf/lib/python3.11/site-packages/keras/src/legacy/preprocessing/image.py:1495: UserWarning: Expected input to be images (as Numpy array) following the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3 or 4 channels on axis 3. However, it was passed an array with shape (2865, 48, 48, 12) (12 channels).\n",
      "  warnings.warn(\n",
      "/home/raulpg/anaconda3/envs/tfm_tf/lib/python3.11/site-packages/keras/src/legacy/preprocessing/image.py:619: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3, or 4 channels on axis 3. However, it was passed an array with shape (2865, 48, 48, 12) (12 channels).\n",
      "  warnings.warn(\n",
      "/home/raulpg/anaconda3/envs/tfm_tf/lib/python3.11/site-packages/keras/src/legacy/preprocessing/image.py:619: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3, or 4 channels on axis 3. However, it was passed an array with shape (1229, 48, 48, 12) (12 channels).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raulpg/anaconda3/envs/tfm_tf/lib/python3.11/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  1/180\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m7:41\u001b[0m 3s/step - acc: 0.2500 - loss: 0.7887"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1727423084.600900   66956 graph_launch.cc:671] Fallback to op-by-op mode because memset node breaks graph update\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 27ms/step - acc: 0.6089 - loss: 0.6689 - val_acc: 0.7168 - val_loss: 0.6092\n",
      "Epoch 2/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.7569 - loss: 0.5508 - val_acc: 0.7925 - val_loss: 0.4580\n",
      "Epoch 3/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.7912 - loss: 0.4582 - val_acc: 0.8316 - val_loss: 0.3772\n",
      "Epoch 4/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.8259 - loss: 0.3784 - val_acc: 0.8234 - val_loss: 0.3741\n",
      "Epoch 5/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.8528 - loss: 0.3456 - val_acc: 0.8413 - val_loss: 0.3479\n",
      "Epoch 6/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.8692 - loss: 0.3084 - val_acc: 0.8641 - val_loss: 0.3068\n",
      "Epoch 7/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.8749 - loss: 0.3012 - val_acc: 0.8609 - val_loss: 0.2982\n",
      "Epoch 8/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.8714 - loss: 0.3130 - val_acc: 0.8739 - val_loss: 0.2987\n",
      "Epoch 9/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.8873 - loss: 0.2938 - val_acc: 0.8836 - val_loss: 0.2708\n",
      "Epoch 10/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.8773 - loss: 0.2947 - val_acc: 0.8446 - val_loss: 0.3451\n",
      "Epoch 11/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.8791 - loss: 0.2876 - val_acc: 0.8869 - val_loss: 0.3222\n",
      "Epoch 12/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.8824 - loss: 0.3001 - val_acc: 0.8609 - val_loss: 0.3229\n",
      "Epoch 13/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9055 - loss: 0.2378 - val_acc: 0.8942 - val_loss: 0.2595\n",
      "Epoch 14/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9136 - loss: 0.2381 - val_acc: 0.9121 - val_loss: 0.2238\n",
      "Epoch 15/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9205 - loss: 0.2054 - val_acc: 0.9015 - val_loss: 0.2371\n",
      "Epoch 16/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9244 - loss: 0.2039 - val_acc: 0.9032 - val_loss: 0.2270\n",
      "Epoch 17/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9336 - loss: 0.1867 - val_acc: 0.9048 - val_loss: 0.2318\n",
      "Epoch 18/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9291 - loss: 0.1873 - val_acc: 0.9178 - val_loss: 0.2099\n",
      "Epoch 19/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9215 - loss: 0.2070 - val_acc: 0.9251 - val_loss: 0.1889\n",
      "Epoch 20/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9243 - loss: 0.1847 - val_acc: 0.9097 - val_loss: 0.2281\n",
      "Epoch 21/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9300 - loss: 0.1674 - val_acc: 0.9162 - val_loss: 0.1995\n",
      "Epoch 22/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9287 - loss: 0.1844 - val_acc: 0.9121 - val_loss: 0.2128\n",
      "Epoch 23/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9295 - loss: 0.1921 - val_acc: 0.9154 - val_loss: 0.2302\n",
      "Epoch 24/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9288 - loss: 0.1859 - val_acc: 0.9203 - val_loss: 0.2030\n",
      "Epoch 25/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9331 - loss: 0.1766 - val_acc: 0.9341 - val_loss: 0.1784\n",
      "Epoch 26/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9415 - loss: 0.1552 - val_acc: 0.9300 - val_loss: 0.2072\n",
      "Epoch 27/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9428 - loss: 0.1514 - val_acc: 0.8828 - val_loss: 0.2797\n",
      "Epoch 28/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9202 - loss: 0.1979 - val_acc: 0.9235 - val_loss: 0.1968\n",
      "Epoch 29/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9362 - loss: 0.1537 - val_acc: 0.9146 - val_loss: 0.1937\n",
      "Epoch 30/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9415 - loss: 0.1634 - val_acc: 0.9276 - val_loss: 0.1765\n",
      "Epoch 31/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9396 - loss: 0.1538 - val_acc: 0.8600 - val_loss: 0.3126\n",
      "Epoch 32/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9333 - loss: 0.1650 - val_acc: 0.9056 - val_loss: 0.2224\n",
      "Epoch 33/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9405 - loss: 0.1651 - val_acc: 0.9398 - val_loss: 0.1673\n",
      "Epoch 34/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9391 - loss: 0.1583 - val_acc: 0.9341 - val_loss: 0.1867\n",
      "Epoch 35/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9373 - loss: 0.1544 - val_acc: 0.9251 - val_loss: 0.1916\n",
      "Epoch 36/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9406 - loss: 0.1507 - val_acc: 0.8975 - val_loss: 0.2788\n",
      "Epoch 37/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9320 - loss: 0.2099 - val_acc: 0.9300 - val_loss: 0.1751\n",
      "Epoch 38/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9450 - loss: 0.1411 - val_acc: 0.9235 - val_loss: 0.1911\n",
      "Epoch 39/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9501 - loss: 0.1188 - val_acc: 0.9373 - val_loss: 0.1576\n",
      "Epoch 40/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9369 - loss: 0.1403 - val_acc: 0.9268 - val_loss: 0.2058\n",
      "Epoch 41/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9498 - loss: 0.1275 - val_acc: 0.9333 - val_loss: 0.1672\n",
      "Epoch 42/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9435 - loss: 0.1322 - val_acc: 0.9292 - val_loss: 0.1870\n",
      "Epoch 43/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9529 - loss: 0.1083 - val_acc: 0.9284 - val_loss: 0.1792\n",
      "Epoch 44/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9566 - loss: 0.1105 - val_acc: 0.9373 - val_loss: 0.1874\n",
      "Epoch 45/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9557 - loss: 0.1180 - val_acc: 0.9382 - val_loss: 0.1715\n",
      "Epoch 46/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9621 - loss: 0.1160 - val_acc: 0.9292 - val_loss: 0.2173\n",
      "Epoch 47/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9474 - loss: 0.1287 - val_acc: 0.9325 - val_loss: 0.2036\n",
      "Epoch 48/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9623 - loss: 0.1102 - val_acc: 0.9398 - val_loss: 0.1798\n",
      "Epoch 49/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9656 - loss: 0.0939 - val_acc: 0.9365 - val_loss: 0.1897\n",
      "Epoch 50/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9544 - loss: 0.1183 - val_acc: 0.9260 - val_loss: 0.2038\n",
      "Epoch 51/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9469 - loss: 0.1309 - val_acc: 0.9414 - val_loss: 0.1680\n",
      "Epoch 52/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9591 - loss: 0.1130 - val_acc: 0.9414 - val_loss: 0.1539\n",
      "Epoch 53/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9491 - loss: 0.1347 - val_acc: 0.9243 - val_loss: 0.1874\n",
      "Epoch 54/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9559 - loss: 0.1154 - val_acc: 0.9439 - val_loss: 0.1473\n",
      "Epoch 55/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9639 - loss: 0.1029 - val_acc: 0.9341 - val_loss: 0.1607\n",
      "Epoch 56/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9637 - loss: 0.1045 - val_acc: 0.9382 - val_loss: 0.1576\n",
      "Epoch 57/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9615 - loss: 0.1047 - val_acc: 0.9308 - val_loss: 0.1707\n",
      "Epoch 58/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9598 - loss: 0.1010 - val_acc: 0.9439 - val_loss: 0.1441\n",
      "Epoch 59/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9677 - loss: 0.0889 - val_acc: 0.9317 - val_loss: 0.1820\n",
      "Epoch 60/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9640 - loss: 0.0980 - val_acc: 0.9300 - val_loss: 0.1766\n",
      "Epoch 61/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9628 - loss: 0.0910 - val_acc: 0.9292 - val_loss: 0.1742\n",
      "Epoch 62/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 19ms/step - acc: 0.9649 - loss: 0.0911 - val_acc: 0.9382 - val_loss: 0.2372\n",
      "Epoch 63/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9715 - loss: 0.0812 - val_acc: 0.9422 - val_loss: 0.1587\n",
      "Epoch 64/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9637 - loss: 0.0988 - val_acc: 0.9349 - val_loss: 0.1892\n",
      "Epoch 65/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9624 - loss: 0.0944 - val_acc: 0.9430 - val_loss: 0.1821\n",
      "Epoch 66/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9587 - loss: 0.1059 - val_acc: 0.9439 - val_loss: 0.1930\n",
      "Epoch 67/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9679 - loss: 0.0834 - val_acc: 0.9390 - val_loss: 0.1890\n",
      "Epoch 68/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9615 - loss: 0.1064 - val_acc: 0.9333 - val_loss: 0.2207\n",
      "Epoch 69/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9666 - loss: 0.0896 - val_acc: 0.9439 - val_loss: 0.1958\n",
      "Epoch 70/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9693 - loss: 0.0856 - val_acc: 0.9439 - val_loss: 0.1523\n",
      "Epoch 71/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9666 - loss: 0.0900 - val_acc: 0.9471 - val_loss: 0.1524\n",
      "Epoch 72/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9651 - loss: 0.1008 - val_acc: 0.9455 - val_loss: 0.1653\n",
      "Epoch 73/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9768 - loss: 0.0657 - val_acc: 0.9430 - val_loss: 0.1671\n",
      "Epoch 74/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9577 - loss: 0.1007 - val_acc: 0.9487 - val_loss: 0.1430\n",
      "Epoch 75/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9693 - loss: 0.0889 - val_acc: 0.9211 - val_loss: 0.2255\n",
      "Epoch 76/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9614 - loss: 0.0975 - val_acc: 0.9528 - val_loss: 0.1484\n",
      "Epoch 77/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9753 - loss: 0.0711 - val_acc: 0.9382 - val_loss: 0.1853\n",
      "Epoch 78/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9619 - loss: 0.0959 - val_acc: 0.9268 - val_loss: 0.2136\n",
      "Epoch 79/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9641 - loss: 0.0923 - val_acc: 0.9398 - val_loss: 0.1780\n",
      "Epoch 80/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9698 - loss: 0.0748 - val_acc: 0.9479 - val_loss: 0.1583\n",
      "Epoch 81/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9767 - loss: 0.0674 - val_acc: 0.9251 - val_loss: 0.2003\n",
      "Epoch 82/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9579 - loss: 0.1260 - val_acc: 0.9439 - val_loss: 0.1426\n",
      "Epoch 83/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9735 - loss: 0.0753 - val_acc: 0.9447 - val_loss: 0.1835\n",
      "Epoch 84/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9702 - loss: 0.0737 - val_acc: 0.9308 - val_loss: 0.1815\n",
      "Epoch 85/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9611 - loss: 0.0960 - val_acc: 0.9422 - val_loss: 0.1655\n",
      "Epoch 86/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9762 - loss: 0.0678 - val_acc: 0.9422 - val_loss: 0.1617\n",
      "Epoch 87/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9755 - loss: 0.0716 - val_acc: 0.9398 - val_loss: 0.1845\n",
      "Epoch 88/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9644 - loss: 0.0875 - val_acc: 0.9390 - val_loss: 0.1746\n",
      "Epoch 89/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9794 - loss: 0.0729 - val_acc: 0.9487 - val_loss: 0.1698\n",
      "Epoch 90/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9735 - loss: 0.0625 - val_acc: 0.9414 - val_loss: 0.1817\n",
      "Epoch 91/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - acc: 0.9722 - loss: 0.0833 - val_acc: 0.9430 - val_loss: 0.1674\n",
      "Epoch 92/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9719 - loss: 0.0668 - val_acc: 0.9479 - val_loss: 0.1951\n",
      "Epoch 93/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9521 - loss: 0.1221 - val_acc: 0.8983 - val_loss: 0.3003\n",
      "Epoch 94/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - acc: 0.9725 - loss: 0.0777 - val_acc: 0.9447 - val_loss: 0.1965\n",
      "Epoch 95/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - acc: 0.9824 - loss: 0.0566 - val_acc: 0.9520 - val_loss: 0.1542\n",
      "Epoch 96/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 21ms/step - acc: 0.9633 - loss: 0.0868 - val_acc: 0.9512 - val_loss: 0.1753\n",
      "Epoch 97/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 20ms/step - acc: 0.9788 - loss: 0.0513 - val_acc: 0.9390 - val_loss: 0.2339\n",
      "Epoch 98/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - acc: 0.9625 - loss: 0.1043 - val_acc: 0.9422 - val_loss: 0.1701\n",
      "Epoch 99/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9689 - loss: 0.0759 - val_acc: 0.9398 - val_loss: 0.2013\n",
      "Epoch 100/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9701 - loss: 0.0856 - val_acc: 0.9463 - val_loss: 0.3683\n",
      "Epoch 101/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9710 - loss: 0.0805 - val_acc: 0.9422 - val_loss: 0.1886\n",
      "Epoch 102/160\n",
      "\u001b[1m180/180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - acc: 0.9784 - loss: 0.0615 - val_acc: 0.9455 - val_loss: 0.1765\n",
      "Epoch 102: early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/scripts/dl_utils.py:172: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  valores.append(float(df.iloc[3][-2]))\n",
      "/mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/scripts/dl_utils.py:176: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  valores_old.append(float(prev_df.iloc[3][-2]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 54min 7s, sys: 2min 23s, total: 56min 31s\n",
      "Wall time: 38min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for test in tests:\n",
    "\n",
    "    # Descripcion de esta prueba\n",
    "    desc_test = test[0]\n",
    "    hiperparametros = test[1]\n",
    "    \n",
    "    # Inicializamos para dar nombre a todos los outputs que se escriban\n",
    "    hora_exec = datetime.now().strftime('%Y-%m-%d_%H-%M')\n",
    "    \n",
    "    # Creamos el nombre del directorio para guardar los modelos finales\n",
    "    path_prueba_actual = f\"../notebooks/best_models/{desc_test}_{hora_exec}/\"\n",
    "    os.makedirs(path_prueba_actual, exist_ok=True)\n",
    "    \n",
    "    # Inicializamos las variables dónde almacenaremos los resultados de cada uno de los modelos generados\n",
    "    df_alexnet = pd.DataFrame()\n",
    "    df_scratch_modified = pd.DataFrame()\n",
    "    df_vgg = pd.DataFrame()\n",
    "    df_mobile_net = pd.DataFrame()\n",
    "    \n",
    "    #Eliminamos los csvs generados en ejecuciones anteriores\n",
    "    dl_utils.limpia_directorios(\"aux_path\")\n",
    "    \n",
    "    # Recorremos la lista de configuraciones distinta generada anteriormente\n",
    "    for id_hiperparams,hiperparams in enumerate(hiperparametros):\n",
    "        for semilla in range(0,2):  \n",
    "    \n",
    "            # Limpiamos la carpeta donde se guardan los modelos\n",
    "            dl_utils.limpia_directorios(\"weights\")\n",
    "    \n",
    "            # Definimos hiperparámetros asociados a la ejecución actual\n",
    "            batch_size = hiperparams[\"batch_size\"]\n",
    "            epochs = hiperparams[\"epochs\"]\n",
    "         \n",
    "            # Dividimos el conjunto de imágenes en train y test\n",
    "            seed = np.random.randint(0, 2000,1)[0]\n",
    "            hiperparams[\"semilla\"] = seed\n",
    "            keras.utils.set_random_seed(int(seed))\n",
    "            x_train, x_test, y_train, y_test = train_test_split(x_norm, y, test_size=hiperparams[\"test_size\"], random_state=123)\n",
    "    \n",
    "            # Generamos los datagen de imágenes, empleamos las mismas imágenes en todos los modelos\n",
    "            datagen.fit(x_train)\n",
    "            train_generator = datagen.flow(x_train, y_train, batch_size=batch_size, shuffle=False)\n",
    "            test_generator = datagen.flow(x_test, y_test, batch_size=batch_size, shuffle=False)\n",
    "            \n",
    "############################################################################### ALEXNET ##########################################################################################################\n",
    "            if \"alexnet\" in modelos:\n",
    "                # ALEXNET\n",
    "                # Definimos y compilamos los modelos\n",
    "                alexnet = models.alexnet_model(input_shape)\n",
    "                start_time = time.time()\n",
    "                alexnet_results = alexnet.fit(\n",
    "                    train_generator,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=test_generator,\n",
    "                    verbose=1,\n",
    "                    shuffle=True,\n",
    "                    callbacks=dl_utils.define_callbacks(\"model_alexnet_\",hiperparams),\n",
    "                    class_weight=hiperparams[\"class_weight\"],\n",
    "                )\n",
    "                training_time_alexnet = time.time() - start_time\n",
    "                hora_actual = datetime.now().strftime('%Y-%m-%d_%H-%M')\n",
    "                # Evaluamos el modelo y lo comparamos con el mejor almacenado.\n",
    "                df_alexnet,           save_df_alexnet         = dl_utils.get_df_best_model(alexnet,test_partition_x,test_partition_y,f\"alexnet_{desc_test}_\",df_alexnet,hora_actual)\n",
    "                if save_df_alexnet:\n",
    "                    best_alexnet_model = alexnet\n",
    "                    best_alexnet_results = alexnet_results.history\n",
    "                    best_alexnet_hiperparams = [hiperparams,\n",
    "                                                id_hiperparams+1,\n",
    "                                                f'resultados_evaluacion_alexnet_{desc_test}_{hora_actual}.csv',\n",
    "                                                training_time_alexnet,\n",
    "                                                len(alexnet_results.epoch)]           \n",
    "                    \n",
    "############################################################################### SCRATCH MODIFIED ##########################################################################################################            \n",
    "            if \"scratch\" in modelos:\n",
    "                scratch_modified_model = models.scratch_modified_model(input_shape)          \n",
    "                # Modelo from scratch modificado, ampliación del modelo original\n",
    "                start_time = time.time()\n",
    "                scratch_modified_model_results = scratch_modified_model.fit(\n",
    "                    train_generator,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=test_generator,\n",
    "                    verbose=1,\n",
    "                    shuffle=True,\n",
    "                    callbacks=dl_utils.define_callbacks(\"model_scratch_modified_\",hiperparams),\n",
    "                    class_weight=hiperparams[\"class_weight\"],\n",
    "                )\n",
    "                training_time_scratch_modified_model = time.time() - start_time\n",
    "                hora_actual = datetime.now().strftime('%Y-%m-%d_%H-%M')\n",
    "                # Evaluamos el modelo y lo comparamos con el mejor almacenado.\n",
    "                df_scratch_modified, save_df_scratch_modified = dl_utils.get_df_best_model(scratch_modified_model,test_partition_x,test_partition_y,f\"scratch_modified_model_{desc_test}_\",df_scratch_modified,hora_actual)\n",
    "                if save_df_scratch_modified:\n",
    "                    best_scratch_modified_model = scratch_modified_model\n",
    "                    best_scratch_modified_model_results = scratch_modified_model_results.history\n",
    "                    best_scratch_modified_hiperparams = [hiperparams,\n",
    "                                                         id_hiperparams+1,\n",
    "                                                         f'resultados_evaluacion_scratch_modified_model_{desc_test}_{hora_actual}.csv',\n",
    "                                                         training_time_scratch_modified_model,\n",
    "                                                         len(scratch_modified_model_results.epoch)]\n",
    "                    \n",
    "############################################################################### VGG16 ##########################################################################################################\n",
    "            if \"vgg\" in modelos:\n",
    "                vgg16 = models.vgg_16_model(input_shape,first_top_model_layer)\n",
    "                # Fine-tunning con los pesos del modelo VGG16\n",
    "                start_time = time.time()\n",
    "                vgg16_results = vgg16.fit(\n",
    "                    train_generator,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=test_generator,\n",
    "                    verbose=1,\n",
    "                    shuffle=True,\n",
    "                    callbacks=dl_utils.define_callbacks(\"model_vgg16_\",hiperparams),\n",
    "                    class_weight=hiperparams[\"class_weight\"],\n",
    "                )\n",
    "                training_time_vgg16 = time.time() - start_time\n",
    "                hora_actual = datetime.now().strftime('%Y-%m-%d_%H-%M')\n",
    "                # Evaluamos el modelo y lo comparamos con el mejor almacenado.\n",
    "                df_vgg,              save_df_vgg              = dl_utils.get_df_best_model(vgg16,test_partition_x,test_partition_y,f\"vgg16_{desc_test}_\",df_vgg,hora_actual)\n",
    "                if save_df_vgg:\n",
    "                    best_vgg_model = vgg16\n",
    "                    best_vgg_model_results = vgg16_results.history\n",
    "                    best_vgg_hiperparams =[hiperparams,\n",
    "                                           id_hiperparams+1,\n",
    "                                           f'resultados_evaluacion_vgg16_{desc_test}_{hora_actual}.csv',\n",
    "                                           training_time_vgg16,\n",
    "                                           len(vgg16_results.epoch)]\n",
    "                    \n",
    "############################################################################### MOBILENET ##########################################################################################################\n",
    "            if \"mobilenet\" in modelos:\n",
    "                mobile_net = models.mobilenet_model(input_shape,first_top_model_layer)\n",
    "                # Fine-tunning con los pesos del modelo MobileNet\n",
    "                start_time = time.time()\n",
    "                mobile_net_results = mobile_net.fit(\n",
    "                    train_generator,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=test_generator,\n",
    "                    verbose=1,\n",
    "                    shuffle=True,\n",
    "                    callbacks=dl_utils.define_callbacks(\"model_mobilenet_\",hiperparams),\n",
    "                    class_weight=hiperparams[\"class_weight\"],\n",
    "                )\n",
    "                training_time_mobile_net = time.time() - start_time\n",
    "                hora_actual = datetime.now().strftime('%Y-%m-%d_%H-%M')\n",
    "                # Evaluamos el modelo y lo comparamos con el mejor almacenado.\n",
    "                df_mobile_net,       save_df_mobile_net       = dl_utils.get_df_best_model(mobile_net,test_partition_x,test_partition_y,f\"mobile_net_{desc_test}_\",df_mobile_net,hora_actual)\n",
    "                # Si el modelo actual es mejor que el almacenado, guardamos su información.      \n",
    "                if save_df_mobile_net:\n",
    "                    best_mobile_net_model = mobile_net\n",
    "                    best_mobile_net_model_results = mobile_net_results.history\n",
    "                    best_mobile_net_hiperparams = [hiperparams,\n",
    "                                                   id_hiperparams+1,\n",
    "                                                   f'resultados_evaluacion_mobile_net_{desc_test}_{hora_actual}.csv',\n",
    "                                                   training_time_mobile_net,\n",
    "                                                   len(mobile_net_results.epoch)]\n",
    "                    \n",
    "############################################################################################################################################################################\n",
    "            # Limpiamos variables\n",
    "            if \"alexnet\" in modelos:\n",
    "                del alexnet\n",
    "                del alexnet_results\n",
    "            if \"scratch\" in modelos:\n",
    "                del scratch_modified_model\n",
    "                del scratch_modified_model_results\n",
    "            if \"vgg\" in modelos:\n",
    "                del vgg16\n",
    "                del vgg16_results\n",
    "            if \"mobilenet\" in modelos:\n",
    "                del mobile_net\n",
    "                del mobile_net_results\n",
    "            del train_generator\n",
    "            del test_generator\n",
    "            K.clear_session()\n",
    "            gc.collect()        \n",
    "\n",
    "    if \"alexnet\" in modelos:\n",
    "        dl_utils.save_models(best_alexnet_model,\n",
    "                             best_alexnet_results,\n",
    "                             best_alexnet_hiperparams,\n",
    "                             hora_exec,\n",
    "                             f'alexnet_{desc_test}',\n",
    "                             path_prueba_actual)\n",
    "    if \"scratch\" in modelos:\n",
    "        dl_utils.save_models(best_scratch_modified_model,\n",
    "                             best_scratch_modified_model_results,\n",
    "                             best_scratch_modified_hiperparams,\n",
    "                             hora_exec,\n",
    "                             f'scratch_modified_model_{desc_test}',\n",
    "                             path_prueba_actual)\n",
    "    if \"vgg\" in modelos:\n",
    "        dl_utils.save_models(best_vgg_model,\n",
    "                         best_vgg_model_results,\n",
    "                         best_vgg_hiperparams,\n",
    "                         hora_exec,\n",
    "                         f'vgg16_{desc_test}',\n",
    "                         path_prueba_actual)\n",
    "    if \"mobilenet\" in modelos:\n",
    "        dl_utils.save_models(best_mobile_net_model,\n",
    "                         best_mobile_net_model_results,\n",
    "                         best_mobile_net_hiperparams,\n",
    "                         hora_exec,\n",
    "                         f'mobile_net_{desc_test}',\n",
    "                         path_prueba_actual)\n",
    "  \n",
    "    # Movemos los archivos asociados a los resultados\n",
    "    paths_to_move = []\n",
    "    if \"alexnet\" in modelos:\n",
    "        paths_to_move.append(best_alexnet_hiperparams[2])\n",
    "    if \"scratch\" in modelos:\n",
    "        paths_to_move.append(best_scratch_modified_hiperparams[2])\n",
    "    if \"vgg\" in modelos:\n",
    "        paths_to_move.append(best_vgg_hiperparams[2])\n",
    "    if \"mobilenet\" in modelos:\n",
    "        paths_to_move.append(best_mobile_net_hiperparams[2])\n",
    "        \n",
    "    dl_utils.obtener_tablas_resultado(path_prueba_actual,paths_to_move)\n",
    "    \n",
    "    # Limpiamos variables auxiliares\n",
    "    if \"alexnet\" in modelos:\n",
    "        del best_alexnet_model\n",
    "        del best_alexnet_results\n",
    "        del best_alexnet_hiperparams\n",
    "    if \"scratch\" in modelos:    \n",
    "        del best_scratch_modified_model\n",
    "        del best_scratch_modified_model_results\n",
    "        del best_scratch_modified_hiperparams\n",
    "    if \"vgg\" in modelos:    \n",
    "        del best_vgg_model\n",
    "        del best_vgg_model_results\n",
    "        del best_vgg_hiperparams\n",
    "    if \"mobilenet\" in modelos:    \n",
    "        del best_mobile_net_model\n",
    "        del best_mobile_net_model_results\n",
    "        del best_mobile_net_hiperparams\n",
    "    K.clear_session()\n",
    "    gc.collect() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "bec97cbb607180795486aa419a93884fe3d0b55501c3e5098d64200fe61c3ffb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
