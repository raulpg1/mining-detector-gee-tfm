{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Notebook for model training\n",
    "\n",
    "### Training Flow\n",
    "\n",
    "Load Training Data:\n",
    "- Load set of input data and label files\n",
    "- Prefilter positive set only to rule out heavily-masked patches\n",
    "- Create train/test set\n",
    "- Define augmentation parameters\n",
    "\n",
    "Train Model:\n",
    "- Define model architecture\n",
    "- Compile model\n",
    "- Train and evaluate model\n",
    "- Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-21 10:48:46.057545: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-09-21 10:48:46.201818: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-21 10:48:46.201842: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-21 10:48:46.226114: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-21 10:48:46.277684: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-21 10:48:46.978193: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "from datetime import datetime\n",
    "import time\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import io\n",
    "from contextlib import redirect_stdout\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, Conv2D\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "parent_dir = os.path.split(os.getcwd())[0]\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.insert(0, parent_dir)\n",
    "\n",
    "from scripts import dl_utils\n",
    "from scripts import viz_tools\n",
    "from scripts import models\n",
    "\n",
    "import gc\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# export TF_GPU_ALLOCATOR=cuda_malloc_async\n",
    "os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "716508a79e844d32ada6f5667f54059c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4549 samples loaded\n",
      "1891 positive samples\n",
      "2658 negative samples\n"
     ]
    }
   ],
   "source": [
    "resolution = 48\n",
    "\n",
    "data_files = [\n",
    "    \"amazonas_2020_thresh_0.5_2_negatives_2019-01-01_2020-01-01_patch_arrays.pkl\",\n",
    "    \"amazonas_2020_thresh_0.8_sumbsample_3_positives_2019-01-01_2020-01-01_patch_arrays.pkl\",\n",
    "    \"MinesPos2018-2020Sentinel_points_2019-01-01_2020-01-01_patch_arrays.pkl\",\n",
    "    \"bolivar_2020_thresh_0.8_sumbsample_5_positives_2019-01-01_2020-01-01_patch_arrays.pkl\",\n",
    "    \"full_amazon_v9_negatives_2019-01-01_2020-01-01_patch_arrays.pkl\",\n",
    "    \"v2.4_amazon_positives_2019-01-01_2020-01-01_patch_arrays.pkl\",\n",
    "    \"v2.6_amazon_thresh_0.8_negatives_2019-01-01_2020-01-01_patch_arrays.pkl\",\n",
    "    \"v2.0_bolivar_negatives_2019-01-01_2020-01-01_patch_arrays.pkl\",\n",
    "    \"riverbank_negatives_2019-01-01_2020-01-01_patch_arrays.pkl\",\n",
    "    \"bolivar_2020_thresh_0.8_1_negatives_2019-01-01_2020-01-01_patch_arrays.pkl\",\n",
    "    \"v2.1.1_bolivar_negatives_2019-01-01_2020-01-01_patch_arrays.pkl\",\n",
    "    \"v2.1_bolivar_positives_2019-01-01_2020-01-01_patch_arrays.pkl\",\n",
    "    \"v2.4_amazonas_negatives_2019-01-01_2020-01-01_patch_arrays.pkl\",\n",
    "    \"v2.4_amazon_negatives_2019-01-01_2020-01-01_patch_arrays.pkl\",\n",
    "    \"v2.6_amazon_negatives_2019-01-01_2020-01-01_patch_arrays.pkl\",\n",
    "    \"v2.6_amazon_negatives_v2_2019-01-01_2020-01-01_patch_arrays.pkl\",\n",
    "    \"v3.1_2023_negatives_2023-01-01_2024-01-01_patch_arrays.pkl\",\n",
    "    \"amazon_all_48px_v3.1_2023_positives_0.999_2023-01-01_2024-01-01_patch_arrays.pkl\",\n",
    "    \"v3.2_2023_negatives_2023-01-01_2024-01-01_patch_arrays.pkl\",\n",
    "    \"v3.3_2023_positives_2023-01-01_2024-01-01_patch_arrays.pkl\",\n",
    "    \"v3.4_2023_negatives_2023-01-01_2024-01-01_patch_arrays.pkl\",\n",
    "    \"v3.5_2023_negatives_2023-01-01_2024-01-01_patch_arrays.pkl\",\n",
    "    \"v3.6_2023_positives_2023-01-01_2024-01-01_patch_arrays.pkl\"\n",
    "    \n",
    "    ]\n",
    "\n",
    "label_files = [\n",
    "    \"amazonas_2020_thresh_0.5_2_negatives_2019-01-01_2020-01-01_patch_array_labels.pkl\",\n",
    "    \"amazonas_2020_thresh_0.8_sumbsample_3_positives_2019-01-01_2020-01-01_patch_array_labels.pkl\",\n",
    "    \"MinesPos2018-2020Sentinel_points_2019-01-01_2020-01-01_patch_array_labels.pkl\",\n",
    "    \"bolivar_2020_thresh_0.8_sumbsample_5_positives_2019-01-01_2020-01-01_patch_array_labels.pkl\",\n",
    "    \"full_amazon_v9_negatives_2019-01-01_2020-01-01_patch_array_labels.pkl\",\n",
    "    \"v2.4_amazon_positives_2019-01-01_2020-01-01_patch_array_labels.pkl\",\n",
    "    \"v2.6_amazon_thresh_0.8_negatives_2019-01-01_2020-01-01_patch_array_labels.pkl\",\n",
    "    \"v2.0_bolivar_negatives_2019-01-01_2020-01-01_patch_array_labels.pkl\",\n",
    "    \"riverbank_negatives_2019-01-01_2020-01-01_patch_array_labels.pkl\",\n",
    "    \"bolivar_2020_thresh_0.8_1_negatives_2019-01-01_2020-01-01_patch_array_labels.pkl\",\n",
    "    \"v2.1.1_bolivar_negatives_2019-01-01_2020-01-01_patch_array_labels.pkl\",\n",
    "    \"v2.1_bolivar_positives_2019-01-01_2020-01-01_patch_array_labels.pkl\",\n",
    "    \"v2.4_amazonas_negatives_2019-01-01_2020-01-01_patch_array_labels.pkl\",\n",
    "    \"v2.4_amazon_negatives_2019-01-01_2020-01-01_patch_array_labels.pkl\",\n",
    "    \"v2.6_amazon_negatives_2019-01-01_2020-01-01_patch_array_labels.pkl\",\n",
    "    \"v2.6_amazon_negatives_v2_2019-01-01_2020-01-01_patch_array_labels.pkl\",\n",
    "    \"v3.1_2023_negatives_2023-01-01_2024-01-01_patch_array_labels.pkl\",\n",
    "    \"amazon_all_48px_v3.1_2023_positives_0.999_2023-01-01_2024-01-01_patch_array_labels.pkl\",\n",
    "    \"v3.2_2023_negatives_2023-01-01_2024-01-01_patch_array_labels.pkl\",\n",
    "    \"v3.3_2023_positives_2023-01-01_2024-01-01_patch_array_labels.pkl\",\n",
    "    \"v3.4_2023_negatives_2023-01-01_2024-01-01_patch_array_labels.pkl\",\n",
    "    \"v3.5_2023_negatives_2023-01-01_2024-01-01_patch_array_labels.pkl\",\n",
    "    \"v3.6_2023_positives_2023-01-01_2024-01-01_patch_array_labels.pkl\"\n",
    "    \n",
    "    \n",
    "]\n",
    "\n",
    "patches = []\n",
    "labels = []\n",
    "\n",
    "data_dir = os.path.join('..', 'data', 'training_data', f\"{resolution}_px\")\n",
    "\n",
    "for data, label in tqdm(zip(data_files, label_files), total=len(data_files)):\n",
    "    with open(os.path.join(data_dir, data), 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "        for elem in data:\n",
    "            #patch = dl_utils.pad_patch(elem, resolution)\n",
    "            patches.append(elem)\n",
    "    with open(os.path.join(data_dir, label), 'rb') as f:\n",
    "        label = pickle.load(f)\n",
    "        labels = np.concatenate((labels, label))\n",
    "\n",
    "patches = np.array(patches)\n",
    "negative_patches = patches[labels == 0]\n",
    "positive_patches = patches[labels == 1]\n",
    "\n",
    "print(len(patches), \"samples loaded\")\n",
    "print(sum(labels == 1), \"positive samples\")\n",
    "print(sum(labels == 0), \"negative samples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 64\n",
    "indices = np.random.randint(0, len(patches), num_samples)\n",
    "# viz_tools.plot_image_grid(patches[indices], labels=[int(label) for label in labels[indices]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_black(data, mask_limit=0.1, return_rejects=False):\n",
    "    masked_fraction = np.array([np.sum(np.mean(patch, axis=-1) < 10) / np.size(np.mean(patch, axis=-1)) for patch in data])\n",
    "    filtered_data = data[masked_fraction < mask_limit]\n",
    "    print(f\"{len(filtered_data) / len(data) :.1%} of data below brightness limit\")\n",
    "    if return_rejects:\n",
    "        rejected_data = data[masked_fraction >= mask_limit]\n",
    "        return filtered_data, rejected_data\n",
    "    else:\n",
    "        return filtered_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99.9% of data below brightness limit\n"
     ]
    }
   ],
   "source": [
    "# Filter positive pixels that are masked beyond a threshold. Don't want to give positive examples of cloud-masked patches\n",
    "filtered_positives, positive_rejects = filter_black(positive_patches, mask_limit = 0.1, return_rejects=True)\n",
    "if len(positive_rejects) > 0:\n",
    "    num_samples = 16**2\n",
    "    if len(positive_rejects) < num_samples:\n",
    "        num_samples = len(positive_rejects)\n",
    "    indices = np.random.randint(0, len(positive_rejects), num_samples)\n",
    "    # viz_tools.plot_numpy_grid(positive_rejects[indices,:,:,3:0:-1] / 3000)\n",
    "    # plt.title(\"Positive Masked Rejects\")\n",
    "    # plt.show()\n",
    "\n",
    "num_samples = 25 ** 2\n",
    "indices = np.random.randint(0, len(filtered_positives), num_samples)\n",
    "# fig = viz_tools.plot_numpy_grid(filtered_positives[indices,:,:,3:0:-1] / 3000)\n",
    "# plt.title('Positive Filtered Samples')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0% of data below brightness limit\n"
     ]
    }
   ],
   "source": [
    "filtered_negatives, negative_rejects = filter_black(negative_patches, mask_limit = 0.6, return_rejects=True)\n",
    "if len(negative_rejects) > 0:\n",
    "    num_samples = 16**2\n",
    "    if len(positive_rejects) < num_samples:\n",
    "        num_samples = len(positive_rejects)\n",
    "    indices = np.random.randint(0, len(negative_rejects), num_samples)\n",
    "    # viz_tools.plot_numpy_grid(negative_rejects[indices,:,:,3:0:-1] / 3000)\n",
    "    # plt.title(\"Negative Mask Rejects\")\n",
    "    # plt.show()\n",
    "\n",
    "num_samples = 25 ** 2\n",
    "indices = np.random.randint(0, len(filtered_negatives), num_samples)\n",
    "# fig = viz_tools.plot_numpy_grid(filtered_negatives[indices,:,:,3:0:-1] / 3000)\n",
    "# plt.title('Negative Filtered Samples')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for RGBIR, x = normalize(np.copy(images[:,:,:,[1,2,3,8]]))\n",
    "x = np.concatenate((filtered_negatives, filtered_positives))\n",
    "y = np.concatenate((np.zeros(len(filtered_negatives)), np.ones(len(filtered_positives))))\n",
    "x, y = shuffle(x, y, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raulpg/anaconda3/envs/tfm_tf/lib/python3.11/site-packages/keras/src/preprocessing/image.py:766: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3, or 4 channels on axis 3. However, it was passed an array with shape (4548, 48, 48, 12) (12 channels).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1800x1800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "augmentation_parameters = {\n",
    "    'featurewise_center': False,\n",
    "    'rotation_range': 360,\n",
    "    'width_shift_range': [0.9, 1.1],\n",
    "    'height_shift_range': [0.9, 1.1],\n",
    "    'shear_range': 10,\n",
    "    'zoom_range': [0.9, 1.1],\n",
    "    'vertical_flip': True,\n",
    "    'horizontal_flip': True,\n",
    "    # Fill options: \"constant\", \"nearest\", \"reflect\" or \"wrap\"\n",
    "    'fill_mode': 'reflect'\n",
    "}\n",
    "\n",
    "datagen = ImageDataGenerator(**augmentation_parameters)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12,12), facecolor=(1,1,1), dpi=150)\n",
    "aug_img, aug_labels = datagen.flow(x, y, batch_size=64).next()\n",
    "# viz_tools.plot_image_grid(aug_img, labels=[int(l) for l in aug_labels], norm=True);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_norm = np.clip(np.array(x.astype(\"float32\") / 10000), 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partimos el 10% del dataset total para test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_size = len(y)\n",
    "test_partition = int(dataset_size*0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de clases positivas en el dataset de training es de 1705, número de clases negativas 2389\n"
     ]
    }
   ],
   "source": [
    "num_positive_samples_train = sum(y[test_partition:]==1)\n",
    "num_negative_samples_train = sum(y[test_partition:]==0)\n",
    "\n",
    "print(f\"Número de clases positivas en el dataset de training es de {num_positive_samples_train}, número de clases negativas {num_negative_samples_train}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminamos estos samples del dataset de validacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_partition_x = x_norm[:test_partition]\n",
    "test_partition_y = y[:test_partition]\n",
    "\n",
    "x_norm = x_norm[test_partition:]\n",
    "y = y[test_partition:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento de la arquitectura original con los parámetros originales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hiper_params_original_test = {\"class_weight\" : {0: 1, 1: 1},\n",
    "                              \"batch_size\" : 32,\n",
    "                              \"epochs\" : 160,\n",
    "                              \"test_size\" : 0.3\n",
    "                           }\n",
    "input_shape = (48,48,12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento\n",
    "- Entrenamos el modelo original para 5 semillas distintas. Se elige el mejor modelo para poder compararlo con los demás.\n",
    "- Total de modelos construidos = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-21 10:48:53.085960: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-09-21 10:48:53.160226: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-09-21 10:48:53.160263: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-09-21 10:48:53.162493: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-09-21 10:48:53.162523: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-09-21 10:48:53.162537: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-09-21 10:48:53.294470: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-09-21 10:48:53.294508: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-09-21 10:48:53.294512: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2022] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-09-21 10:48:53.294522: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:236] Using CUDA malloc Async allocator for GPU: 0\n",
      "2024-09-21 10:48:53.294614: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-09-21 10:48:53.294631: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5529 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Ti, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raulpg/anaconda3/envs/tfm_tf/lib/python3.11/site-packages/keras/src/preprocessing/image.py:766: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3, or 4 channels on axis 3. However, it was passed an array with shape (2865, 48, 48, 12) (12 channels).\n",
      "  warnings.warn(\n",
      "2024-09-21 10:48:54.304253: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8907\n",
      "2024-09-21 10:48:54.422494: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-09-21 10:48:54.723523: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-09-21 10:48:55.311775: I external/local_xla/xla/service/service.cc:168] XLA service 0x7fc6443cc6e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-09-21 10:48:55.311802: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4060 Ti, Compute Capability 8.9\n",
      "2024-09-21 10:48:55.320038: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1726908535.379532   37010 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 5s 24ms/step - loss: 0.6881 - acc: 0.5679 - val_loss: 0.6765 - val_acc: 0.5899\n",
      "Epoch 2/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.6496 - acc: 0.6258 - val_loss: 0.5860 - val_acc: 0.6981\n",
      "Epoch 3/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.5693 - acc: 0.7316 - val_loss: 0.5424 - val_acc: 0.6981\n",
      "Epoch 4/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.5377 - acc: 0.7466 - val_loss: 0.5032 - val_acc: 0.7648\n",
      "Epoch 5/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.5112 - acc: 0.7668 - val_loss: 0.4789 - val_acc: 0.7673\n",
      "Epoch 6/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.4860 - acc: 0.7812 - val_loss: 0.4574 - val_acc: 0.7673\n",
      "Epoch 7/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.5039 - acc: 0.7773 - val_loss: 0.4638 - val_acc: 0.7909\n",
      "Epoch 8/160\n",
      "90/90 [==============================] - 3s 31ms/step - loss: 0.4642 - acc: 0.7874 - val_loss: 0.4437 - val_acc: 0.7925\n",
      "Epoch 9/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.4589 - acc: 0.8150 - val_loss: 0.4213 - val_acc: 0.7998\n",
      "Epoch 10/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.4269 - acc: 0.8143 - val_loss: 0.4393 - val_acc: 0.8120\n",
      "Epoch 11/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.4154 - acc: 0.8283 - val_loss: 0.3943 - val_acc: 0.8080\n",
      "Epoch 12/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.3943 - acc: 0.8318 - val_loss: 0.3662 - val_acc: 0.8324\n",
      "Epoch 13/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.3729 - acc: 0.8408 - val_loss: 0.3817 - val_acc: 0.8153\n",
      "Epoch 14/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.3647 - acc: 0.8555 - val_loss: 0.3279 - val_acc: 0.8511\n",
      "Epoch 15/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.3719 - acc: 0.8485 - val_loss: 0.3264 - val_acc: 0.8535\n",
      "Epoch 16/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.3713 - acc: 0.8454 - val_loss: 0.3525 - val_acc: 0.8397\n",
      "Epoch 17/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.3408 - acc: 0.8531 - val_loss: 0.3244 - val_acc: 0.8535\n",
      "Epoch 18/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.3234 - acc: 0.8674 - val_loss: 0.2936 - val_acc: 0.8723\n",
      "Epoch 19/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.3451 - acc: 0.8614 - val_loss: 0.3571 - val_acc: 0.8356\n",
      "Epoch 20/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.3100 - acc: 0.8754 - val_loss: 0.3194 - val_acc: 0.8641\n",
      "Epoch 21/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.3126 - acc: 0.8757 - val_loss: 0.2795 - val_acc: 0.8731\n",
      "Epoch 22/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.2841 - acc: 0.8845 - val_loss: 0.2820 - val_acc: 0.8731\n",
      "Epoch 23/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.2925 - acc: 0.8817 - val_loss: 0.2878 - val_acc: 0.8747\n",
      "Epoch 24/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.2836 - acc: 0.8862 - val_loss: 0.2601 - val_acc: 0.8934\n",
      "Epoch 25/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.2836 - acc: 0.8911 - val_loss: 0.2510 - val_acc: 0.8885\n",
      "Epoch 26/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.2733 - acc: 0.8960 - val_loss: 0.2597 - val_acc: 0.8853\n",
      "Epoch 27/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.2597 - acc: 0.8949 - val_loss: 0.2292 - val_acc: 0.8975\n",
      "Epoch 28/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.2643 - acc: 0.9002 - val_loss: 0.4076 - val_acc: 0.8291\n",
      "Epoch 29/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.2705 - acc: 0.8946 - val_loss: 0.2338 - val_acc: 0.9024\n",
      "Epoch 30/160\n",
      "90/90 [==============================] - 3s 32ms/step - loss: 0.2523 - acc: 0.9065 - val_loss: 0.2863 - val_acc: 0.8893\n",
      "Epoch 31/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.2541 - acc: 0.9023 - val_loss: 0.2329 - val_acc: 0.9056\n",
      "Epoch 32/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.2540 - acc: 0.9086 - val_loss: 0.2337 - val_acc: 0.9048\n",
      "Epoch 33/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.2285 - acc: 0.9106 - val_loss: 0.3600 - val_acc: 0.8641\n",
      "Epoch 34/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.2671 - acc: 0.8942 - val_loss: 0.2420 - val_acc: 0.8950\n",
      "Epoch 35/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.2514 - acc: 0.9058 - val_loss: 0.2024 - val_acc: 0.9162\n",
      "Epoch 36/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.2146 - acc: 0.9201 - val_loss: 0.2074 - val_acc: 0.9203\n",
      "Epoch 37/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.2285 - acc: 0.9155 - val_loss: 0.2078 - val_acc: 0.9146\n",
      "Epoch 38/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.2279 - acc: 0.9096 - val_loss: 0.2032 - val_acc: 0.9268\n",
      "Epoch 39/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.2173 - acc: 0.9208 - val_loss: 0.1882 - val_acc: 0.9243\n",
      "Epoch 40/160\n",
      "90/90 [==============================] - 2s 28ms/step - loss: 0.2095 - acc: 0.9187 - val_loss: 0.1868 - val_acc: 0.9243\n",
      "Epoch 41/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.2231 - acc: 0.9169 - val_loss: 0.2203 - val_acc: 0.9064\n",
      "Epoch 42/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.2244 - acc: 0.9204 - val_loss: 0.1932 - val_acc: 0.9243\n",
      "Epoch 43/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1929 - acc: 0.9291 - val_loss: 0.1782 - val_acc: 0.9317\n",
      "Epoch 44/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.2068 - acc: 0.9222 - val_loss: 0.1841 - val_acc: 0.9284\n",
      "Epoch 45/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.2013 - acc: 0.9239 - val_loss: 0.2011 - val_acc: 0.9211\n",
      "Epoch 46/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.2077 - acc: 0.9211 - val_loss: 0.1923 - val_acc: 0.9243\n",
      "Epoch 47/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.2014 - acc: 0.9250 - val_loss: 0.2209 - val_acc: 0.9121\n",
      "Epoch 48/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.2039 - acc: 0.9264 - val_loss: 0.2074 - val_acc: 0.9211\n",
      "Epoch 49/160\n",
      "90/90 [==============================] - 2s 28ms/step - loss: 0.2024 - acc: 0.9260 - val_loss: 0.2831 - val_acc: 0.8861\n",
      "Epoch 50/160\n",
      "90/90 [==============================] - 2s 28ms/step - loss: 0.2018 - acc: 0.9215 - val_loss: 0.1891 - val_acc: 0.9251\n",
      "Epoch 51/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1907 - acc: 0.9305 - val_loss: 0.2045 - val_acc: 0.9203\n",
      "Epoch 52/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1975 - acc: 0.9298 - val_loss: 0.1553 - val_acc: 0.9422\n",
      "Epoch 53/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.1840 - acc: 0.9302 - val_loss: 0.1781 - val_acc: 0.9317\n",
      "Epoch 54/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1816 - acc: 0.9340 - val_loss: 0.1801 - val_acc: 0.9292\n",
      "Epoch 55/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1686 - acc: 0.9417 - val_loss: 0.1744 - val_acc: 0.9300\n",
      "Epoch 56/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1873 - acc: 0.9330 - val_loss: 0.1646 - val_acc: 0.9365\n",
      "Epoch 57/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.1762 - acc: 0.9445 - val_loss: 0.1888 - val_acc: 0.9357\n",
      "Epoch 58/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1923 - acc: 0.9351 - val_loss: 0.2008 - val_acc: 0.9211\n",
      "Epoch 59/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1735 - acc: 0.9347 - val_loss: 0.1647 - val_acc: 0.9349\n",
      "Epoch 60/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1783 - acc: 0.9403 - val_loss: 0.2059 - val_acc: 0.9203\n",
      "Epoch 61/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1888 - acc: 0.9354 - val_loss: 0.1652 - val_acc: 0.9390\n",
      "Epoch 62/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1696 - acc: 0.9410 - val_loss: 0.2095 - val_acc: 0.9243\n",
      "Epoch 63/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1655 - acc: 0.9455 - val_loss: 0.1612 - val_acc: 0.9414\n",
      "Epoch 64/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1565 - acc: 0.9400 - val_loss: 0.2185 - val_acc: 0.9178\n",
      "Epoch 65/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1722 - acc: 0.9358 - val_loss: 0.1819 - val_acc: 0.9251\n",
      "Epoch 66/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1563 - acc: 0.9462 - val_loss: 0.1864 - val_acc: 0.9268\n",
      "Epoch 67/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1975 - acc: 0.9243 - val_loss: 0.2064 - val_acc: 0.9194\n",
      "Epoch 68/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1747 - acc: 0.9361 - val_loss: 0.1670 - val_acc: 0.9357\n",
      "Epoch 69/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1650 - acc: 0.9417 - val_loss: 0.1825 - val_acc: 0.9300\n",
      "Epoch 70/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1536 - acc: 0.9466 - val_loss: 0.2097 - val_acc: 0.9227\n",
      "Epoch 71/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.1788 - acc: 0.9372 - val_loss: 0.1540 - val_acc: 0.9398\n",
      "Epoch 72/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1692 - acc: 0.9400 - val_loss: 0.2936 - val_acc: 0.8812\n",
      "Epoch 73/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1984 - acc: 0.9201 - val_loss: 0.1947 - val_acc: 0.9260\n",
      "Epoch 74/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1642 - acc: 0.9469 - val_loss: 0.1694 - val_acc: 0.9382\n",
      "Epoch 75/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1534 - acc: 0.9403 - val_loss: 0.2149 - val_acc: 0.9186\n",
      "Epoch 76/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.1617 - acc: 0.9400 - val_loss: 0.1957 - val_acc: 0.9276\n",
      "Epoch 77/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1492 - acc: 0.9417 - val_loss: 0.1774 - val_acc: 0.9341\n",
      "Epoch 78/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1606 - acc: 0.9449 - val_loss: 0.1401 - val_acc: 0.9455\n",
      "Epoch 79/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1668 - acc: 0.9435 - val_loss: 0.1485 - val_acc: 0.9447\n",
      "Epoch 80/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1565 - acc: 0.9428 - val_loss: 0.1964 - val_acc: 0.9284\n",
      "Epoch 81/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1454 - acc: 0.9483 - val_loss: 0.1558 - val_acc: 0.9398\n",
      "Epoch 82/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1430 - acc: 0.9473 - val_loss: 0.1840 - val_acc: 0.9317\n",
      "Epoch 83/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1385 - acc: 0.9504 - val_loss: 0.1687 - val_acc: 0.9365\n",
      "Epoch 84/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1425 - acc: 0.9483 - val_loss: 0.1352 - val_acc: 0.9512\n",
      "Epoch 85/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.1547 - acc: 0.9445 - val_loss: 0.1400 - val_acc: 0.9487\n",
      "Epoch 86/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1422 - acc: 0.9518 - val_loss: 0.1635 - val_acc: 0.9390\n",
      "Epoch 87/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1407 - acc: 0.9536 - val_loss: 0.2096 - val_acc: 0.9219\n",
      "Epoch 88/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1499 - acc: 0.9466 - val_loss: 0.1552 - val_acc: 0.9422\n",
      "Epoch 89/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1324 - acc: 0.9536 - val_loss: 0.1720 - val_acc: 0.9333\n",
      "Epoch 90/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1422 - acc: 0.9487 - val_loss: 0.1640 - val_acc: 0.9390\n",
      "Epoch 91/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1379 - acc: 0.9553 - val_loss: 0.1832 - val_acc: 0.9382\n",
      "Epoch 92/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1581 - acc: 0.9435 - val_loss: 0.1940 - val_acc: 0.9333\n",
      "Epoch 93/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1500 - acc: 0.9462 - val_loss: 0.1353 - val_acc: 0.9463\n",
      "Epoch 94/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1653 - acc: 0.9382 - val_loss: 0.1393 - val_acc: 0.9447\n",
      "Epoch 95/160\n",
      "90/90 [==============================] - 3s 31ms/step - loss: 0.1368 - acc: 0.9515 - val_loss: 0.1655 - val_acc: 0.9430\n",
      "Epoch 96/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1358 - acc: 0.9515 - val_loss: 0.2023 - val_acc: 0.9154\n",
      "Epoch 97/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1539 - acc: 0.9445 - val_loss: 0.1471 - val_acc: 0.9422\n",
      "Epoch 98/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1254 - acc: 0.9564 - val_loss: 0.1736 - val_acc: 0.9382\n",
      "Epoch 99/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1339 - acc: 0.9490 - val_loss: 0.1530 - val_acc: 0.9398\n",
      "Epoch 100/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1346 - acc: 0.9536 - val_loss: 0.1355 - val_acc: 0.9520\n",
      "Epoch 101/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1289 - acc: 0.9518 - val_loss: 0.1705 - val_acc: 0.9292\n",
      "Epoch 102/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.1312 - acc: 0.9578 - val_loss: 0.1961 - val_acc: 0.9235\n",
      "Epoch 103/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.1392 - acc: 0.9515 - val_loss: 0.1748 - val_acc: 0.9390\n",
      "Epoch 104/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1220 - acc: 0.9581 - val_loss: 0.1314 - val_acc: 0.9479\n",
      "Epoch 105/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1170 - acc: 0.9588 - val_loss: 0.1580 - val_acc: 0.9390\n",
      "Epoch 106/160\n",
      "90/90 [==============================] - 2s 28ms/step - loss: 0.1236 - acc: 0.9567 - val_loss: 0.2333 - val_acc: 0.9170\n",
      "Epoch 107/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1345 - acc: 0.9483 - val_loss: 0.1310 - val_acc: 0.9512\n",
      "Epoch 108/160\n",
      "90/90 [==============================] - 2s 28ms/step - loss: 0.1277 - acc: 0.9532 - val_loss: 0.1222 - val_acc: 0.9552\n",
      "Epoch 109/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.1083 - acc: 0.9592 - val_loss: 0.1676 - val_acc: 0.9373\n",
      "Epoch 110/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1236 - acc: 0.9550 - val_loss: 0.1442 - val_acc: 0.9422\n",
      "Epoch 111/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1231 - acc: 0.9564 - val_loss: 0.1684 - val_acc: 0.9447\n",
      "Epoch 112/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.1302 - acc: 0.9546 - val_loss: 0.1306 - val_acc: 0.9536\n",
      "Epoch 113/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.1305 - acc: 0.9557 - val_loss: 0.1559 - val_acc: 0.9406\n",
      "Epoch 114/160\n",
      "90/90 [==============================] - 2s 28ms/step - loss: 0.1252 - acc: 0.9585 - val_loss: 0.1246 - val_acc: 0.9544\n",
      "Epoch 115/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.1087 - acc: 0.9616 - val_loss: 0.1663 - val_acc: 0.9447\n",
      "Epoch 116/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1217 - acc: 0.9588 - val_loss: 0.1323 - val_acc: 0.9552\n",
      "Epoch 117/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1262 - acc: 0.9532 - val_loss: 0.1585 - val_acc: 0.9382\n",
      "Epoch 118/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.1156 - acc: 0.9588 - val_loss: 0.1407 - val_acc: 0.9487\n",
      "Epoch 119/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1299 - acc: 0.9529 - val_loss: 0.1263 - val_acc: 0.9512\n",
      "Epoch 120/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1209 - acc: 0.9602 - val_loss: 0.1414 - val_acc: 0.9512\n",
      "Epoch 121/160\n",
      "90/90 [==============================] - 3s 32ms/step - loss: 0.1165 - acc: 0.9588 - val_loss: 0.2337 - val_acc: 0.9113\n",
      "Epoch 122/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1403 - acc: 0.9476 - val_loss: 0.1369 - val_acc: 0.9496\n",
      "Epoch 123/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1069 - acc: 0.9606 - val_loss: 0.1513 - val_acc: 0.9414\n",
      "Epoch 124/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.1086 - acc: 0.9634 - val_loss: 0.1663 - val_acc: 0.9365\n",
      "Epoch 125/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1099 - acc: 0.9606 - val_loss: 0.1226 - val_acc: 0.9439\n",
      "Epoch 126/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1124 - acc: 0.9623 - val_loss: 0.2080 - val_acc: 0.9146\n",
      "Epoch 127/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1280 - acc: 0.9518 - val_loss: 0.1353 - val_acc: 0.9487\n",
      "Epoch 128/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1113 - acc: 0.9620 - val_loss: 0.1310 - val_acc: 0.9536\n",
      "Epoch 129/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.0980 - acc: 0.9654 - val_loss: 0.1170 - val_acc: 0.9552\n",
      "Epoch 130/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1253 - acc: 0.9571 - val_loss: 0.1370 - val_acc: 0.9447\n",
      "Epoch 131/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1240 - acc: 0.9599 - val_loss: 0.1389 - val_acc: 0.9520\n",
      "Epoch 132/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1187 - acc: 0.9574 - val_loss: 0.1258 - val_acc: 0.9569\n",
      "Epoch 133/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.1069 - acc: 0.9630 - val_loss: 0.2360 - val_acc: 0.9219\n",
      "Epoch 134/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1129 - acc: 0.9595 - val_loss: 0.1631 - val_acc: 0.9325\n",
      "Epoch 135/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1000 - acc: 0.9616 - val_loss: 0.1313 - val_acc: 0.9536\n",
      "Epoch 136/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1159 - acc: 0.9564 - val_loss: 0.1332 - val_acc: 0.9561\n",
      "Epoch 137/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1120 - acc: 0.9616 - val_loss: 0.1745 - val_acc: 0.9357\n",
      "Epoch 138/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1108 - acc: 0.9595 - val_loss: 0.1174 - val_acc: 0.9536\n",
      "Epoch 139/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.0985 - acc: 0.9647 - val_loss: 0.1572 - val_acc: 0.9422\n",
      "Epoch 140/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1107 - acc: 0.9588 - val_loss: 0.1576 - val_acc: 0.9430\n",
      "Epoch 141/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1113 - acc: 0.9602 - val_loss: 0.1151 - val_acc: 0.9561\n",
      "Epoch 142/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.0956 - acc: 0.9675 - val_loss: 0.1182 - val_acc: 0.9552\n",
      "Epoch 143/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.0876 - acc: 0.9693 - val_loss: 0.1680 - val_acc: 0.9398\n",
      "Epoch 144/160\n",
      "90/90 [==============================] - 2s 28ms/step - loss: 0.1020 - acc: 0.9644 - val_loss: 0.2002 - val_acc: 0.9373\n",
      "Epoch 145/160\n",
      "90/90 [==============================] - 2s 28ms/step - loss: 0.1055 - acc: 0.9620 - val_loss: 0.1795 - val_acc: 0.9439\n",
      "Epoch 146/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.0964 - acc: 0.9644 - val_loss: 0.1214 - val_acc: 0.9585\n",
      "Epoch 147/160\n",
      "90/90 [==============================] - 3s 27ms/step - loss: 0.1317 - acc: 0.9522 - val_loss: 0.1203 - val_acc: 0.9520\n",
      "Epoch 148/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.0869 - acc: 0.9700 - val_loss: 0.1258 - val_acc: 0.9552\n",
      "Epoch 149/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.1054 - acc: 0.9578 - val_loss: 0.1190 - val_acc: 0.9496\n",
      "Epoch 150/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.1045 - acc: 0.9665 - val_loss: 0.1249 - val_acc: 0.9520\n",
      "Epoch 151/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.0895 - acc: 0.9689 - val_loss: 0.1338 - val_acc: 0.9439\n",
      "Epoch 152/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.1246 - acc: 0.9564 - val_loss: 0.1398 - val_acc: 0.9430\n",
      "Epoch 153/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.0983 - acc: 0.9661 - val_loss: 0.1133 - val_acc: 0.9601\n",
      "Epoch 154/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.1046 - acc: 0.9609 - val_loss: 0.2055 - val_acc: 0.9333\n",
      "Epoch 155/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1020 - acc: 0.9602 - val_loss: 0.1818 - val_acc: 0.9317\n",
      "Epoch 156/160\n",
      "90/90 [==============================] - 2s 28ms/step - loss: 0.0836 - acc: 0.9721 - val_loss: 0.1748 - val_acc: 0.9390\n",
      "Epoch 157/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1518 - acc: 0.9497 - val_loss: 0.1215 - val_acc: 0.9552\n",
      "Epoch 158/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1023 - acc: 0.9647 - val_loss: 0.1081 - val_acc: 0.9544\n",
      "Epoch 159/160\n",
      "90/90 [==============================] - 2s 28ms/step - loss: 0.1024 - acc: 0.9630 - val_loss: 0.1237 - val_acc: 0.9520\n",
      "Epoch 160/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.0855 - acc: 0.9658 - val_loss: 0.1406 - val_acc: 0.9439\n",
      "Epoch 1/160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raulpg/anaconda3/envs/tfm_tf/lib/python3.11/site-packages/keras/src/preprocessing/image.py:766: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3, or 4 channels on axis 3. However, it was passed an array with shape (2865, 48, 48, 12) (12 channels).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 4s 22ms/step - loss: 0.6790 - acc: 0.5742 - val_loss: 0.6903 - val_acc: 0.5899\n",
      "Epoch 2/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.6806 - acc: 0.5756 - val_loss: 0.6636 - val_acc: 0.5899\n",
      "Epoch 3/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.6812 - acc: 0.5815 - val_loss: 0.6475 - val_acc: 0.5899\n",
      "Epoch 4/160\n",
      "90/90 [==============================] - 2s 28ms/step - loss: 0.6238 - acc: 0.6307 - val_loss: 0.5882 - val_acc: 0.7217\n",
      "Epoch 5/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.5667 - acc: 0.7267 - val_loss: 0.5466 - val_acc: 0.7380\n",
      "Epoch 6/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.5281 - acc: 0.7564 - val_loss: 0.4889 - val_acc: 0.7478\n",
      "Epoch 7/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.5048 - acc: 0.7710 - val_loss: 0.4713 - val_acc: 0.7640\n",
      "Epoch 8/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.4985 - acc: 0.7654 - val_loss: 0.4972 - val_acc: 0.7722\n",
      "Epoch 9/160\n",
      "90/90 [==============================] - 2s 28ms/step - loss: 0.4937 - acc: 0.7696 - val_loss: 0.4895 - val_acc: 0.7738\n",
      "Epoch 10/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.4685 - acc: 0.7808 - val_loss: 0.4524 - val_acc: 0.7950\n",
      "Epoch 11/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.4618 - acc: 0.7990 - val_loss: 0.5099 - val_acc: 0.7225\n",
      "Epoch 12/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.4336 - acc: 0.8105 - val_loss: 0.4171 - val_acc: 0.8023\n",
      "Epoch 13/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.4263 - acc: 0.8126 - val_loss: 0.4314 - val_acc: 0.7966\n",
      "Epoch 14/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.4089 - acc: 0.8237 - val_loss: 0.3574 - val_acc: 0.8462\n",
      "Epoch 15/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.4050 - acc: 0.8328 - val_loss: 0.4114 - val_acc: 0.7933\n",
      "Epoch 16/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.3898 - acc: 0.8353 - val_loss: 0.3439 - val_acc: 0.8405\n",
      "Epoch 17/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.3677 - acc: 0.8419 - val_loss: 0.3503 - val_acc: 0.8413\n",
      "Epoch 18/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.3509 - acc: 0.8503 - val_loss: 0.3787 - val_acc: 0.8169\n",
      "Epoch 19/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.3329 - acc: 0.8583 - val_loss: 0.3835 - val_acc: 0.8348\n",
      "Epoch 20/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.3601 - acc: 0.8429 - val_loss: 0.3783 - val_acc: 0.8177\n",
      "Epoch 21/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.3222 - acc: 0.8621 - val_loss: 0.3292 - val_acc: 0.8544\n",
      "Epoch 22/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.3134 - acc: 0.8656 - val_loss: 0.3351 - val_acc: 0.8617\n",
      "Epoch 23/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.3167 - acc: 0.8653 - val_loss: 0.3069 - val_acc: 0.8674\n",
      "Epoch 24/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.3029 - acc: 0.8817 - val_loss: 0.3759 - val_acc: 0.8202\n",
      "Epoch 25/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.3130 - acc: 0.8712 - val_loss: 0.2761 - val_acc: 0.8812\n",
      "Epoch 26/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.2780 - acc: 0.8869 - val_loss: 0.2787 - val_acc: 0.8804\n",
      "Epoch 27/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.2884 - acc: 0.8817 - val_loss: 0.4426 - val_acc: 0.8169\n",
      "Epoch 28/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.2978 - acc: 0.8831 - val_loss: 0.2559 - val_acc: 0.8877\n",
      "Epoch 29/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.2785 - acc: 0.8918 - val_loss: 0.2501 - val_acc: 0.8950\n",
      "Epoch 30/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.2841 - acc: 0.8866 - val_loss: 0.3194 - val_acc: 0.8470\n",
      "Epoch 31/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.2903 - acc: 0.8820 - val_loss: 0.2864 - val_acc: 0.8779\n",
      "Epoch 32/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.2729 - acc: 0.8967 - val_loss: 0.3210 - val_acc: 0.8633\n",
      "Epoch 33/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.2904 - acc: 0.8813 - val_loss: 0.2444 - val_acc: 0.8991\n",
      "Epoch 34/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.2598 - acc: 0.8911 - val_loss: 0.2687 - val_acc: 0.8950\n",
      "Epoch 35/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.2518 - acc: 0.9082 - val_loss: 0.2357 - val_acc: 0.9032\n",
      "Epoch 36/160\n",
      "90/90 [==============================] - 2s 28ms/step - loss: 0.2516 - acc: 0.9026 - val_loss: 0.2442 - val_acc: 0.8959\n",
      "Epoch 37/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.2459 - acc: 0.9082 - val_loss: 0.2274 - val_acc: 0.9081\n",
      "Epoch 38/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.2376 - acc: 0.9099 - val_loss: 0.3740 - val_acc: 0.8446\n",
      "Epoch 39/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.2333 - acc: 0.9103 - val_loss: 0.2514 - val_acc: 0.8926\n",
      "Epoch 40/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.2269 - acc: 0.9099 - val_loss: 0.3234 - val_acc: 0.8674\n",
      "Epoch 41/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.2258 - acc: 0.9169 - val_loss: 0.2665 - val_acc: 0.8942\n",
      "Epoch 42/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.2267 - acc: 0.9138 - val_loss: 0.2101 - val_acc: 0.9260\n",
      "Epoch 43/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.2222 - acc: 0.9110 - val_loss: 0.2383 - val_acc: 0.9105\n",
      "Epoch 44/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.2188 - acc: 0.9211 - val_loss: 0.1967 - val_acc: 0.9268\n",
      "Epoch 45/160\n",
      "90/90 [==============================] - 2s 28ms/step - loss: 0.2147 - acc: 0.9183 - val_loss: 0.2235 - val_acc: 0.9138\n",
      "Epoch 46/160\n",
      "90/90 [==============================] - 2s 28ms/step - loss: 0.2067 - acc: 0.9271 - val_loss: 0.2339 - val_acc: 0.9081\n",
      "Epoch 47/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.2160 - acc: 0.9225 - val_loss: 0.3276 - val_acc: 0.8690\n",
      "Epoch 48/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.2103 - acc: 0.9187 - val_loss: 0.2074 - val_acc: 0.9219\n",
      "Epoch 49/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.2036 - acc: 0.9232 - val_loss: 0.1836 - val_acc: 0.9333\n",
      "Epoch 50/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.2166 - acc: 0.9176 - val_loss: 0.2088 - val_acc: 0.9227\n",
      "Epoch 51/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.1965 - acc: 0.9302 - val_loss: 0.1924 - val_acc: 0.9349\n",
      "Epoch 52/160\n",
      "90/90 [==============================] - 2s 28ms/step - loss: 0.2071 - acc: 0.9239 - val_loss: 0.1911 - val_acc: 0.9284\n",
      "Epoch 53/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.2173 - acc: 0.9201 - val_loss: 0.2067 - val_acc: 0.9243\n",
      "Epoch 54/160\n",
      "90/90 [==============================] - 3s 31ms/step - loss: 0.2179 - acc: 0.9274 - val_loss: 0.1967 - val_acc: 0.9268\n",
      "Epoch 55/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1921 - acc: 0.9330 - val_loss: 0.1828 - val_acc: 0.9349\n",
      "Epoch 56/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1938 - acc: 0.9284 - val_loss: 0.2300 - val_acc: 0.9089\n",
      "Epoch 57/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1796 - acc: 0.9358 - val_loss: 0.2318 - val_acc: 0.9072\n",
      "Epoch 58/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1885 - acc: 0.9312 - val_loss: 0.1706 - val_acc: 0.9357\n",
      "Epoch 59/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1842 - acc: 0.9393 - val_loss: 0.2346 - val_acc: 0.9146\n",
      "Epoch 60/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1842 - acc: 0.9312 - val_loss: 0.1635 - val_acc: 0.9414\n",
      "Epoch 61/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.2190 - acc: 0.9190 - val_loss: 0.1969 - val_acc: 0.9284\n",
      "Epoch 62/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1717 - acc: 0.9393 - val_loss: 0.1796 - val_acc: 0.9325\n",
      "Epoch 63/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.1641 - acc: 0.9431 - val_loss: 0.2170 - val_acc: 0.9186\n",
      "Epoch 64/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1746 - acc: 0.9358 - val_loss: 0.1528 - val_acc: 0.9447\n",
      "Epoch 65/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.1683 - acc: 0.9379 - val_loss: 0.2013 - val_acc: 0.9308\n",
      "Epoch 66/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1816 - acc: 0.9295 - val_loss: 0.1523 - val_acc: 0.9455\n",
      "Epoch 67/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.1809 - acc: 0.9361 - val_loss: 0.2075 - val_acc: 0.9349\n",
      "Epoch 68/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1705 - acc: 0.9361 - val_loss: 0.1839 - val_acc: 0.9333\n",
      "Epoch 69/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1884 - acc: 0.9295 - val_loss: 0.1909 - val_acc: 0.9341\n",
      "Epoch 70/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1746 - acc: 0.9351 - val_loss: 0.1592 - val_acc: 0.9430\n",
      "Epoch 71/160\n",
      "90/90 [==============================] - 2s 28ms/step - loss: 0.1593 - acc: 0.9417 - val_loss: 0.1795 - val_acc: 0.9333\n",
      "Epoch 72/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1755 - acc: 0.9354 - val_loss: 0.1757 - val_acc: 0.9300\n",
      "Epoch 73/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.1493 - acc: 0.9428 - val_loss: 0.2051 - val_acc: 0.9268\n",
      "Epoch 74/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1817 - acc: 0.9379 - val_loss: 0.2038 - val_acc: 0.9203\n",
      "Epoch 75/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1980 - acc: 0.9267 - val_loss: 0.2191 - val_acc: 0.9154\n",
      "Epoch 76/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1798 - acc: 0.9333 - val_loss: 0.1610 - val_acc: 0.9414\n",
      "Epoch 77/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1598 - acc: 0.9431 - val_loss: 0.1605 - val_acc: 0.9382\n",
      "Epoch 78/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1681 - acc: 0.9372 - val_loss: 0.1563 - val_acc: 0.9406\n",
      "Epoch 79/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1535 - acc: 0.9452 - val_loss: 0.2729 - val_acc: 0.8967\n",
      "Epoch 80/160\n",
      "90/90 [==============================] - 3s 31ms/step - loss: 0.1470 - acc: 0.9511 - val_loss: 0.1383 - val_acc: 0.9496\n",
      "Epoch 81/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1557 - acc: 0.9466 - val_loss: 0.1425 - val_acc: 0.9430\n",
      "Epoch 82/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1501 - acc: 0.9466 - val_loss: 0.1549 - val_acc: 0.9463\n",
      "Epoch 83/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.1623 - acc: 0.9431 - val_loss: 0.3335 - val_acc: 0.8861\n",
      "Epoch 84/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.1676 - acc: 0.9410 - val_loss: 0.1772 - val_acc: 0.9260\n",
      "Epoch 85/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.1364 - acc: 0.9501 - val_loss: 0.1915 - val_acc: 0.9382\n",
      "Epoch 86/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1485 - acc: 0.9483 - val_loss: 0.1668 - val_acc: 0.9398\n",
      "Epoch 87/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.1652 - acc: 0.9396 - val_loss: 0.1896 - val_acc: 0.9276\n",
      "Epoch 88/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1484 - acc: 0.9494 - val_loss: 0.1668 - val_acc: 0.9406\n",
      "Epoch 89/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1361 - acc: 0.9466 - val_loss: 0.1806 - val_acc: 0.9414\n",
      "Epoch 90/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1433 - acc: 0.9525 - val_loss: 0.1600 - val_acc: 0.9471\n",
      "Epoch 91/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1408 - acc: 0.9522 - val_loss: 0.1588 - val_acc: 0.9439\n",
      "Epoch 92/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1390 - acc: 0.9462 - val_loss: 0.2241 - val_acc: 0.9162\n",
      "Epoch 93/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1632 - acc: 0.9400 - val_loss: 0.1748 - val_acc: 0.9308\n",
      "Epoch 94/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1212 - acc: 0.9585 - val_loss: 0.2143 - val_acc: 0.9268\n",
      "Epoch 95/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.1483 - acc: 0.9431 - val_loss: 0.1579 - val_acc: 0.9414\n",
      "Epoch 96/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1700 - acc: 0.9372 - val_loss: 0.1584 - val_acc: 0.9365\n",
      "Epoch 97/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1469 - acc: 0.9483 - val_loss: 0.1732 - val_acc: 0.9422\n",
      "Epoch 98/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1325 - acc: 0.9532 - val_loss: 0.1487 - val_acc: 0.9463\n",
      "Epoch 99/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1192 - acc: 0.9571 - val_loss: 0.1443 - val_acc: 0.9439\n",
      "Epoch 100/160\n",
      "90/90 [==============================] - 3s 31ms/step - loss: 0.1275 - acc: 0.9532 - val_loss: 0.1613 - val_acc: 0.9406\n",
      "Epoch 101/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1162 - acc: 0.9546 - val_loss: 0.1271 - val_acc: 0.9561\n",
      "Epoch 102/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1096 - acc: 0.9630 - val_loss: 0.1896 - val_acc: 0.9357\n",
      "Epoch 103/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1281 - acc: 0.9578 - val_loss: 0.1595 - val_acc: 0.9430\n",
      "Epoch 104/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1332 - acc: 0.9546 - val_loss: 0.1400 - val_acc: 0.9479\n",
      "Epoch 105/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1307 - acc: 0.9494 - val_loss: 0.1322 - val_acc: 0.9504\n",
      "Epoch 106/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1209 - acc: 0.9543 - val_loss: 0.1279 - val_acc: 0.9487\n",
      "Epoch 107/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1361 - acc: 0.9483 - val_loss: 0.1239 - val_acc: 0.9512\n",
      "Epoch 108/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1099 - acc: 0.9613 - val_loss: 0.1587 - val_acc: 0.9512\n",
      "Epoch 109/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1157 - acc: 0.9560 - val_loss: 0.1406 - val_acc: 0.9536\n",
      "Epoch 110/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1284 - acc: 0.9546 - val_loss: 0.1170 - val_acc: 0.9552\n",
      "Epoch 111/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1312 - acc: 0.9508 - val_loss: 0.1606 - val_acc: 0.9398\n",
      "Epoch 112/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.1338 - acc: 0.9529 - val_loss: 0.1312 - val_acc: 0.9544\n",
      "Epoch 113/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1379 - acc: 0.9497 - val_loss: 0.1854 - val_acc: 0.9349\n",
      "Epoch 114/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1221 - acc: 0.9571 - val_loss: 0.1448 - val_acc: 0.9422\n",
      "Epoch 115/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1234 - acc: 0.9553 - val_loss: 0.1654 - val_acc: 0.9382\n",
      "Epoch 116/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1304 - acc: 0.9564 - val_loss: 0.1437 - val_acc: 0.9439\n",
      "Epoch 117/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1196 - acc: 0.9613 - val_loss: 0.1547 - val_acc: 0.9504\n",
      "Epoch 118/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1089 - acc: 0.9609 - val_loss: 0.1398 - val_acc: 0.9414\n",
      "Epoch 119/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.1272 - acc: 0.9546 - val_loss: 0.2116 - val_acc: 0.9243\n",
      "Epoch 120/160\n",
      "90/90 [==============================] - 2s 28ms/step - loss: 0.1276 - acc: 0.9515 - val_loss: 0.1174 - val_acc: 0.9577\n",
      "Epoch 121/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1178 - acc: 0.9585 - val_loss: 0.1694 - val_acc: 0.9308\n",
      "Epoch 122/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1154 - acc: 0.9595 - val_loss: 0.2054 - val_acc: 0.9284\n",
      "Epoch 123/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1052 - acc: 0.9640 - val_loss: 0.1295 - val_acc: 0.9593\n",
      "Epoch 124/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1114 - acc: 0.9592 - val_loss: 0.1313 - val_acc: 0.9455\n",
      "Epoch 125/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1239 - acc: 0.9515 - val_loss: 0.1408 - val_acc: 0.9528\n",
      "Epoch 126/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.1111 - acc: 0.9602 - val_loss: 0.1741 - val_acc: 0.9536\n",
      "Epoch 127/160\n",
      "90/90 [==============================] - 2s 28ms/step - loss: 0.1255 - acc: 0.9525 - val_loss: 0.2058 - val_acc: 0.9162\n",
      "Epoch 128/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.1116 - acc: 0.9627 - val_loss: 0.1294 - val_acc: 0.9536\n",
      "Epoch 129/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1265 - acc: 0.9578 - val_loss: 0.1289 - val_acc: 0.9561\n",
      "Epoch 130/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.1068 - acc: 0.9627 - val_loss: 0.1470 - val_acc: 0.9504\n",
      "Epoch 131/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1145 - acc: 0.9564 - val_loss: 0.2185 - val_acc: 0.9276\n",
      "Epoch 132/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.1047 - acc: 0.9620 - val_loss: 0.1419 - val_acc: 0.9512\n",
      "Epoch 133/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.1191 - acc: 0.9553 - val_loss: 0.1651 - val_acc: 0.9439\n",
      "Epoch 134/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.0985 - acc: 0.9693 - val_loss: 0.1443 - val_acc: 0.9512\n",
      "Epoch 135/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1100 - acc: 0.9606 - val_loss: 0.1510 - val_acc: 0.9479\n",
      "Epoch 136/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.1114 - acc: 0.9606 - val_loss: 0.1255 - val_acc: 0.9544\n",
      "Epoch 137/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1026 - acc: 0.9609 - val_loss: 0.1325 - val_acc: 0.9593\n",
      "Epoch 138/160\n",
      "90/90 [==============================] - 3s 31ms/step - loss: 0.0995 - acc: 0.9654 - val_loss: 0.1557 - val_acc: 0.9439\n",
      "Epoch 139/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1035 - acc: 0.9571 - val_loss: 0.2389 - val_acc: 0.9227\n",
      "Epoch 140/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.0997 - acc: 0.9623 - val_loss: 0.1482 - val_acc: 0.9528\n",
      "Epoch 141/160\n",
      "90/90 [==============================] - 3s 32ms/step - loss: 0.1063 - acc: 0.9623 - val_loss: 0.1462 - val_acc: 0.9528\n",
      "Epoch 142/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1089 - acc: 0.9658 - val_loss: 0.1242 - val_acc: 0.9487\n",
      "Epoch 143/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1149 - acc: 0.9595 - val_loss: 0.1468 - val_acc: 0.9447\n",
      "Epoch 144/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.1142 - acc: 0.9602 - val_loss: 0.2067 - val_acc: 0.9260\n",
      "Epoch 145/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1108 - acc: 0.9616 - val_loss: 0.1158 - val_acc: 0.9585\n",
      "Epoch 146/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.0923 - acc: 0.9661 - val_loss: 0.1410 - val_acc: 0.9471\n",
      "Epoch 147/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.1129 - acc: 0.9592 - val_loss: 0.1160 - val_acc: 0.9577\n",
      "Epoch 148/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1599 - acc: 0.9438 - val_loss: 0.1773 - val_acc: 0.9357\n",
      "Epoch 149/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1185 - acc: 0.9571 - val_loss: 0.1203 - val_acc: 0.9496\n",
      "Epoch 150/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.0904 - acc: 0.9675 - val_loss: 0.1652 - val_acc: 0.9422\n",
      "Epoch 151/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1015 - acc: 0.9627 - val_loss: 0.2113 - val_acc: 0.9235\n",
      "Epoch 152/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.0987 - acc: 0.9637 - val_loss: 0.2251 - val_acc: 0.9341\n",
      "Epoch 153/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1065 - acc: 0.9606 - val_loss: 0.1217 - val_acc: 0.9536\n",
      "Epoch 154/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.0870 - acc: 0.9668 - val_loss: 0.1914 - val_acc: 0.9373\n",
      "Epoch 155/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1237 - acc: 0.9581 - val_loss: 0.1175 - val_acc: 0.9593\n",
      "Epoch 156/160\n",
      "90/90 [==============================] - 3s 27ms/step - loss: 0.0876 - acc: 0.9686 - val_loss: 0.1211 - val_acc: 0.9569\n",
      "Epoch 157/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1028 - acc: 0.9651 - val_loss: 0.2189 - val_acc: 0.9422\n",
      "Epoch 158/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.0948 - acc: 0.9654 - val_loss: 0.1199 - val_acc: 0.9552\n",
      "Epoch 159/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.0983 - acc: 0.9627 - val_loss: 0.1184 - val_acc: 0.9536\n",
      "Epoch 160/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.0844 - acc: 0.9693 - val_loss: 0.1218 - val_acc: 0.9626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/scripts/dl_utils.py:172: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  valores.append(float(df.iloc[3][-2]))\n",
      "/mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/scripts/dl_utils.py:176: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  valores_old.append(float(prev_df.iloc[3][-2]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raulpg/anaconda3/envs/tfm_tf/lib/python3.11/site-packages/keras/src/preprocessing/image.py:766: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3, or 4 channels on axis 3. However, it was passed an array with shape (2865, 48, 48, 12) (12 channels).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 3s 21ms/step - loss: 0.6867 - acc: 0.5714 - val_loss: 0.6670 - val_acc: 0.5899\n",
      "Epoch 2/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.6507 - acc: 0.6321 - val_loss: 0.5701 - val_acc: 0.7274\n",
      "Epoch 3/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.5793 - acc: 0.7033 - val_loss: 0.5412 - val_acc: 0.7494\n",
      "Epoch 4/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.5472 - acc: 0.7466 - val_loss: 0.5054 - val_acc: 0.7608\n",
      "Epoch 5/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.5104 - acc: 0.7672 - val_loss: 0.4799 - val_acc: 0.7510\n",
      "Epoch 6/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.4953 - acc: 0.7742 - val_loss: 0.4666 - val_acc: 0.7616\n",
      "Epoch 7/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.5121 - acc: 0.7599 - val_loss: 0.4833 - val_acc: 0.7535\n",
      "Epoch 8/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.4883 - acc: 0.7829 - val_loss: 0.4633 - val_acc: 0.7575\n",
      "Epoch 9/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.4714 - acc: 0.7951 - val_loss: 0.4385 - val_acc: 0.8063\n",
      "Epoch 10/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.4684 - acc: 0.7888 - val_loss: 0.4535 - val_acc: 0.7705\n",
      "Epoch 11/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.4743 - acc: 0.7881 - val_loss: 0.4991 - val_acc: 0.7526\n",
      "Epoch 12/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.4721 - acc: 0.7874 - val_loss: 0.4331 - val_acc: 0.7884\n",
      "Epoch 13/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.4274 - acc: 0.8206 - val_loss: 0.3841 - val_acc: 0.8177\n",
      "Epoch 14/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.4170 - acc: 0.8112 - val_loss: 0.4038 - val_acc: 0.8267\n",
      "Epoch 15/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.3740 - acc: 0.8450 - val_loss: 0.3540 - val_acc: 0.8340\n",
      "Epoch 16/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.3693 - acc: 0.8380 - val_loss: 0.3637 - val_acc: 0.8446\n",
      "Epoch 17/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.3505 - acc: 0.8517 - val_loss: 0.3396 - val_acc: 0.8454\n",
      "Epoch 18/160\n",
      "90/90 [==============================] - 2s 28ms/step - loss: 0.3341 - acc: 0.8600 - val_loss: 0.2991 - val_acc: 0.8633\n",
      "Epoch 19/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.3296 - acc: 0.8639 - val_loss: 0.3064 - val_acc: 0.8674\n",
      "Epoch 20/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.3080 - acc: 0.8764 - val_loss: 0.2979 - val_acc: 0.8584\n",
      "Epoch 21/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.3061 - acc: 0.8729 - val_loss: 0.3412 - val_acc: 0.8609\n",
      "Epoch 22/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.3098 - acc: 0.8747 - val_loss: 0.2695 - val_acc: 0.8828\n",
      "Epoch 23/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.2861 - acc: 0.8904 - val_loss: 0.2940 - val_acc: 0.8747\n",
      "Epoch 24/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.2965 - acc: 0.8841 - val_loss: 0.2738 - val_acc: 0.8910\n",
      "Epoch 25/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.2755 - acc: 0.8942 - val_loss: 0.2644 - val_acc: 0.8828\n",
      "Epoch 26/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.2822 - acc: 0.8890 - val_loss: 0.2674 - val_acc: 0.8845\n",
      "Epoch 27/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.2925 - acc: 0.8855 - val_loss: 0.2640 - val_acc: 0.8869\n",
      "Epoch 28/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.2818 - acc: 0.8883 - val_loss: 0.2832 - val_acc: 0.8804\n",
      "Epoch 29/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.2800 - acc: 0.8880 - val_loss: 0.2752 - val_acc: 0.8771\n",
      "Epoch 30/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.2637 - acc: 0.8949 - val_loss: 0.2845 - val_acc: 0.8714\n",
      "Epoch 31/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.2515 - acc: 0.9026 - val_loss: 0.2703 - val_acc: 0.8779\n",
      "Epoch 32/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.2765 - acc: 0.8942 - val_loss: 0.2432 - val_acc: 0.8942\n",
      "Epoch 33/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.2482 - acc: 0.9058 - val_loss: 0.2560 - val_acc: 0.9032\n",
      "Epoch 34/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.2429 - acc: 0.9103 - val_loss: 0.2660 - val_acc: 0.8877\n",
      "Epoch 35/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.2511 - acc: 0.9030 - val_loss: 0.2351 - val_acc: 0.9040\n",
      "Epoch 36/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.2393 - acc: 0.9072 - val_loss: 0.2750 - val_acc: 0.8755\n",
      "Epoch 37/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.2434 - acc: 0.9040 - val_loss: 0.2455 - val_acc: 0.9056\n",
      "Epoch 38/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.2406 - acc: 0.9092 - val_loss: 0.2261 - val_acc: 0.9032\n",
      "Epoch 39/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.2568 - acc: 0.9054 - val_loss: 0.2237 - val_acc: 0.9170\n",
      "Epoch 40/160\n",
      "90/90 [==============================] - 2s 28ms/step - loss: 0.2331 - acc: 0.9141 - val_loss: 0.2246 - val_acc: 0.9097\n",
      "Epoch 41/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.2277 - acc: 0.9152 - val_loss: 0.2376 - val_acc: 0.9113\n",
      "Epoch 42/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.2645 - acc: 0.8939 - val_loss: 0.2264 - val_acc: 0.9089\n",
      "Epoch 43/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.2292 - acc: 0.9162 - val_loss: 0.2291 - val_acc: 0.8999\n",
      "Epoch 44/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.2255 - acc: 0.9197 - val_loss: 0.2312 - val_acc: 0.9064\n",
      "Epoch 45/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.2350 - acc: 0.9110 - val_loss: 0.2063 - val_acc: 0.9146\n",
      "Epoch 46/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.2212 - acc: 0.9110 - val_loss: 0.2115 - val_acc: 0.9138\n",
      "Epoch 47/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.2134 - acc: 0.9215 - val_loss: 0.2155 - val_acc: 0.9138\n",
      "Epoch 48/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.2227 - acc: 0.9159 - val_loss: 0.2566 - val_acc: 0.8910\n",
      "Epoch 49/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.2157 - acc: 0.9211 - val_loss: 0.2473 - val_acc: 0.8926\n",
      "Epoch 50/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.2218 - acc: 0.9229 - val_loss: 0.2347 - val_acc: 0.9089\n",
      "Epoch 51/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.2075 - acc: 0.9253 - val_loss: 0.1908 - val_acc: 0.9300\n",
      "Epoch 52/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.2115 - acc: 0.9159 - val_loss: 0.1811 - val_acc: 0.9276\n",
      "Epoch 53/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.2055 - acc: 0.9236 - val_loss: 0.4359 - val_acc: 0.7933\n",
      "Epoch 54/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.2153 - acc: 0.9173 - val_loss: 0.2499 - val_acc: 0.8836\n",
      "Epoch 55/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.2105 - acc: 0.9267 - val_loss: 0.1967 - val_acc: 0.9235\n",
      "Epoch 56/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.2011 - acc: 0.9246 - val_loss: 0.1901 - val_acc: 0.9243\n",
      "Epoch 57/160\n",
      "90/90 [==============================] - 2s 28ms/step - loss: 0.2014 - acc: 0.9232 - val_loss: 0.1761 - val_acc: 0.9341\n",
      "Epoch 58/160\n",
      "90/90 [==============================] - 2s 28ms/step - loss: 0.2000 - acc: 0.9218 - val_loss: 0.2055 - val_acc: 0.9129\n",
      "Epoch 59/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1899 - acc: 0.9274 - val_loss: 0.1965 - val_acc: 0.9203\n",
      "Epoch 60/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.1976 - acc: 0.9295 - val_loss: 0.1877 - val_acc: 0.9276\n",
      "Epoch 61/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.2054 - acc: 0.9232 - val_loss: 0.1902 - val_acc: 0.9251\n",
      "Epoch 62/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.1916 - acc: 0.9312 - val_loss: 0.1675 - val_acc: 0.9365\n",
      "Epoch 63/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.1852 - acc: 0.9298 - val_loss: 0.1811 - val_acc: 0.9276\n",
      "Epoch 64/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.2101 - acc: 0.9215 - val_loss: 0.2149 - val_acc: 0.9203\n",
      "Epoch 65/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1971 - acc: 0.9250 - val_loss: 0.1722 - val_acc: 0.9365\n",
      "Epoch 66/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.2021 - acc: 0.9302 - val_loss: 0.1732 - val_acc: 0.9325\n",
      "Epoch 67/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1760 - acc: 0.9354 - val_loss: 0.1743 - val_acc: 0.9284\n",
      "Epoch 68/160\n",
      "90/90 [==============================] - 3s 31ms/step - loss: 0.1861 - acc: 0.9257 - val_loss: 0.1754 - val_acc: 0.9243\n",
      "Epoch 69/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1781 - acc: 0.9309 - val_loss: 0.2263 - val_acc: 0.9097\n",
      "Epoch 70/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.1780 - acc: 0.9330 - val_loss: 0.2083 - val_acc: 0.9154\n",
      "Epoch 71/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1843 - acc: 0.9344 - val_loss: 0.1661 - val_acc: 0.9308\n",
      "Epoch 72/160\n",
      "90/90 [==============================] - 3s 32ms/step - loss: 0.1957 - acc: 0.9316 - val_loss: 0.1592 - val_acc: 0.9382\n",
      "Epoch 73/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1713 - acc: 0.9365 - val_loss: 0.1595 - val_acc: 0.9414\n",
      "Epoch 74/160\n",
      "90/90 [==============================] - 3s 31ms/step - loss: 0.1630 - acc: 0.9403 - val_loss: 0.1788 - val_acc: 0.9243\n",
      "Epoch 75/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1679 - acc: 0.9333 - val_loss: 0.1657 - val_acc: 0.9341\n",
      "Epoch 76/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1706 - acc: 0.9354 - val_loss: 0.1922 - val_acc: 0.9203\n",
      "Epoch 77/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1725 - acc: 0.9337 - val_loss: 0.1862 - val_acc: 0.9211\n",
      "Epoch 78/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1698 - acc: 0.9421 - val_loss: 0.1771 - val_acc: 0.9251\n",
      "Epoch 79/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.1733 - acc: 0.9379 - val_loss: 0.1662 - val_acc: 0.9341\n",
      "Epoch 80/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1475 - acc: 0.9459 - val_loss: 0.1978 - val_acc: 0.9194\n",
      "Epoch 81/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1707 - acc: 0.9375 - val_loss: 0.2274 - val_acc: 0.8983\n",
      "Epoch 82/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.1516 - acc: 0.9431 - val_loss: 0.1621 - val_acc: 0.9365\n",
      "Epoch 83/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1418 - acc: 0.9494 - val_loss: 0.2037 - val_acc: 0.9251\n",
      "Epoch 84/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1674 - acc: 0.9347 - val_loss: 0.1717 - val_acc: 0.9317\n",
      "Epoch 85/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1661 - acc: 0.9403 - val_loss: 0.3119 - val_acc: 0.8755\n",
      "Epoch 86/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1474 - acc: 0.9438 - val_loss: 0.1974 - val_acc: 0.9308\n",
      "Epoch 87/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1476 - acc: 0.9435 - val_loss: 0.1395 - val_acc: 0.9487\n",
      "Epoch 88/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1569 - acc: 0.9421 - val_loss: 0.1743 - val_acc: 0.9341\n",
      "Epoch 89/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1522 - acc: 0.9393 - val_loss: 0.1839 - val_acc: 0.9341\n",
      "Epoch 90/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1478 - acc: 0.9462 - val_loss: 0.1623 - val_acc: 0.9349\n",
      "Epoch 91/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.1513 - acc: 0.9389 - val_loss: 0.1522 - val_acc: 0.9398\n",
      "Epoch 92/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1474 - acc: 0.9473 - val_loss: 0.1479 - val_acc: 0.9406\n",
      "Epoch 93/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.1368 - acc: 0.9522 - val_loss: 0.1409 - val_acc: 0.9463\n",
      "Epoch 94/160\n",
      "90/90 [==============================] - 2s 28ms/step - loss: 0.1506 - acc: 0.9386 - val_loss: 0.1895 - val_acc: 0.9186\n",
      "Epoch 95/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1692 - acc: 0.9347 - val_loss: 0.1814 - val_acc: 0.9162\n",
      "Epoch 96/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1468 - acc: 0.9466 - val_loss: 0.1431 - val_acc: 0.9373\n",
      "Epoch 97/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1912 - acc: 0.9267 - val_loss: 0.1634 - val_acc: 0.9373\n",
      "Epoch 98/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1540 - acc: 0.9417 - val_loss: 0.1734 - val_acc: 0.9365\n",
      "Epoch 99/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.1543 - acc: 0.9396 - val_loss: 0.1578 - val_acc: 0.9471\n",
      "Epoch 100/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1372 - acc: 0.9515 - val_loss: 0.1872 - val_acc: 0.9300\n",
      "Epoch 101/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.1388 - acc: 0.9532 - val_loss: 0.1303 - val_acc: 0.9504\n",
      "Epoch 102/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.1445 - acc: 0.9497 - val_loss: 0.1942 - val_acc: 0.9317\n",
      "Epoch 103/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.1210 - acc: 0.9529 - val_loss: 0.1605 - val_acc: 0.9406\n",
      "Epoch 104/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1273 - acc: 0.9494 - val_loss: 0.1481 - val_acc: 0.9487\n",
      "Epoch 105/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.1513 - acc: 0.9435 - val_loss: 0.1361 - val_acc: 0.9496\n",
      "Epoch 106/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1380 - acc: 0.9480 - val_loss: 0.1846 - val_acc: 0.9276\n",
      "Epoch 107/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.1382 - acc: 0.9518 - val_loss: 0.1338 - val_acc: 0.9463\n",
      "Epoch 108/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.1204 - acc: 0.9553 - val_loss: 0.1220 - val_acc: 0.9471\n",
      "Epoch 109/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.1296 - acc: 0.9553 - val_loss: 0.1192 - val_acc: 0.9569\n",
      "Epoch 110/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1318 - acc: 0.9501 - val_loss: 0.1990 - val_acc: 0.9186\n",
      "Epoch 111/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1526 - acc: 0.9452 - val_loss: 0.2323 - val_acc: 0.9089\n",
      "Epoch 112/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.1486 - acc: 0.9424 - val_loss: 0.1775 - val_acc: 0.9292\n",
      "Epoch 113/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1251 - acc: 0.9543 - val_loss: 0.1434 - val_acc: 0.9398\n",
      "Epoch 114/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.1287 - acc: 0.9529 - val_loss: 0.1220 - val_acc: 0.9512\n",
      "Epoch 115/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1198 - acc: 0.9557 - val_loss: 0.1262 - val_acc: 0.9512\n",
      "Epoch 116/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1205 - acc: 0.9522 - val_loss: 0.1550 - val_acc: 0.9430\n",
      "Epoch 117/160\n",
      "90/90 [==============================] - 3s 32ms/step - loss: 0.1137 - acc: 0.9564 - val_loss: 0.1974 - val_acc: 0.9390\n",
      "Epoch 118/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1469 - acc: 0.9487 - val_loss: 0.1302 - val_acc: 0.9520\n",
      "Epoch 119/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1350 - acc: 0.9494 - val_loss: 0.1607 - val_acc: 0.9382\n",
      "Epoch 120/160\n",
      "90/90 [==============================] - 3s 31ms/step - loss: 0.1311 - acc: 0.9508 - val_loss: 0.1397 - val_acc: 0.9422\n",
      "Epoch 121/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1174 - acc: 0.9571 - val_loss: 0.1775 - val_acc: 0.9325\n",
      "Epoch 122/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1263 - acc: 0.9529 - val_loss: 0.1321 - val_acc: 0.9479\n",
      "Epoch 123/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1139 - acc: 0.9620 - val_loss: 0.1099 - val_acc: 0.9626\n",
      "Epoch 124/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1147 - acc: 0.9616 - val_loss: 0.1347 - val_acc: 0.9422\n",
      "Epoch 125/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1278 - acc: 0.9518 - val_loss: 0.1651 - val_acc: 0.9382\n",
      "Epoch 126/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1329 - acc: 0.9483 - val_loss: 0.2877 - val_acc: 0.8967\n",
      "Epoch 127/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1210 - acc: 0.9543 - val_loss: 0.1594 - val_acc: 0.9463\n",
      "Epoch 128/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1259 - acc: 0.9599 - val_loss: 0.1186 - val_acc: 0.9561\n",
      "Epoch 129/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.0948 - acc: 0.9654 - val_loss: 0.1253 - val_acc: 0.9520\n",
      "Epoch 130/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1254 - acc: 0.9522 - val_loss: 0.1243 - val_acc: 0.9520\n",
      "Epoch 131/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1087 - acc: 0.9592 - val_loss: 0.1969 - val_acc: 0.9211\n",
      "Epoch 132/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1235 - acc: 0.9553 - val_loss: 0.1655 - val_acc: 0.9382\n",
      "Epoch 133/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1126 - acc: 0.9613 - val_loss: 0.1377 - val_acc: 0.9496\n",
      "Epoch 134/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1276 - acc: 0.9557 - val_loss: 0.1612 - val_acc: 0.9333\n",
      "Epoch 135/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1089 - acc: 0.9567 - val_loss: 0.1825 - val_acc: 0.9292\n",
      "Epoch 136/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1075 - acc: 0.9606 - val_loss: 0.1163 - val_acc: 0.9520\n",
      "Epoch 137/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.1448 - acc: 0.9522 - val_loss: 0.1306 - val_acc: 0.9569\n",
      "Epoch 138/160\n",
      "90/90 [==============================] - 2s 28ms/step - loss: 0.1107 - acc: 0.9627 - val_loss: 0.1452 - val_acc: 0.9512\n",
      "Epoch 139/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1177 - acc: 0.9578 - val_loss: 0.1244 - val_acc: 0.9544\n",
      "Epoch 140/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1006 - acc: 0.9644 - val_loss: 0.1287 - val_acc: 0.9561\n",
      "Epoch 141/160\n",
      "90/90 [==============================] - 2s 28ms/step - loss: 0.1019 - acc: 0.9609 - val_loss: 0.1514 - val_acc: 0.9471\n",
      "Epoch 142/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1198 - acc: 0.9557 - val_loss: 0.1331 - val_acc: 0.9544\n",
      "Epoch 143/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1098 - acc: 0.9588 - val_loss: 0.1220 - val_acc: 0.9577\n",
      "Epoch 144/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.0902 - acc: 0.9675 - val_loss: 0.1050 - val_acc: 0.9601\n",
      "Epoch 145/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.1124 - acc: 0.9599 - val_loss: 0.1705 - val_acc: 0.9365\n",
      "Epoch 146/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1146 - acc: 0.9578 - val_loss: 0.1162 - val_acc: 0.9593\n",
      "Epoch 147/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.0953 - acc: 0.9644 - val_loss: 0.1492 - val_acc: 0.9422\n",
      "Epoch 148/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1048 - acc: 0.9634 - val_loss: 0.1240 - val_acc: 0.9585\n",
      "Epoch 149/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.0969 - acc: 0.9672 - val_loss: 0.1351 - val_acc: 0.9585\n",
      "Epoch 150/160\n",
      "90/90 [==============================] - 2s 28ms/step - loss: 0.1124 - acc: 0.9595 - val_loss: 0.1213 - val_acc: 0.9577\n",
      "Epoch 151/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1039 - acc: 0.9581 - val_loss: 0.1175 - val_acc: 0.9593\n",
      "Epoch 152/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.0991 - acc: 0.9658 - val_loss: 0.1323 - val_acc: 0.9512\n",
      "Epoch 153/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.0998 - acc: 0.9627 - val_loss: 0.1086 - val_acc: 0.9626\n",
      "Epoch 154/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.1170 - acc: 0.9560 - val_loss: 0.1210 - val_acc: 0.9552\n",
      "Epoch 155/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.1058 - acc: 0.9634 - val_loss: 0.2187 - val_acc: 0.9276\n",
      "Epoch 156/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.1064 - acc: 0.9609 - val_loss: 0.1746 - val_acc: 0.9341\n",
      "Epoch 157/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1023 - acc: 0.9668 - val_loss: 0.1306 - val_acc: 0.9536\n",
      "Epoch 158/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.0899 - acc: 0.9665 - val_loss: 0.1656 - val_acc: 0.9414\n",
      "Epoch 159/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.1219 - acc: 0.9571 - val_loss: 0.1233 - val_acc: 0.9528\n",
      "Epoch 160/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.0851 - acc: 0.9675 - val_loss: 0.1384 - val_acc: 0.9536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/scripts/dl_utils.py:172: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  valores.append(float(df.iloc[3][-2]))\n",
      "/mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/scripts/dl_utils.py:176: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  valores_old.append(float(prev_df.iloc[3][-2]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raulpg/anaconda3/envs/tfm_tf/lib/python3.11/site-packages/keras/src/preprocessing/image.py:766: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3, or 4 channels on axis 3. However, it was passed an array with shape (2865, 48, 48, 12) (12 channels).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 4s 22ms/step - loss: 0.6833 - acc: 0.5679 - val_loss: 0.6550 - val_acc: 0.5899\n",
      "Epoch 2/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.6291 - acc: 0.6363 - val_loss: 0.6030 - val_acc: 0.6192\n",
      "Epoch 3/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.5703 - acc: 0.7305 - val_loss: 0.5362 - val_acc: 0.7250\n",
      "Epoch 4/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.5185 - acc: 0.7546 - val_loss: 0.4748 - val_acc: 0.7657\n",
      "Epoch 5/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.5165 - acc: 0.7651 - val_loss: 0.4771 - val_acc: 0.7665\n",
      "Epoch 6/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.4704 - acc: 0.7902 - val_loss: 0.4278 - val_acc: 0.8039\n",
      "Epoch 7/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.4748 - acc: 0.7934 - val_loss: 0.4655 - val_acc: 0.7868\n",
      "Epoch 8/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.4412 - acc: 0.8098 - val_loss: 0.4022 - val_acc: 0.8381\n",
      "Epoch 9/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.4058 - acc: 0.8318 - val_loss: 0.3677 - val_acc: 0.8324\n",
      "Epoch 10/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.4044 - acc: 0.8262 - val_loss: 0.4582 - val_acc: 0.7730\n",
      "Epoch 11/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.3799 - acc: 0.8415 - val_loss: 0.3591 - val_acc: 0.8478\n",
      "Epoch 12/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.3863 - acc: 0.8366 - val_loss: 0.4241 - val_acc: 0.8096\n",
      "Epoch 13/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.3749 - acc: 0.8426 - val_loss: 0.3921 - val_acc: 0.8194\n",
      "Epoch 14/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.3250 - acc: 0.8621 - val_loss: 0.3069 - val_acc: 0.8544\n",
      "Epoch 15/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.3581 - acc: 0.8513 - val_loss: 0.3710 - val_acc: 0.8356\n",
      "Epoch 16/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.3311 - acc: 0.8663 - val_loss: 0.3001 - val_acc: 0.8698\n",
      "Epoch 17/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.2997 - acc: 0.8824 - val_loss: 0.2964 - val_acc: 0.8674\n",
      "Epoch 18/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.3080 - acc: 0.8796 - val_loss: 0.2662 - val_acc: 0.8828\n",
      "Epoch 19/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.2773 - acc: 0.8873 - val_loss: 0.2749 - val_acc: 0.8885\n",
      "Epoch 20/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.2749 - acc: 0.8925 - val_loss: 0.3320 - val_acc: 0.8592\n",
      "Epoch 21/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.2778 - acc: 0.8960 - val_loss: 0.3617 - val_acc: 0.8592\n",
      "Epoch 22/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.2617 - acc: 0.9037 - val_loss: 0.2991 - val_acc: 0.8617\n",
      "Epoch 23/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.2499 - acc: 0.9016 - val_loss: 0.2754 - val_acc: 0.8828\n",
      "Epoch 24/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.2602 - acc: 0.8998 - val_loss: 0.2519 - val_acc: 0.8959\n",
      "Epoch 25/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.2787 - acc: 0.8848 - val_loss: 0.2496 - val_acc: 0.9064\n",
      "Epoch 26/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.2609 - acc: 0.8967 - val_loss: 0.2700 - val_acc: 0.8788\n",
      "Epoch 27/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.2292 - acc: 0.9127 - val_loss: 0.2188 - val_acc: 0.9064\n",
      "Epoch 28/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.2358 - acc: 0.9068 - val_loss: 0.2143 - val_acc: 0.9211\n",
      "Epoch 29/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.2339 - acc: 0.9082 - val_loss: 0.2338 - val_acc: 0.9056\n",
      "Epoch 30/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.2157 - acc: 0.9159 - val_loss: 0.2585 - val_acc: 0.8836\n",
      "Epoch 31/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.2254 - acc: 0.9180 - val_loss: 0.3443 - val_acc: 0.8487\n",
      "Epoch 32/160\n",
      "90/90 [==============================] - 2s 28ms/step - loss: 0.2458 - acc: 0.9051 - val_loss: 0.2610 - val_acc: 0.8885\n",
      "Epoch 33/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.2231 - acc: 0.9141 - val_loss: 0.2428 - val_acc: 0.9032\n",
      "Epoch 34/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.2037 - acc: 0.9264 - val_loss: 0.2332 - val_acc: 0.9007\n",
      "Epoch 35/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.2513 - acc: 0.9044 - val_loss: 0.3000 - val_acc: 0.8592\n",
      "Epoch 36/160\n",
      "90/90 [==============================] - 2s 28ms/step - loss: 0.2266 - acc: 0.9145 - val_loss: 0.2441 - val_acc: 0.8902\n",
      "Epoch 37/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.2020 - acc: 0.9271 - val_loss: 0.1879 - val_acc: 0.9276\n",
      "Epoch 38/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.2001 - acc: 0.9239 - val_loss: 0.1961 - val_acc: 0.9227\n",
      "Epoch 39/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.1880 - acc: 0.9309 - val_loss: 0.1976 - val_acc: 0.9243\n",
      "Epoch 40/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.2029 - acc: 0.9239 - val_loss: 0.1905 - val_acc: 0.9227\n",
      "Epoch 41/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.2071 - acc: 0.9288 - val_loss: 0.2556 - val_acc: 0.8950\n",
      "Epoch 42/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.1901 - acc: 0.9302 - val_loss: 0.2096 - val_acc: 0.9219\n",
      "Epoch 43/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1999 - acc: 0.9222 - val_loss: 0.1621 - val_acc: 0.9390\n",
      "Epoch 44/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1892 - acc: 0.9340 - val_loss: 0.2121 - val_acc: 0.9105\n",
      "Epoch 45/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1878 - acc: 0.9323 - val_loss: 0.1656 - val_acc: 0.9325\n",
      "Epoch 46/160\n",
      "90/90 [==============================] - 3s 31ms/step - loss: 0.1680 - acc: 0.9414 - val_loss: 0.1839 - val_acc: 0.9284\n",
      "Epoch 47/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1948 - acc: 0.9358 - val_loss: 0.1753 - val_acc: 0.9333\n",
      "Epoch 48/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.1645 - acc: 0.9396 - val_loss: 0.1707 - val_acc: 0.9382\n",
      "Epoch 49/160\n",
      "90/90 [==============================] - 3s 31ms/step - loss: 0.1785 - acc: 0.9295 - val_loss: 0.2024 - val_acc: 0.9186\n",
      "Epoch 50/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1820 - acc: 0.9361 - val_loss: 0.2384 - val_acc: 0.9032\n",
      "Epoch 51/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.1603 - acc: 0.9462 - val_loss: 0.1859 - val_acc: 0.9292\n",
      "Epoch 52/160\n",
      "90/90 [==============================] - 3s 31ms/step - loss: 0.1550 - acc: 0.9410 - val_loss: 0.2048 - val_acc: 0.9251\n",
      "Epoch 53/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1658 - acc: 0.9400 - val_loss: 0.1570 - val_acc: 0.9390\n",
      "Epoch 54/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1655 - acc: 0.9442 - val_loss: 0.1525 - val_acc: 0.9406\n",
      "Epoch 55/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.1494 - acc: 0.9452 - val_loss: 0.2287 - val_acc: 0.9162\n",
      "Epoch 56/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1945 - acc: 0.9271 - val_loss: 0.1533 - val_acc: 0.9398\n",
      "Epoch 57/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.1598 - acc: 0.9414 - val_loss: 0.1650 - val_acc: 0.9357\n",
      "Epoch 58/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1525 - acc: 0.9452 - val_loss: 0.1522 - val_acc: 0.9430\n",
      "Epoch 59/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1512 - acc: 0.9462 - val_loss: 0.1518 - val_acc: 0.9406\n",
      "Epoch 60/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1527 - acc: 0.9487 - val_loss: 0.2070 - val_acc: 0.9154\n",
      "Epoch 61/160\n",
      "90/90 [==============================] - 2s 28ms/step - loss: 0.1561 - acc: 0.9452 - val_loss: 0.1444 - val_acc: 0.9471\n",
      "Epoch 62/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1651 - acc: 0.9396 - val_loss: 0.2770 - val_acc: 0.8893\n",
      "Epoch 63/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1651 - acc: 0.9428 - val_loss: 0.1565 - val_acc: 0.9430\n",
      "Epoch 64/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.1583 - acc: 0.9400 - val_loss: 0.1625 - val_acc: 0.9422\n",
      "Epoch 65/160\n",
      "90/90 [==============================] - 2s 28ms/step - loss: 0.1640 - acc: 0.9389 - val_loss: 0.1922 - val_acc: 0.9284\n",
      "Epoch 66/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1361 - acc: 0.9532 - val_loss: 0.1517 - val_acc: 0.9512\n",
      "Epoch 67/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1531 - acc: 0.9459 - val_loss: 0.1573 - val_acc: 0.9479\n",
      "Epoch 68/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1720 - acc: 0.9354 - val_loss: 0.1392 - val_acc: 0.9504\n",
      "Epoch 69/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1309 - acc: 0.9525 - val_loss: 0.2350 - val_acc: 0.9162\n",
      "Epoch 70/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1432 - acc: 0.9515 - val_loss: 0.1355 - val_acc: 0.9512\n",
      "Epoch 71/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.1259 - acc: 0.9571 - val_loss: 0.1368 - val_acc: 0.9504\n",
      "Epoch 72/160\n",
      "90/90 [==============================] - 2s 28ms/step - loss: 0.1419 - acc: 0.9442 - val_loss: 0.1385 - val_acc: 0.9487\n",
      "Epoch 73/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1306 - acc: 0.9515 - val_loss: 0.1500 - val_acc: 0.9422\n",
      "Epoch 74/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.1304 - acc: 0.9518 - val_loss: 0.1362 - val_acc: 0.9463\n",
      "Epoch 75/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1553 - acc: 0.9403 - val_loss: 0.1651 - val_acc: 0.9333\n",
      "Epoch 76/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1209 - acc: 0.9613 - val_loss: 0.1651 - val_acc: 0.9382\n",
      "Epoch 77/160\n",
      "90/90 [==============================] - 3s 31ms/step - loss: 0.1474 - acc: 0.9428 - val_loss: 0.1643 - val_acc: 0.9341\n",
      "Epoch 78/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.1382 - acc: 0.9490 - val_loss: 0.1380 - val_acc: 0.9471\n",
      "Epoch 79/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.1120 - acc: 0.9553 - val_loss: 0.1333 - val_acc: 0.9479\n",
      "Epoch 80/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.1388 - acc: 0.9504 - val_loss: 0.2293 - val_acc: 0.9089\n",
      "Epoch 81/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1365 - acc: 0.9543 - val_loss: 0.2031 - val_acc: 0.9284\n",
      "Epoch 82/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.1498 - acc: 0.9466 - val_loss: 0.1287 - val_acc: 0.9577\n",
      "Epoch 83/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.1161 - acc: 0.9595 - val_loss: 0.1281 - val_acc: 0.9536\n",
      "Epoch 84/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.1296 - acc: 0.9567 - val_loss: 0.1295 - val_acc: 0.9504\n",
      "Epoch 85/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1164 - acc: 0.9581 - val_loss: 0.1220 - val_acc: 0.9487\n",
      "Epoch 86/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.1441 - acc: 0.9466 - val_loss: 0.1903 - val_acc: 0.9317\n",
      "Epoch 87/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.1291 - acc: 0.9543 - val_loss: 0.1492 - val_acc: 0.9487\n",
      "Epoch 88/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.1317 - acc: 0.9532 - val_loss: 0.1789 - val_acc: 0.9317\n",
      "Epoch 89/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1293 - acc: 0.9546 - val_loss: 0.1301 - val_acc: 0.9561\n",
      "Epoch 90/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1190 - acc: 0.9595 - val_loss: 0.1405 - val_acc: 0.9561\n",
      "Epoch 91/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1200 - acc: 0.9557 - val_loss: 0.1240 - val_acc: 0.9569\n",
      "Epoch 92/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.1178 - acc: 0.9599 - val_loss: 0.1425 - val_acc: 0.9512\n",
      "Epoch 93/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1061 - acc: 0.9630 - val_loss: 0.1335 - val_acc: 0.9544\n",
      "Epoch 94/160\n",
      "90/90 [==============================] - 3s 31ms/step - loss: 0.1279 - acc: 0.9539 - val_loss: 0.1395 - val_acc: 0.9463\n",
      "Epoch 95/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1031 - acc: 0.9606 - val_loss: 0.1156 - val_acc: 0.9569\n",
      "Epoch 96/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.1358 - acc: 0.9501 - val_loss: 0.1974 - val_acc: 0.9349\n",
      "Epoch 97/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1105 - acc: 0.9606 - val_loss: 0.1216 - val_acc: 0.9585\n",
      "Epoch 98/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1203 - acc: 0.9539 - val_loss: 0.1860 - val_acc: 0.9373\n",
      "Epoch 99/160\n",
      "90/90 [==============================] - 3s 31ms/step - loss: 0.1236 - acc: 0.9564 - val_loss: 0.2249 - val_acc: 0.9089\n",
      "Epoch 100/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1171 - acc: 0.9592 - val_loss: 0.1473 - val_acc: 0.9455\n",
      "Epoch 101/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.1027 - acc: 0.9668 - val_loss: 0.1374 - val_acc: 0.9487\n",
      "Epoch 102/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1016 - acc: 0.9668 - val_loss: 0.1123 - val_acc: 0.9593\n",
      "Epoch 103/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1099 - acc: 0.9585 - val_loss: 0.1347 - val_acc: 0.9479\n",
      "Epoch 104/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1029 - acc: 0.9620 - val_loss: 0.2389 - val_acc: 0.9194\n",
      "Epoch 105/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1139 - acc: 0.9623 - val_loss: 0.1906 - val_acc: 0.9308\n",
      "Epoch 106/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1147 - acc: 0.9574 - val_loss: 0.1283 - val_acc: 0.9552\n",
      "Epoch 107/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1088 - acc: 0.9620 - val_loss: 0.1319 - val_acc: 0.9512\n",
      "Epoch 108/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.1002 - acc: 0.9661 - val_loss: 0.1495 - val_acc: 0.9504\n",
      "Epoch 109/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1052 - acc: 0.9651 - val_loss: 0.1338 - val_acc: 0.9544\n",
      "Epoch 110/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1148 - acc: 0.9602 - val_loss: 0.1294 - val_acc: 0.9512\n",
      "Epoch 111/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.1121 - acc: 0.9595 - val_loss: 0.1343 - val_acc: 0.9544\n",
      "Epoch 112/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1134 - acc: 0.9571 - val_loss: 0.1412 - val_acc: 0.9422\n",
      "Epoch 113/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1029 - acc: 0.9609 - val_loss: 0.1155 - val_acc: 0.9593\n",
      "Epoch 114/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1041 - acc: 0.9623 - val_loss: 0.1115 - val_acc: 0.9593\n",
      "Epoch 115/160\n",
      "90/90 [==============================] - 2s 28ms/step - loss: 0.1072 - acc: 0.9602 - val_loss: 0.1752 - val_acc: 0.9357\n",
      "Epoch 116/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.0858 - acc: 0.9689 - val_loss: 0.1139 - val_acc: 0.9666\n",
      "Epoch 117/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.0896 - acc: 0.9668 - val_loss: 0.1415 - val_acc: 0.9561\n",
      "Epoch 118/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.0911 - acc: 0.9672 - val_loss: 0.1179 - val_acc: 0.9577\n",
      "Epoch 119/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.0922 - acc: 0.9682 - val_loss: 0.2112 - val_acc: 0.9284\n",
      "Epoch 120/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1258 - acc: 0.9522 - val_loss: 0.1158 - val_acc: 0.9601\n",
      "Epoch 121/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.0901 - acc: 0.9682 - val_loss: 0.1223 - val_acc: 0.9528\n",
      "Epoch 122/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.1038 - acc: 0.9616 - val_loss: 0.1557 - val_acc: 0.9455\n",
      "Epoch 123/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.0923 - acc: 0.9654 - val_loss: 0.1360 - val_acc: 0.9487\n",
      "Epoch 124/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1207 - acc: 0.9536 - val_loss: 0.1318 - val_acc: 0.9496\n",
      "Epoch 125/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1169 - acc: 0.9574 - val_loss: 0.1206 - val_acc: 0.9544\n",
      "Epoch 126/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.1025 - acc: 0.9595 - val_loss: 0.1077 - val_acc: 0.9601\n",
      "Epoch 127/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.0894 - acc: 0.9661 - val_loss: 0.1058 - val_acc: 0.9634\n",
      "Epoch 128/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.0810 - acc: 0.9703 - val_loss: 0.1227 - val_acc: 0.9536\n",
      "Epoch 129/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1009 - acc: 0.9640 - val_loss: 0.3251 - val_acc: 0.8959\n",
      "Epoch 130/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.0957 - acc: 0.9634 - val_loss: 0.1141 - val_acc: 0.9601\n",
      "Epoch 131/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.0917 - acc: 0.9689 - val_loss: 0.1139 - val_acc: 0.9634\n",
      "Epoch 132/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.1151 - acc: 0.9567 - val_loss: 0.1716 - val_acc: 0.9422\n",
      "Epoch 133/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.1028 - acc: 0.9620 - val_loss: 0.1020 - val_acc: 0.9658\n",
      "Epoch 134/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.0884 - acc: 0.9686 - val_loss: 0.1144 - val_acc: 0.9577\n",
      "Epoch 135/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.0917 - acc: 0.9654 - val_loss: 0.1819 - val_acc: 0.9496\n",
      "Epoch 136/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.0948 - acc: 0.9616 - val_loss: 0.1244 - val_acc: 0.9577\n",
      "Epoch 137/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.0951 - acc: 0.9675 - val_loss: 0.1685 - val_acc: 0.9471\n",
      "Epoch 138/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.0871 - acc: 0.9661 - val_loss: 0.3279 - val_acc: 0.9081\n",
      "Epoch 139/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.1039 - acc: 0.9637 - val_loss: 0.1746 - val_acc: 0.9357\n",
      "Epoch 140/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.0980 - acc: 0.9654 - val_loss: 0.1407 - val_acc: 0.9528\n",
      "Epoch 141/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.0879 - acc: 0.9675 - val_loss: 0.1383 - val_acc: 0.9601\n",
      "Epoch 142/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.0818 - acc: 0.9717 - val_loss: 0.1477 - val_acc: 0.9504\n",
      "Epoch 143/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1013 - acc: 0.9651 - val_loss: 0.2733 - val_acc: 0.9227\n",
      "Epoch 144/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.0979 - acc: 0.9682 - val_loss: 0.1752 - val_acc: 0.9496\n",
      "Epoch 145/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.0955 - acc: 0.9627 - val_loss: 0.1219 - val_acc: 0.9577\n",
      "Epoch 146/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.0988 - acc: 0.9634 - val_loss: 0.1380 - val_acc: 0.9512\n",
      "Epoch 147/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.0894 - acc: 0.9672 - val_loss: 0.1334 - val_acc: 0.9520\n",
      "Epoch 148/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.0759 - acc: 0.9728 - val_loss: 0.1930 - val_acc: 0.9406\n",
      "Epoch 149/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.0948 - acc: 0.9661 - val_loss: 0.1261 - val_acc: 0.9536\n",
      "Epoch 150/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.0742 - acc: 0.9742 - val_loss: 0.1811 - val_acc: 0.9349\n",
      "Epoch 151/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1275 - acc: 0.9522 - val_loss: 0.2178 - val_acc: 0.9097\n",
      "Epoch 152/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.0900 - acc: 0.9703 - val_loss: 0.1012 - val_acc: 0.9650\n",
      "Epoch 153/160\n",
      "90/90 [==============================] - 2s 28ms/step - loss: 0.0789 - acc: 0.9710 - val_loss: 0.1636 - val_acc: 0.9447\n",
      "Epoch 154/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.0748 - acc: 0.9724 - val_loss: 0.1202 - val_acc: 0.9626\n",
      "Epoch 155/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.0858 - acc: 0.9724 - val_loss: 0.1226 - val_acc: 0.9601\n",
      "Epoch 156/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1073 - acc: 0.9627 - val_loss: 0.1260 - val_acc: 0.9569\n",
      "Epoch 157/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.0846 - acc: 0.9686 - val_loss: 0.1334 - val_acc: 0.9593\n",
      "Epoch 158/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.0731 - acc: 0.9735 - val_loss: 0.1246 - val_acc: 0.9536\n",
      "Epoch 159/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.0646 - acc: 0.9766 - val_loss: 0.1148 - val_acc: 0.9634\n",
      "Epoch 160/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.0740 - acc: 0.9738 - val_loss: 0.1472 - val_acc: 0.9552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/scripts/dl_utils.py:172: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  valores.append(float(df.iloc[3][-2]))\n",
      "/mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/scripts/dl_utils.py:176: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  valores_old.append(float(prev_df.iloc[3][-2]))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/raulpg/anaconda3/envs/tfm_tf/lib/python3.11/site-packages/keras/src/preprocessing/image.py:766: UserWarning: NumpyArrayIterator is set to use the data format convention \"channels_last\" (channels on axis 3), i.e. expected either 1, 3, or 4 channels on axis 3. However, it was passed an array with shape (2865, 48, 48, 12) (12 channels).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 4s 22ms/step - loss: 0.6865 - acc: 0.5937 - val_loss: 0.6798 - val_acc: 0.5899\n",
      "Epoch 2/160\n",
      "90/90 [==============================] - 2s 28ms/step - loss: 0.6336 - acc: 0.6531 - val_loss: 0.5170 - val_acc: 0.7583\n",
      "Epoch 3/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.5433 - acc: 0.7483 - val_loss: 0.4879 - val_acc: 0.7526\n",
      "Epoch 4/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.4979 - acc: 0.7700 - val_loss: 0.4484 - val_acc: 0.7884\n",
      "Epoch 5/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.4898 - acc: 0.7937 - val_loss: 0.4361 - val_acc: 0.7966\n",
      "Epoch 6/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.4625 - acc: 0.7934 - val_loss: 0.4189 - val_acc: 0.7738\n",
      "Epoch 7/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.4346 - acc: 0.8059 - val_loss: 0.3934 - val_acc: 0.8169\n",
      "Epoch 8/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.4013 - acc: 0.8297 - val_loss: 0.3873 - val_acc: 0.8291\n",
      "Epoch 9/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.4057 - acc: 0.8213 - val_loss: 0.3951 - val_acc: 0.8316\n",
      "Epoch 10/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.3842 - acc: 0.8394 - val_loss: 0.3480 - val_acc: 0.8332\n",
      "Epoch 11/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.4209 - acc: 0.8213 - val_loss: 0.3910 - val_acc: 0.8365\n",
      "Epoch 12/160\n",
      "90/90 [==============================] - 3s 31ms/step - loss: 0.3721 - acc: 0.8380 - val_loss: 0.3453 - val_acc: 0.8405\n",
      "Epoch 13/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.3415 - acc: 0.8541 - val_loss: 0.3633 - val_acc: 0.8129\n",
      "Epoch 14/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.3366 - acc: 0.8538 - val_loss: 0.3380 - val_acc: 0.8495\n",
      "Epoch 15/160\n",
      "90/90 [==============================] - 3s 32ms/step - loss: 0.3354 - acc: 0.8590 - val_loss: 0.3299 - val_acc: 0.8503\n",
      "Epoch 16/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.3081 - acc: 0.8768 - val_loss: 0.3010 - val_acc: 0.8600\n",
      "Epoch 17/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.3007 - acc: 0.8743 - val_loss: 0.3108 - val_acc: 0.8560\n",
      "Epoch 18/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.3076 - acc: 0.8764 - val_loss: 0.3211 - val_acc: 0.8592\n",
      "Epoch 19/160\n",
      "90/90 [==============================] - 3s 31ms/step - loss: 0.3130 - acc: 0.8754 - val_loss: 0.3444 - val_acc: 0.8413\n",
      "Epoch 20/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.2859 - acc: 0.8768 - val_loss: 0.3169 - val_acc: 0.8796\n",
      "Epoch 21/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.2761 - acc: 0.8921 - val_loss: 0.3015 - val_acc: 0.8649\n",
      "Epoch 22/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.2778 - acc: 0.8901 - val_loss: 0.2684 - val_acc: 0.8950\n",
      "Epoch 23/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.2815 - acc: 0.8908 - val_loss: 0.2994 - val_acc: 0.8714\n",
      "Epoch 24/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.2644 - acc: 0.8949 - val_loss: 0.2841 - val_acc: 0.8731\n",
      "Epoch 25/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.2679 - acc: 0.8946 - val_loss: 0.2779 - val_acc: 0.8828\n",
      "Epoch 26/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.2485 - acc: 0.9012 - val_loss: 0.3071 - val_acc: 0.8747\n",
      "Epoch 27/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.2564 - acc: 0.9005 - val_loss: 0.4095 - val_acc: 0.8234\n",
      "Epoch 28/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.2513 - acc: 0.9040 - val_loss: 0.2570 - val_acc: 0.8893\n",
      "Epoch 29/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.2566 - acc: 0.9037 - val_loss: 0.2913 - val_acc: 0.8682\n",
      "Epoch 30/160\n",
      "90/90 [==============================] - 3s 31ms/step - loss: 0.2499 - acc: 0.8942 - val_loss: 0.2387 - val_acc: 0.9024\n",
      "Epoch 31/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.2326 - acc: 0.9145 - val_loss: 0.2228 - val_acc: 0.9121\n",
      "Epoch 32/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.2427 - acc: 0.9033 - val_loss: 0.2490 - val_acc: 0.8934\n",
      "Epoch 33/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.2459 - acc: 0.9009 - val_loss: 0.2404 - val_acc: 0.9072\n",
      "Epoch 34/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.2392 - acc: 0.9040 - val_loss: 0.2908 - val_acc: 0.8731\n",
      "Epoch 35/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.2281 - acc: 0.9141 - val_loss: 0.3060 - val_acc: 0.8698\n",
      "Epoch 36/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.2356 - acc: 0.9075 - val_loss: 0.2179 - val_acc: 0.9105\n",
      "Epoch 37/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.2081 - acc: 0.9225 - val_loss: 0.2152 - val_acc: 0.9154\n",
      "Epoch 38/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.2211 - acc: 0.9117 - val_loss: 0.2349 - val_acc: 0.8983\n",
      "Epoch 39/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.2117 - acc: 0.9190 - val_loss: 0.2516 - val_acc: 0.8975\n",
      "Epoch 40/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.2181 - acc: 0.9208 - val_loss: 0.2268 - val_acc: 0.9138\n",
      "Epoch 41/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.2143 - acc: 0.9176 - val_loss: 0.2537 - val_acc: 0.8893\n",
      "Epoch 42/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.2153 - acc: 0.9208 - val_loss: 0.2604 - val_acc: 0.8836\n",
      "Epoch 43/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.2132 - acc: 0.9190 - val_loss: 0.2045 - val_acc: 0.9170\n",
      "Epoch 44/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.2045 - acc: 0.9253 - val_loss: 0.1980 - val_acc: 0.9211\n",
      "Epoch 45/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1929 - acc: 0.9267 - val_loss: 0.2220 - val_acc: 0.9089\n",
      "Epoch 46/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.2057 - acc: 0.9232 - val_loss: 0.3602 - val_acc: 0.8584\n",
      "Epoch 47/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.2058 - acc: 0.9166 - val_loss: 0.2025 - val_acc: 0.9113\n",
      "Epoch 48/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.2025 - acc: 0.9253 - val_loss: 0.2290 - val_acc: 0.9113\n",
      "Epoch 49/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.1988 - acc: 0.9194 - val_loss: 0.2124 - val_acc: 0.9186\n",
      "Epoch 50/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.2012 - acc: 0.9243 - val_loss: 0.3454 - val_acc: 0.8560\n",
      "Epoch 51/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1868 - acc: 0.9354 - val_loss: 0.2036 - val_acc: 0.9178\n",
      "Epoch 52/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.2000 - acc: 0.9225 - val_loss: 0.1848 - val_acc: 0.9227\n",
      "Epoch 53/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1809 - acc: 0.9354 - val_loss: 0.1995 - val_acc: 0.9251\n",
      "Epoch 54/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1898 - acc: 0.9257 - val_loss: 0.1799 - val_acc: 0.9292\n",
      "Epoch 55/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1903 - acc: 0.9264 - val_loss: 0.1879 - val_acc: 0.9235\n",
      "Epoch 56/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.1800 - acc: 0.9316 - val_loss: 0.2524 - val_acc: 0.8926\n",
      "Epoch 57/160\n",
      "90/90 [==============================] - 3s 31ms/step - loss: 0.1837 - acc: 0.9309 - val_loss: 0.1773 - val_acc: 0.9243\n",
      "Epoch 58/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1789 - acc: 0.9333 - val_loss: 0.1918 - val_acc: 0.9203\n",
      "Epoch 59/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1717 - acc: 0.9347 - val_loss: 0.2015 - val_acc: 0.9227\n",
      "Epoch 60/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1715 - acc: 0.9361 - val_loss: 0.2135 - val_acc: 0.9121\n",
      "Epoch 61/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.1536 - acc: 0.9428 - val_loss: 0.1732 - val_acc: 0.9333\n",
      "Epoch 62/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.1819 - acc: 0.9323 - val_loss: 0.1796 - val_acc: 0.9276\n",
      "Epoch 63/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.1655 - acc: 0.9431 - val_loss: 0.1738 - val_acc: 0.9284\n",
      "Epoch 64/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1616 - acc: 0.9386 - val_loss: 0.2042 - val_acc: 0.9170\n",
      "Epoch 65/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.1618 - acc: 0.9414 - val_loss: 0.1666 - val_acc: 0.9333\n",
      "Epoch 66/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.1485 - acc: 0.9438 - val_loss: 0.1763 - val_acc: 0.9219\n",
      "Epoch 67/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1592 - acc: 0.9431 - val_loss: 0.2132 - val_acc: 0.9186\n",
      "Epoch 68/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.1682 - acc: 0.9382 - val_loss: 0.2209 - val_acc: 0.9129\n",
      "Epoch 69/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1457 - acc: 0.9494 - val_loss: 0.1781 - val_acc: 0.9349\n",
      "Epoch 70/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.1715 - acc: 0.9368 - val_loss: 0.3071 - val_acc: 0.8836\n",
      "Epoch 71/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1578 - acc: 0.9403 - val_loss: 0.1595 - val_acc: 0.9414\n",
      "Epoch 72/160\n",
      "90/90 [==============================] - 3s 31ms/step - loss: 0.1388 - acc: 0.9508 - val_loss: 0.1716 - val_acc: 0.9341\n",
      "Epoch 73/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1595 - acc: 0.9396 - val_loss: 0.1784 - val_acc: 0.9276\n",
      "Epoch 74/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1508 - acc: 0.9438 - val_loss: 0.1606 - val_acc: 0.9365\n",
      "Epoch 75/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1378 - acc: 0.9515 - val_loss: 0.2278 - val_acc: 0.9219\n",
      "Epoch 76/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.1709 - acc: 0.9400 - val_loss: 0.1675 - val_acc: 0.9333\n",
      "Epoch 77/160\n",
      "90/90 [==============================] - 2s 28ms/step - loss: 0.1418 - acc: 0.9431 - val_loss: 0.1541 - val_acc: 0.9447\n",
      "Epoch 78/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1454 - acc: 0.9435 - val_loss: 0.1633 - val_acc: 0.9357\n",
      "Epoch 79/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1427 - acc: 0.9518 - val_loss: 0.2286 - val_acc: 0.9081\n",
      "Epoch 80/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1500 - acc: 0.9442 - val_loss: 0.1491 - val_acc: 0.9430\n",
      "Epoch 81/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1370 - acc: 0.9525 - val_loss: 0.2708 - val_acc: 0.8967\n",
      "Epoch 82/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1510 - acc: 0.9449 - val_loss: 0.1627 - val_acc: 0.9349\n",
      "Epoch 83/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.1385 - acc: 0.9501 - val_loss: 0.1816 - val_acc: 0.9292\n",
      "Epoch 84/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1369 - acc: 0.9532 - val_loss: 0.1492 - val_acc: 0.9422\n",
      "Epoch 85/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1355 - acc: 0.9497 - val_loss: 0.1724 - val_acc: 0.9349\n",
      "Epoch 86/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.1395 - acc: 0.9532 - val_loss: 0.1339 - val_acc: 0.9487\n",
      "Epoch 87/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1428 - acc: 0.9473 - val_loss: 0.1871 - val_acc: 0.9292\n",
      "Epoch 88/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1249 - acc: 0.9571 - val_loss: 0.1525 - val_acc: 0.9382\n",
      "Epoch 89/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1419 - acc: 0.9504 - val_loss: 0.3229 - val_acc: 0.8836\n",
      "Epoch 90/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1564 - acc: 0.9414 - val_loss: 0.1591 - val_acc: 0.9390\n",
      "Epoch 91/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.1400 - acc: 0.9483 - val_loss: 0.1409 - val_acc: 0.9422\n",
      "Epoch 92/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1283 - acc: 0.9501 - val_loss: 0.1475 - val_acc: 0.9430\n",
      "Epoch 93/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.1330 - acc: 0.9515 - val_loss: 0.1529 - val_acc: 0.9439\n",
      "Epoch 94/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1313 - acc: 0.9578 - val_loss: 0.1242 - val_acc: 0.9528\n",
      "Epoch 95/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1280 - acc: 0.9599 - val_loss: 0.2058 - val_acc: 0.9260\n",
      "Epoch 96/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1411 - acc: 0.9462 - val_loss: 0.1775 - val_acc: 0.9186\n",
      "Epoch 97/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.1375 - acc: 0.9473 - val_loss: 0.1383 - val_acc: 0.9439\n",
      "Epoch 98/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1116 - acc: 0.9557 - val_loss: 0.1930 - val_acc: 0.9447\n",
      "Epoch 99/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1140 - acc: 0.9616 - val_loss: 0.1446 - val_acc: 0.9430\n",
      "Epoch 100/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1244 - acc: 0.9567 - val_loss: 0.1533 - val_acc: 0.9414\n",
      "Epoch 101/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.1017 - acc: 0.9616 - val_loss: 0.1630 - val_acc: 0.9414\n",
      "Epoch 102/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.1300 - acc: 0.9501 - val_loss: 0.2796 - val_acc: 0.9113\n",
      "Epoch 103/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.1126 - acc: 0.9609 - val_loss: 0.1532 - val_acc: 0.9439\n",
      "Epoch 104/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1157 - acc: 0.9581 - val_loss: 0.2020 - val_acc: 0.9284\n",
      "Epoch 105/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.1279 - acc: 0.9525 - val_loss: 0.1469 - val_acc: 0.9496\n",
      "Epoch 106/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1199 - acc: 0.9581 - val_loss: 0.1578 - val_acc: 0.9447\n",
      "Epoch 107/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.1207 - acc: 0.9550 - val_loss: 0.1227 - val_acc: 0.9552\n",
      "Epoch 108/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.1125 - acc: 0.9567 - val_loss: 0.1374 - val_acc: 0.9496\n",
      "Epoch 109/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.1000 - acc: 0.9630 - val_loss: 0.1945 - val_acc: 0.9382\n",
      "Epoch 110/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1351 - acc: 0.9490 - val_loss: 0.1288 - val_acc: 0.9487\n",
      "Epoch 111/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.1476 - acc: 0.9449 - val_loss: 0.1538 - val_acc: 0.9439\n",
      "Epoch 112/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1105 - acc: 0.9616 - val_loss: 0.1219 - val_acc: 0.9552\n",
      "Epoch 113/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.1181 - acc: 0.9602 - val_loss: 0.3776 - val_acc: 0.8674\n",
      "Epoch 114/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1173 - acc: 0.9585 - val_loss: 0.1681 - val_acc: 0.9373\n",
      "Epoch 115/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1067 - acc: 0.9620 - val_loss: 0.1477 - val_acc: 0.9390\n",
      "Epoch 116/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.0981 - acc: 0.9644 - val_loss: 0.1437 - val_acc: 0.9398\n",
      "Epoch 117/160\n",
      "90/90 [==============================] - 2s 28ms/step - loss: 0.1150 - acc: 0.9585 - val_loss: 0.1252 - val_acc: 0.9496\n",
      "Epoch 118/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1020 - acc: 0.9640 - val_loss: 0.3648 - val_acc: 0.8731\n",
      "Epoch 119/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1284 - acc: 0.9532 - val_loss: 0.1454 - val_acc: 0.9439\n",
      "Epoch 120/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1068 - acc: 0.9592 - val_loss: 0.1281 - val_acc: 0.9528\n",
      "Epoch 121/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1158 - acc: 0.9560 - val_loss: 0.1776 - val_acc: 0.9382\n",
      "Epoch 122/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1031 - acc: 0.9627 - val_loss: 0.1195 - val_acc: 0.9561\n",
      "Epoch 123/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1139 - acc: 0.9585 - val_loss: 0.1619 - val_acc: 0.9414\n",
      "Epoch 124/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1024 - acc: 0.9606 - val_loss: 0.1461 - val_acc: 0.9471\n",
      "Epoch 125/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.0891 - acc: 0.9661 - val_loss: 0.1231 - val_acc: 0.9569\n",
      "Epoch 126/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1031 - acc: 0.9620 - val_loss: 0.1402 - val_acc: 0.9463\n",
      "Epoch 127/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.0996 - acc: 0.9640 - val_loss: 0.2069 - val_acc: 0.9186\n",
      "Epoch 128/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.1241 - acc: 0.9553 - val_loss: 0.3337 - val_acc: 0.9032\n",
      "Epoch 129/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1292 - acc: 0.9574 - val_loss: 0.1400 - val_acc: 0.9487\n",
      "Epoch 130/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1040 - acc: 0.9640 - val_loss: 0.1324 - val_acc: 0.9504\n",
      "Epoch 131/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1383 - acc: 0.9494 - val_loss: 0.1802 - val_acc: 0.9219\n",
      "Epoch 132/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.1030 - acc: 0.9658 - val_loss: 0.1307 - val_acc: 0.9520\n",
      "Epoch 133/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.0880 - acc: 0.9696 - val_loss: 0.1933 - val_acc: 0.9365\n",
      "Epoch 134/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1058 - acc: 0.9606 - val_loss: 0.1624 - val_acc: 0.9349\n",
      "Epoch 135/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1006 - acc: 0.9651 - val_loss: 0.1319 - val_acc: 0.9536\n",
      "Epoch 136/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1051 - acc: 0.9599 - val_loss: 0.2043 - val_acc: 0.9178\n",
      "Epoch 137/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1315 - acc: 0.9501 - val_loss: 0.1905 - val_acc: 0.9243\n",
      "Epoch 138/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.0958 - acc: 0.9647 - val_loss: 0.1119 - val_acc: 0.9536\n",
      "Epoch 139/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.0923 - acc: 0.9700 - val_loss: 0.1389 - val_acc: 0.9479\n",
      "Epoch 140/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1070 - acc: 0.9588 - val_loss: 0.1726 - val_acc: 0.9471\n",
      "Epoch 141/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.0950 - acc: 0.9665 - val_loss: 0.1329 - val_acc: 0.9520\n",
      "Epoch 142/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.0812 - acc: 0.9742 - val_loss: 0.1278 - val_acc: 0.9609\n",
      "Epoch 143/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1027 - acc: 0.9616 - val_loss: 0.2155 - val_acc: 0.9308\n",
      "Epoch 144/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.0938 - acc: 0.9654 - val_loss: 0.1096 - val_acc: 0.9585\n",
      "Epoch 145/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.1137 - acc: 0.9585 - val_loss: 0.1761 - val_acc: 0.9455\n",
      "Epoch 146/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1042 - acc: 0.9647 - val_loss: 0.1231 - val_acc: 0.9577\n",
      "Epoch 147/160\n",
      "90/90 [==============================] - 3s 30ms/step - loss: 0.0964 - acc: 0.9654 - val_loss: 0.1285 - val_acc: 0.9471\n",
      "Epoch 148/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.0866 - acc: 0.9679 - val_loss: 0.1674 - val_acc: 0.9471\n",
      "Epoch 149/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.0905 - acc: 0.9703 - val_loss: 0.1151 - val_acc: 0.9504\n",
      "Epoch 150/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.0902 - acc: 0.9679 - val_loss: 0.1775 - val_acc: 0.9382\n",
      "Epoch 151/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.1278 - acc: 0.9536 - val_loss: 0.1339 - val_acc: 0.9463\n",
      "Epoch 152/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.0928 - acc: 0.9679 - val_loss: 0.1392 - val_acc: 0.9414\n",
      "Epoch 153/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.0874 - acc: 0.9668 - val_loss: 0.1376 - val_acc: 0.9447\n",
      "Epoch 154/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.0944 - acc: 0.9627 - val_loss: 0.1050 - val_acc: 0.9601\n",
      "Epoch 155/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.0815 - acc: 0.9724 - val_loss: 0.1589 - val_acc: 0.9471\n",
      "Epoch 156/160\n",
      "90/90 [==============================] - 3s 29ms/step - loss: 0.0814 - acc: 0.9696 - val_loss: 0.1123 - val_acc: 0.9593\n",
      "Epoch 157/160\n",
      "90/90 [==============================] - 2s 28ms/step - loss: 0.0780 - acc: 0.9700 - val_loss: 0.1925 - val_acc: 0.9520\n",
      "Epoch 158/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.1054 - acc: 0.9658 - val_loss: 0.1308 - val_acc: 0.9552\n",
      "Epoch 159/160\n",
      "90/90 [==============================] - 3s 28ms/step - loss: 0.0852 - acc: 0.9689 - val_loss: 0.1268 - val_acc: 0.9569\n",
      "Epoch 160/160\n",
      "90/90 [==============================] - 2s 27ms/step - loss: 0.0950 - acc: 0.9640 - val_loss: 0.2348 - val_acc: 0.9300\n",
      "CPU times: user 42min 46s, sys: 2min 32s, total: 45min 19s\n",
      "Wall time: 35min 5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/scripts/dl_utils.py:172: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  valores.append(float(df.iloc[3][-2]))\n",
      "/mnt/c/Users/raulp/Documents/Master/TFM/minig-detector-tfm/scripts/dl_utils.py:176: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  valores_old.append(float(prev_df.iloc[3][-2]))\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Descripcion de esta prueba\n",
    "desc_test = \"modelo_y_parametros_originales\"\n",
    "hiperparametros = [hiper_params_original_test]\n",
    "\n",
    "# Inicializamos para dar nombre a todos los outputs que se escriban\n",
    "hora_exec = datetime.now().strftime('%Y-%m-%d_%H-%M')\n",
    "\n",
    "# Creamos el nombre del directorio para guardar los modelos finales\n",
    "path_prueba_actual = f\"../notebooks/best_models/{desc_test}_{hora_exec}/\"\n",
    "os.makedirs(path_prueba_actual, exist_ok=True)\n",
    "\n",
    "# Inicializamos las variables dónde almacenaremos los resultados de cada uno de los modelos generados\n",
    "df_scratch = pd.DataFrame()\n",
    "\n",
    "#Eliminamos los csvs generados en ejecuciones anteriores\n",
    "dl_utils.limpia_directorios(\"aux_path\")\n",
    "\n",
    "# Recorremos la lista de configuraciones distinta generada anteriormente\n",
    "for id_hiperparams,hiperparams in enumerate(hiperparametros):\n",
    "    for semilla in range(0,5):  \n",
    "\n",
    "        # Limpiamos la carpeta donde se guardan los modelos\n",
    "        dl_utils.limpia_directorios(\"weigths\")\n",
    "\n",
    "        # Definimos hiperparámetros asociados a la ejecución actual\n",
    "        batch_size = hiperparams[\"batch_size\"]\n",
    "        epochs = hiperparams[\"epochs\"]\n",
    "     \n",
    "        # Dividimos el conjunto de imágenes en train y test\n",
    "        seed = np.random.randint(0, 2000,1)[0]\n",
    "        hiperparams[\"semilla\"] = seed\n",
    "        keras.utils.set_random_seed(int(seed))\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x_norm, y, test_size=hiperparams[\"test_size\"], random_state=123)\n",
    "\n",
    "        # Definimos y compilamos los modelos\n",
    "        scratch_original_model_and_params = models.scratch_original_model(input_shape)\n",
    "\n",
    "        start_time = time.time()\n",
    "        # Modelo por defecto empleando los mismos parámetros que el original.\n",
    "        scratch_original_model_and_params_results = scratch_original_model_and_params.fit(\n",
    "            datagen.flow(x_train, y_train),\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            validation_data=(x_test, y_test),\n",
    "            verbose=1,\n",
    "            shuffle=True,\n",
    "            class_weight=hiperparams[\"class_weight\"],\n",
    "        )\n",
    "        training_time_scratch_original_model_and_params = time.time() - start_time\n",
    "\n",
    "        # Evaluamos el modelo y lo comparamos con el mejor almacenado.  \n",
    "        hora_actual = datetime.now().strftime('%Y-%m-%d_%H-%M')\n",
    "        df_scratch,          save_df_scratch          = dl_utils.get_df_best_model(scratch_original_model_and_params,x_test,y_test,f\"scratch_original_model_and_params_{desc_test}_\",df_scratch,hora_actual)\n",
    "\n",
    "        # Si el modelo actual es mejor que el almacenado, guardamos su información.      \n",
    "        if save_df_scratch:\n",
    "            best_scratch_original_model_and_params = scratch_original_model_and_params\n",
    "            best_scratch_original_model_and_params_results = scratch_original_model_and_params_results.history\n",
    "            best_scratch_original_model_and_params_hiperparams = [hiperparams,\n",
    "                                                                  id_hiperparams+1,\n",
    "                                                                  f'resultados_evaluacion_scratch_original_model_and_params_{desc_test}_{hora_actual}.csv',\n",
    "                                                                  training_time_scratch_original_model_and_params,\n",
    "                                                                  len(scratch_original_model_and_params_results.epoch)]\n",
    "        \n",
    "        del scratch_original_model_and_params\n",
    "        del scratch_original_model_and_params_results\n",
    "        K.clear_session()\n",
    "        gc.collect()        \n",
    "\n",
    "# Guardamos el mejor modelo\n",
    "dl_utils.save_models(best_scratch_original_model_and_params,best_scratch_original_model_and_params_results,best_scratch_original_model_and_params_hiperparams,hora_exec,f'scratch_original_model_and_params_{desc_test}',path_prueba_actual)\n",
    "\n",
    "# Movemos los archivos asociados a los resultados\n",
    "dl_utils.obtener_tablas_resultado(path_prueba_actual,[best_scratch_original_model_and_params_hiperparams[2]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "bec97cbb607180795486aa419a93884fe3d0b55501c3e5098d64200fe61c3ffb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
